0:00 hi me too good morning so now it's 7 00
0:04 am for you or
0:05 yeah just after 7 a.m yeah so
0:08 thanks a lot for uh for coming
0:12 such an early hour you know for me this
0:16 actually isn't that early it's i work a
0:19 couple of different time zones so this
0:21 isn't too strange for me
0:24 okay so what time do you usually wake up
0:27 uh usually about 4 35
0:31 somewhere in that half hour range and
0:34 i've got east coast clients i've got uk
0:36 clients i've got one client in germany
0:39 but we don't really get on the phone too
0:40 often i usually interact with their us
0:42 division
0:43 i've got one client now that's in south
0:46 korea
0:47 and so i am i'm global
0:53 so okay yeah thanks for finding
0:57 time in your schedule to talk to us and
1:00 share your
1:00 your knowledge and uh yeah i think we
1:04 can start
1:05 yes it's uh yeah next time maybe i'll
1:09 think if i want to do another five hours
1:11 long conference
1:12 so it's uh it's a marathon if you're the
1:15 host
1:16 and you're the only one so i'll think
1:19 twice next time
1:20 and actually we still have 55 people
1:23 who managed to steal till uh to stay
1:26 till the
1:26 the last hour so these are probably
1:29 people who really wanted to
1:30 to listen to our conversation so thanks
1:33 a lot for staying that long
1:35 uh it must be tiring i know uh and uh
1:38 yeah thank you also for uh
1:40 for putting that post that went uh uh
1:43 like i don't know if it's wild for you
1:45 but like i i consider it a
1:47 pretty um successful post like
1:50 a lot of people noticed that uh
1:54 that conference because of your post so
1:57 i i don't know
1:58 like how many but like i saw a very high
2:01 speak
2:02 of registrations right after you posted
2:04 and the trick you did
2:05 with uh you know like first 45 people
2:08 get a free and they
2:10 this is amazing you know it's funny
2:12 we're data scientists
2:14 we do all of this type of work with
2:16 marketing
2:17 we build models to help automate
2:20 marketing
2:20 i build models for pricing strategy and
2:22 decision support
2:24 and then you see people online not use
2:26 it you know we have all of this
2:27 knowledge
2:28 and why do i use it why not apply it to
2:31 our everyday life and you can do things
2:34 that are interesting and fun and
2:35 entertaining
2:36 because we've seen the data okay
2:39 yeah so let's start so
2:42 now we have this last talk of today
2:46 and we will talk about the key roles and
2:48 skills for monetizing machine learning
2:50 and we have a special guest today uh vin
2:52 vashishta
2:53 vin's current focus is monetizing
2:56 machine learning
2:57 which covers revenue pricing strategies
2:59 model reliability
3:01 and also covers defining and hiring
3:03 research architect
3:05 architecture product management roles
3:08 and
3:08 he also covers the path to production so
3:11 as you see
3:12 vin is doing a lot of interesting things
3:15 since the topic of today's conference is
3:18 career
3:20 we will focus more on on roles roles
3:23 that are important for monetizing
3:24 machine learning
3:25 so welcome thanks for joining us today
3:28 thank you for having me
3:29 yes before we go into our main topic
3:33 uh let's start with your background can
3:35 you tell us a bit more about your career
3:37 journey so far
3:39 every time i do this i sound old i've
3:41 been in
3:42 technology in the field for over 25
3:44 years
3:45 i was fortunate my mom worked at the
3:48 university
3:49 where i lived and so i had one of the
3:51 earliest email addresses when i was 12
3:54 years old
3:55 and fell in love with it really did i
3:58 had a couple of good teachers in grade
4:00 school who pushed me towards programming
4:04 and fell in love with it wanted to do
4:06 machine learning
4:07 went to school went to college for
4:09 machine learning during that first
4:11 boom uh in the early 90s and graduated
4:14 and no one wanted to hire me to do
4:16 machine learning because it had all
4:17 fallen apart by the time i graduated
4:19 so i had to go into tech i had to go
4:21 into traditional technology roles
4:23 and that meant a broad range for my
4:26 career
4:27 i've done everything from install
4:29 computers do websites
4:31 build networks all the way out to
4:34 product management roles
4:35 and so i've played a role in every phase
4:37 of the software development life cycle
4:39 got into strategy led and built
4:42 teams and then in about 2010 2011
4:45 data science again showed up we got
4:48 past bi and advanced analytics and
4:51 that's when i got
4:52 back into the field i didn't know it was
4:54 called data science at the time there
4:55 were a bunch of us
4:57 doing it outside of silicon valley and
4:59 we all thought
5:00 something like then what's that remember
5:02 then data mining or
5:04 oh yeah data mining um we were doing
5:07 mapreduce
5:08 we were using we were using some of the
5:10 early google tools
5:12 depending upon a lot of the early papers
5:14 even back into the 90s there were a lot
5:16 of publications that we ended up using
5:19 and a lot of papers and thoughts from
5:20 the 90s and early 2000s that we ended up
5:22 implementing my first client was supply
5:25 chain
5:26 then i went into marketing and it kind
5:28 of snowballed from there
5:29 a lot of the early work was me having to
5:30 convince companies that there was value
5:33 in gathering data in a more
5:35 comprehensive way than just
5:36 bi and warehousing and that sort of
5:38 thing
5:39 and like i said it just took off 2015 i
5:42 had
5:43 fortune 100 clients people were bought
5:46 in at that point
5:47 and i've spent almost six years seven
5:50 years almost in
5:51 strategy for machine learning before
5:53 that i was published on things like
5:54 competitive intelligence
5:56 and competitive strategies so there's a
5:59 deep strategy background deep machine
6:01 learning and data science background
6:02 deep technical background
6:04 i got lucky that i got this whole
6:06 spectrum of
6:07 everything sort of over the course of
6:09 this 25 years
6:10 and that's what i'm working on now is
6:12 helping companies with strategy helping
6:14 companies with things like monetization
6:16 which we're going to get into path to
6:17 production
6:18 helping companies understand exactly how
6:20 to build products
6:22 and make money and generate revenue tech
6:25 from the technical side i work in
6:27 decision support decision science
6:29 i do that for c-suite
6:32 for actual strategy creation and
6:34 strategy planning
6:35 as well as some behavioral aspects that
6:38 work into marketing
6:39 and automated process
6:42 ml pro ml based process improvement
6:46 and so it's it's an interesting field
6:49 it's an emerging category
6:50 uh i'm kind of lucky i'll be completely
6:53 honest really lucky to be uh
6:55 where i am yeah i guess uh like
6:59 when it just started all this data
7:00 science people had no clue what it is
7:03 like and uh yeah being around that time
7:07 is really something that uh like a
7:10 luxury that people now don't have
7:12 somebody who wants to get into data
7:13 science because back then uh
7:16 like nobody had the clue and then it was
7:18 uh probably easier
7:19 to get into that field i don't know uh
7:21 you know it was interesting it wasn't
7:23 easier the it was easy to
7:27 be a data scientist it was really hard
7:29 to get people to
7:31 pay you to be a data scientist
7:34 because it wasn't popular right so it
7:36 became
7:37 more popular like maybe six years ago
7:40 right seven years ago
7:41 when it kind of boomed but before that
7:43 uh
7:44 yeah yeah right yeah so maybe uh
7:48 i have a few questions about your career
7:51 but maybe let's keep them
7:52 till the end because i really want to
7:54 get into the main topic of
7:55 monetizing machine learning so your head
7:58 linkedin headline says i monetize
8:01 machine learnings my machine learning
8:02 and i remember when i connected to you
8:04 on linkedin the first thing i asked you
8:07 about was what does it mean so
8:10 what is that what do you mean by i
8:12 monetize machine learning
8:14 well companies have different levels of
8:17 maturity when it comes to machine
8:19 learning so obviously i'm talking about
8:21 this broad spectrum of companies who are
8:25 either at the very early stages they
8:26 have data scientists and they
8:28 might have some prototype type projects
8:31 that have gone through the pipeline
8:33 they're in production all the way out to
8:36 companies that have done
8:38 advanced machine learning that actually
8:39 have products that are based around
8:41 models and no matter where you are in
8:44 the spectrum
8:46 there's this one common theme it is
8:48 revenue
8:49 and so companies are starting to look at
8:52 machine learning and saying okay this is
8:54 really expensive this is more expensive
8:57 than we thought the early companies that
8:59 are still doing prototypes are looking
9:00 at it from
9:01 a staffing perspective these engineers
9:04 are extremely expensive
9:05 they're now telling me i have to have
9:06 all these other different types of
9:08 products
9:08 to support machine learning and then you
9:11 have very very mature companies
9:13 who are looking at the cost to maintain
9:15 and deploy
9:16 high-end models these very very complex
9:18 models they're looking at that cost
9:20 and saying you know this just gets more
9:22 and more and more expensive as it's in
9:24 production so we need revenue
9:26 and so from both ends of the spectrum
9:28 you have companies saying
9:29 we need to make more money off of
9:31 machine learning so that's the core
9:33 driver
9:33 for monetization and what monetization
9:37 is
9:37 is teaching companies number one how to
9:39 become more mature
9:41 when they look at machine learning but
9:42 number two is to create
9:44 a strategy to handle everything from
9:48 research and
9:50 understanding how much value you can get
9:51 from research because that's the most
9:53 valuable thing a company can be doing is
9:56 creating research
9:57 doing research and creating artifacts
9:58 from that research
10:00 and then using it for project after
10:02 project product after product
10:04 in many cases they're defining new
10:05 categories and
10:07 evolving the business model in
10:09 interesting ways
10:11 the more mature they get with research
10:12 and the more they understand how to
10:14 monetize research and how to productize
10:17 models the more revenue they see coming
10:20 out of it and so that's monetization
10:22 it's this massive
10:23 really effort to take the business from
10:26 toy projects
10:27 or projects that to get into production
10:29 and then are very very expensive
10:31 and the returns sort of reduce over time
10:34 monetization is that process of taking
10:37 them out of sort of the machine learning
10:38 dark ages
10:39 and into a more modern way of
10:43 using these for products and
10:45 efficiencies
10:47 yeah so as i understood you just let me
10:49 summarize it quickly
10:50 so machine learning is expensive right
10:52 so first you need to pay people
10:54 people are expensive and especially like
10:56 we are talking about people with a
10:58 certain
10:58 skill set which is not easy to find
11:01 right so these people are expensive
11:03 and then once we get these people they
11:05 run all these gpus kubernetes clusters
11:08 and things like that
11:09 that are also expensive so expensive
11:11 people spend a lot of
11:12 money on expensive things right so we
11:15 need to somehow
11:16 uh warrant like in a way like uh
11:20 to say okay we keep these people because
11:22 they
11:23 generate these products that bring this
11:26 amount of revenue right so they're not
11:28 just burning money but they're being
11:29 doing something useful right and you do
11:32 that by coming up with a strategy
11:34 of different like finding okay what
11:37 should we focus on what should we do
11:39 to actually to show that these people
11:42 are not just
11:42 not just burning money but they're
11:44 bringing value um bringing value to the
11:47 company
11:48 right is it correct yes
11:51 and you know we can go into a little bit
11:52 more depth into each one of those areas
11:54 i wanted to give you the
11:55 all of the high points and i think we
11:57 can kind of explore
11:59 more of what this means not only from a
12:00 business perspective but also people
12:02 trying to get into the field what does
12:03 this mean for you what does this mean
12:04 for your career
12:07 and yes so we definitely will go
12:10 there but uh it's interesting to know
12:13 like how
12:14 uh how companies can actually evaluate
12:18 the value that data scientists can bring
12:20 and again
12:21 um coming back to your linkedin profile
12:23 so you bo mentions that uh
12:26 you built and brought products to market
12:28 with uh
12:29 a rr in the hundreds of dollars
12:32 hundreds of millions hundreds of
12:34 millions okay
12:35 hundreds of dollars they wouldn't pay me
12:36 very well for but
12:38 i i i to be honest like i think this is
12:41 a
12:42 an important uh like uh money related
12:44 metric
12:45 but to be honest i don't really know
12:47 what this r
12:48 a r r means like do i even pronounce it
12:51 correctly
12:52 and what is that no you did that's
12:53 perfect we've got an acronym soup and
12:56 strategy
12:56 and you know i'm building a strategy
12:58 course kind of on the side
13:00 uh that and one of the first things i'm
13:02 doing is building a glossary because
13:04 these terms are
13:05 you know if you're in data science
13:06 you're looking at these terms going what
13:07 are you talking about
13:09 because we have a totally different
13:10 language so arr
13:12 annual recurring revenue annualized
13:14 recurring revenue you'll
13:16 hear mrr monthly recurring revenue these
13:19 are
13:20 terms that the c-suite is going to
13:22 listen to
13:23 like my profile is very c-suite-centric
13:27 i look at board of directors and people
13:30 who are
13:30 ceo cto see ammo in a lot of cases uh
13:34 chief data scientists who are
13:37 you know product focused who are
13:39 revenues focused who are cost savings
13:41 focused
13:42 and so there is this rich acronym soup
13:45 just like there is in technology and
13:47 it's a different language
13:48 and a different way of speaking and
13:50 you're totally right if you come
13:52 from a data science background there's
13:54 this translation that needs to happen
13:56 between things like revenue and how
13:59 companies measure revenue and how they
14:01 talk about metrics and how we talk about
14:03 metrics
14:04 and the nice thing about data science
14:05 and machine learning is we do this
14:08 and ceos like that because they're used
14:10 to strategy consultants
14:12 and these large companies and i.t
14:14 services companies who come
14:16 in and it's hard to
14:19 sort of differentiate between what's
14:21 real and what's not for them whereas the
14:23 data scientists come
14:24 in and we have data we have results we
14:27 support our results
14:29 and so all you have to do
14:32 really to be successful with the c-suite
14:34 is understand their language and then
14:36 convert
14:37 our data bring our data into
14:40 their way of thinking and arr
14:43 those types of metrics are important to
14:46 understand
14:47 because now you're speaking a language
14:49 that is going to get you budget
14:51 and so that's why that's one of the
14:52 first things in my profile
14:54 is i build products with a an expected
14:58 return
14:59 which is going to be interesting and
15:00 significant to a ceo
15:02 and also is going to generate budget i'm
15:04 going to be able to justify budget
15:06 to a ceo because here is the potential
15:09 range
15:10 high expected and then under performing
15:13 where they can look at it and say okay
15:15 i'm going to spend 100 000 on this
15:16 project because i'm expecting
15:18 at the mid-range at least 10 to 12
15:20 million dollars
15:21 in annual revenue or something broken
15:24 down monthly if that's how they work
15:26 okay so basically the the this line in
15:29 in your biography in linkedin is
15:32 targeted
15:33 towards your potential clients this c
15:36 level people who find you in linkedin
15:39 and then say okay
15:40 this is the right person because he can
15:42 bring me
15:44 that amount of like he first of all
15:46 speaks my language
15:47 so like a r r this is something uh this
15:50 person understands so clearly
15:52 we will not have any troubles talking
15:54 right and then
15:56 yeah i see no um what are the other
16:00 important things that people uh
16:03 on this sea level like in high
16:05 management and top management
16:07 in addition to this uh annual recurring
16:09 revenue and monthly recurring revenue
16:11 what are the other money-related metrics
16:14 that they care about
16:16 every company is different and so you
16:18 have high-level metrics which are
16:20 important
16:20 across the board revenue and cost
16:23 savings
16:23 are your two drivers then you start
16:27 looking at business model
16:28 what is the business model and you're
16:30 not necessarily looking at a static
16:32 thing one of the large sort of themes in
16:35 strategy right now
16:36 is this concept of business model
16:38 innovation and
16:40 altering the business model for
16:43 adapting new technologies including
16:45 machine learning
16:47 and so every business now is coming to
16:49 terms with that that
16:51 business model innovation and trying to
16:53 figure out how they're going to change
16:54 their business model
16:56 and that's where you find the core
16:57 metrics that's where you find the types
16:59 of numbers
17:00 that are interesting to the company and
17:02 i again i say that this is a dense
17:04 acronym soup because it really is
17:07 and in every business you'll find
17:08 businesses talk about
17:10 strategy differently some when they say
17:12 strategy they really mean tactics there
17:14 are some businesses that are just
17:15 immature that way
17:16 and that's not a bad thing in every case
17:18 some companies are so focused on
17:20 execution
17:21 especially at a very very young phase or
17:23 a small company
17:25 that their needs for strategy are just
17:27 as big as any other company but the
17:28 maturity just isn't there yet simply
17:30 because they haven't
17:32 made it and so you have an entirely
17:34 different range of
17:35 tactical focused metrics for those
17:38 companies
17:39 whereas the more strategic company is
17:40 looking at a bit more of a long-term
17:43 view they're looking
17:44 at their product roadmap they're looking
17:46 for
17:47 efficiency type products which are going
17:48 to reduce the costs
17:50 of doing business which is going to give
17:52 them a competitive advantage
17:54 you're also looking at revenue streams
17:56 increasing their current revenue streams
17:58 by acquiring new customers producing new
18:00 products
18:00 that may create new revenue streams
18:03 pivoting their business model and
18:05 you're kind of hearing now i'm getting
18:06 more and more and more specific
18:09 and i'm going from the strategy realm
18:11 into
18:12 more of our realm we start talking about
18:15 products
18:16 and building models that are going to
18:19 line up with their core business metrics
18:22 and
18:22 and you really have to look at when you
18:24 when you're in a business
18:26 what do they care about what are they
18:27 talking to investors about the numbers
18:29 that are important will almost
18:31 always be in their quarterly reports
18:34 that's a really quick and easy way to
18:35 understand
18:36 the business that you're in or a company
18:38 that you're potentially looking at being
18:40 hired by what metrics are they
18:43 explaining to
18:43 investors what are they talking about in
18:45 press releases those are going to be the
18:47 core numbers that they're most
18:49 interested in and so that's how you
18:51 quickly understand the metrics that are
18:53 important to them
18:54 then you can start thinking okay is this
18:56 a data science problem
18:57 is this a machine learning problem how
18:59 do i now translate that
19:01 into my language and then using their
19:04 language using these
19:06 specific metrics that they talk to
19:07 others about
19:09 now i'm going to say my project can do
19:12 my project can improve
19:13 my project can change and you can start
19:16 talking about it from a business model
19:17 perspective
19:18 or a current business model perspective
19:21 and the metrics and goals that are
19:22 important
19:23 yeah i can immediately immediately see
19:25 how
19:26 being able to speak this language and
19:28 translate
19:29 this okay now i have a model with uh
19:33 auc 90 or whatever to
19:36 uh this arr of
19:39 some other number like this skill is
19:41 something that is
19:42 really valuable to convince the the
19:45 people who are actually in charge of
19:46 money
19:47 to give more money to give budget to the
19:50 machine learning team right
19:52 if you don't convince them if you fail
19:53 to convince them they will
19:55 not invest they will not invest money in
19:57 the team right they will say okay i
19:59 don't understand what you're doing
20:00 i don't see how important it is for our
20:03 business
20:04 then yeah maybe we should spend this
20:06 money on marketing or something else
20:08 right
20:10 then like what's the point of keeping
20:12 this people here right
20:14 and yeah coming back to our main topic
20:17 of
20:17 monetization roles um so
20:21 who should we have on the team to make
20:24 sure that
20:26 the projects we are working on they are
20:28 successful and monetizable
20:30 there are three real main areas that i
20:32 focus on you know we've talked about
20:34 strategy
20:35 so you need someone on the team who is a
20:38 strategist
20:39 who speaks both languages kind of
20:41 straddles both worlds
20:42 you need someone who understands like
20:45 we've been talking about we have this
20:47 language of
20:48 business which is very very revenue
20:51 focused very very cost savings focused
20:53 and then we have this language of
20:54 machine learning
20:56 and you have a role that is a machine
20:58 learning product manager
21:00 where this person is sort of the
21:02 crossover with
21:04 a strong strategy background but also a
21:06 strong machine
21:07 learning background so you need a
21:09 machine learning product manager
21:11 like we talked about also we mentioned
21:13 research being such an important part
21:16 of realizing revenue creating
21:18 competitive advantages
21:19 building a company that understands not
21:23 only machine learning but how they're
21:24 going to make money off of machine
21:25 learning
21:26 and how they're going to change the
21:28 business model in order to start
21:29 leveraging machine learning instead of
21:31 constantly keeping up and and trying to
21:34 chase after companies that are
21:35 bringing out market share that are
21:37 stealing customers away from them
21:39 and that's where the machine learning
21:41 researcher comes into play and you've
21:42 got
21:42 two different types of researchers you
21:44 have applied and you have science
21:46 the more mature a company is the more
21:48 they're going to
21:50 go into the science side true hard
21:53 science
21:54 research applied research is
21:58 still scientific you're still making
21:59 breakthroughs but it's very very focused
22:01 on
22:02 building like i do applied research i
22:04 don't have a phd
22:05 so i i could do science but i'm not the
22:08 right
22:09 person to and that's also important when
22:12 you look at these roles
22:13 a machine learning product manager could
22:15 spend a lot of time building models
22:16 but they're most valuable because they
22:18 also have that strategy side
22:20 we're seeing machine learning researcher
22:24 as an applied researcher i have more
22:26 value because my
22:27 science focus i have it but still i'm
22:30 far more valuable because i understand
22:32 how to apply
22:33 research and how to take something
22:35 that's new build it
22:37 and make money with it you also have a
22:39 machine learning
22:40 architect which encompasses the data
22:42 engineering machine learning engineering
22:44 and a lot of these roles
22:46 but they're more front end they again
22:48 have a
22:49 almost strategic role even though
22:51 they're very very hardware very
22:53 technical
22:54 very software development focused along
22:57 with having strong machine learning
22:58 skills
22:59 and so you have these three capabilities
23:02 in three roles who are going to speak to
23:06 the c-suite
23:07 create a connection between research and
23:10 strategy and that's your product manager
23:12 then you have your researcher who's
23:14 going to take that understanding of what
23:15 the business needs what
23:17 what kind of lines up with the business
23:18 model and start creating research that
23:21 results in artifacts that the company
23:23 can use over and over again
23:25 these become intellectual property and
23:28 can be reused from project to project to
23:30 project and drive
23:31 new products new revenue new
23:33 efficiencies for the business
23:36 and you have the ml architect who's
23:38 going to sort of
23:40 create part of the product roadmap that
23:42 explains exactly how expensive some of
23:44 these projects are going to be
23:46 and as part of that your researcher is
23:48 also going to
23:49 adopt their solutions because some
23:51 solutions
23:52 are viable but way more expensive than
23:55 other solutions
23:56 and so that sort of drives research from
23:58 more applied and practical standpoint
24:00 because your architect's going to say
24:01 look
24:02 yes you can do that but in a year this
24:04 is going to cost five
24:05 times what you know maybe you can figure
24:08 out
24:08 a better approach because this is going
24:10 to get expensive
24:11 you roll all of those roles together
24:14 and you now have this front of the
24:17 process that's connected to strategy
24:19 that is going to create a product and a
24:21 competitive advantage for the business
24:24 and now your more traditional roles
24:26 downstream can be
24:27 far more effective because a researcher
24:29 is going to hand these artifacts
24:31 off and your data scientists and your
24:34 machine learning engineers now
24:35 have a solid framework to begin from
24:39 they have a solid product from the road
24:41 map they have requirements they
24:42 understand the connection between
24:44 the business model and what they're
24:46 building
24:47 you have ml engineers who have a
24:49 long-term framework that they're
24:50 building out
24:51 what does this platform look like now
24:53 and what do we need it to look like in
24:55 two years
24:56 where is it going to go how is it going
24:58 to scale what are we going to support
25:00 coming up in the next couple of years
25:02 and so what kind of considerations do we
25:04 need to have
25:05 and you hear this more mature way and
25:09 far faster you build models and get them
25:11 into production
25:12 at a far faster cadence because you have
25:15 these upstream roles and that's a big
25:17 part of monetization is making sure that
25:18 these projects aren't wasted money
25:22 yeah so i just want to make sure i
25:25 understood so
25:26 like you mentioned three roles as you
25:28 mentioned
25:29 machine learning uh product manager to
25:32 somebody who thinks about strategy
25:34 and uh knows how to apply uh knows
25:37 machine learning then machine learning
25:40 researcher
25:41 there are two kinds applied and
25:43 scientist
25:44 somebody with a phd and then we have an
25:47 architect machine learning architect
25:50 who like can say okay this is too
25:52 expensive
25:53 and just thinks about implementation so
25:55 this is uh like an artifact from
25:57 researcher
25:58 and this is how we can bring into into
25:59 production so we have three roles
26:02 and then in addition to these three
26:03 roles we also have
26:05 more traditional roles like data
26:06 scientists machine learning engineer
26:08 uh maybe data engineer right and uh
26:12 so if i understood you correctly so we
26:15 already let's say we have a team we have
26:18 data scientists we have data engineers
26:20 we have machine learning engineers to be
26:23 better at monetizing their efforts their
26:26 projects we need
26:27 to add three more roles to the team or
26:30 maybe somebody in the teams can perhaps
26:33 play these roles right so this is like
26:35 something in addition to existing team
26:38 we can add three more i don't know not
26:41 people maybe three more roles
26:42 and then we become better at uh um you
26:45 know explaining
26:47 um how we earn money with machine
26:49 learning
26:50 right yeah i say three more capabilities
26:54 but that's yeah that's perfect
26:58 and then let's talk a bit more about
27:00 this uh
27:01 this first uh the the researcher machine
27:04 learning researcher
27:05 so we have applied research we have uh
27:08 yeah maybe let's talk about this this
27:10 person applied researcher
27:12 so what do they do so you mentioned that
27:15 they produce some artifacts
27:17 and so what are these artifacts what do
27:19 they produce
27:20 so the two main artifacts are your model
27:24 and research is really poorly understood
27:28 within the data science community you
27:30 have your applied researcher and you
27:31 have your science researcher
27:33 and so on two sides your main artifacts
27:36 are your models and your data sets
27:40 it's really important to understand that
27:41 a novel data set
27:43 is just as valid a an outcome of
27:46 research as
27:48 a new approach or a more accurate model
27:51 and what a researcher will do whether
27:54 applied or scientific and
27:55 you have to sort of parse these roles
27:57 based off of
27:58 where their focus is science researcher
28:01 is more
28:02 interested in creating an artifact
28:05 whether it be a model or a data set
28:07 that does not have a specific
28:08 application but simply lines up with the
28:10 business model or
28:11 a potential business model a pivot for
28:14 that particular business model
28:16 and it takes a more mature company to
28:18 understand how to
28:19 evaluate research pure science research
28:22 about some part of the business because
28:25 essentially what you're modeling is some
28:27 piece of the business
28:29 or some interaction between the business
28:31 and say customers competitors
28:33 some other portion of the market it can
28:35 be something like a supply chain
28:37 and that's what's being modeled a
28:39 scientist is going to do
28:40 a pure science project obviously with
28:44 data with machine learning
28:45 involved in it but what gets created the
28:48 business is going to have to look at
28:49 those artifacts and say okay now how do
28:51 we turn these into products
28:53 that's why it's a more mature business
28:55 because in many cases
28:56 you're creating a new category and in
28:58 machine learning this happens all the
29:00 time new categories
29:01 of product or just new categories in
29:03 general being created
29:05 the company then has to define that
29:06 category and figure out how to enter
29:08 that new market
29:10 or expand into
29:13 that market if they're already in it
29:15 your applied researcher
29:17 what's up i'm just thinking like what
29:19 kind of uh like
29:21 maybe you have an example like what kind
29:23 of category would it be
29:24 let's say if we take amazon or google or
29:27 some
29:28 like maybe um let's say google wants to
29:31 get into
29:32 a new market let's say develop a new
29:34 product would it be
29:35 a category uh or
29:38 for google they've they're going in two
29:40 different directions they are creating
29:41 categories and i don't think we've seen
29:44 google has a lot under the covers that
29:48 we just don't get to see we see these
29:50 small pieces of it in their open source
29:52 offerings and in some of their
29:54 some of their papers and so we don't
29:56 really know a lot of what's going on in
29:58 the covers
29:59 they've looked at things like healthcare
30:01 they've looked at finance
30:02 they've lowered fintech they've looked
30:04 at a lot of different spaces amazon's
30:06 the same way they just kind of abandoned
30:08 health care i don't think
30:10 health care is really ready for some
30:13 kind of
30:13 category right so amazon wants to get
30:16 into health care
30:17 and health care would be a category
30:19 right and then there could be a
30:20 researcher
30:22 like a scientist somebody with academic
30:24 background who can think okay
30:26 i know what are the goals of the company
30:29 right i know what is the business model
30:32 i know what the company wants to do and
30:34 this is the area where the company wants
30:36 to do
30:36 and the task of a researcher is to
30:39 figure out
30:40 how they can do this right like
30:41 experimental how do they do it in a
30:43 different way
30:44 because in a lot of cases you're
30:45 entering a crowded field fintech's a
30:46 crowded field
30:48 healthcare is a crowded field and what
30:50 you'll see companies do
30:51 is kind of two things and bring up
30:53 amazon because they killed
30:55 a project in a lot of cases this is what
30:57 happens with science
30:58 you have to have a company that's mature
31:00 enough to monetize science
31:02 and real data science research you know
31:04 the big
31:05 big r type of research and in some cases
31:09 that means killing projects because
31:11 you get to the end of the road and
31:12 there's just been nothing produced
31:14 there's nothing valuable you can't find
31:16 anything to productize or monetize
31:18 and so you try to expand into a space
31:20 and you say okay this is a failed
31:21 experiment
31:22 but the company understands because they
31:25 understand monetization
31:26 that that little failure is worth it
31:29 because if they do 10 failed projects
31:31 and one of them is a success
31:33 the roi of that success is huge because
31:36 now they're entering a new market
31:38 and so what amazon was trying to do was
31:40 figure out if they could define a new
31:42 category within healthcare
31:43 and they failed whereas you see in other
31:46 cases where
31:48 they you know went into services like
31:51 aws is a great example of them creating
31:53 a new category
31:54 where nobody was there before this and
31:56 now
31:57 they've also created categories around
31:58 machine learning and your ml ops they
32:01 were one of the early
32:02 sort of providers for ml ops type
32:05 software
32:06 they created a category and now you're
32:07 seeing a lot of people rush into that
32:09 category
32:10 and that's more of your applied
32:12 researcher side of the the world because
32:14 there wasn't really a whole lot of
32:15 science to do there
32:17 it was simply amazon looking at a
32:18 problem that they had in house and
32:19 saying
32:20 a lot of people are going to have this
32:22 problem so now this is a
32:23 product and so that's your artifact for
32:26 an applied researcher is someone who's
32:28 looking at a new category and saying
32:31 we can actually build this because we
32:33 already have it and we just need to
32:35 scale it
32:36 and offer it up to cli you know offer it
32:38 up to customers
32:39 you've got a pdm who's going to say this
32:41 is the business model
32:43 you know this is the business model we
32:44 could get into and this is the pricing
32:46 that we could support and again it's
32:47 that strategy side
32:49 overlapping with research when you talk
32:51 about creating a new category
32:54 now you're talking about a product that
32:56 maybe has never existed or can't
32:58 exist without the model itself or
33:00 without some sort
33:01 of machine learning driving and running
33:04 it
33:04 and that's what you're looking at when
33:06 you start talking about new categories
33:07 and defining categories
33:09 is something like uber without machine
33:11 learning it wouldn't
33:12 it simply wouldn't be as efficient as it
33:15 is
33:16 and the same thing with a lot of these
33:17 new online startups they're creating new
33:19 categories because they can use machine
33:21 learning and they can monetize machine
33:22 learning
33:23 as a core piece of their business model
33:25 the machine learning first
33:27 that's where a lot of the research piece
33:29 comes into play
33:30 and that's where defining a new category
33:32 as a result of machine learning comes
33:34 into play and those are the artifacts
33:36 that you see
33:37 when you look at a stitch fix another
33:39 great example of a company which is
33:41 machine learning first and creating a
33:43 new category that
33:45 product existed in the past but not in
33:47 the way that they've been able to
33:49 redefine it
33:50 and so they have redefined the category
33:52 and entered a new market because they
33:54 have that machine learning there
33:56 and how about what about companies that
33:58 are
33:59 let's say it's small startup they just
34:01 appear so like
34:02 not as ambitious like they don't want to
34:04 be second google they don't be second
34:06 amazon they just found a small niche
34:08 they think they can make a difference in
34:10 this niche
34:12 so how about them do they even need this
34:15 kind of role
34:16 for them and if they need like maybe
34:19 i guess they also need to be at some
34:21 point of maturity to think about this
34:24 role right or it's uh
34:28 it's different well i say this a lot um
34:31 angry users and data scientists create
34:34 startups
34:35 because in a lot of cases you know that
34:37 niche that you're talking about
34:39 it's a niche because there's no product
34:41 there
34:42 and you have an angry passionate user
34:44 base who's saying
34:46 everything we do is bad everything we
34:48 have is not a solution to my problem
34:50 this just doesn't work
34:52 and you have this very very angry user
34:54 base who
34:56 angry user bases are willing to spend
34:58 money
34:59 and so if you can as a data scientist
35:02 pair up
35:03 with an angry user who really
35:05 understands the need
35:06 who has a connection to that market who
35:08 understands
35:09 a lot of the business side of how you
35:12 would get into that market what the
35:13 product would need to look like
35:15 what problems it needs to solve who the
35:17 most passionate
35:18 people within that you know problem
35:20 group within that angry user group
35:22 are and then you have a data scientist
35:24 that looks at it and says oh yeah i can
35:26 solve this problem this is a machine
35:27 learning problem
35:28 and i can create a novel solution even
35:30 in a startup those
35:31 two people by themselves can create and
35:34 define a new category for everything
35:36 from a niche to
35:37 a massive market and like i said that's
35:40 how the best
35:41 startups are founded is an angry user
35:44 meets a data scientist and they get
35:46 together and have a bright idea and
35:48 build something
35:49 and if you even as a two to five person
35:53 startup
35:54 can do that and can tap into a market
35:56 and understand how to define that new
35:58 category you can make a lot of money and
36:00 the machine learning researcher
36:02 is your first or second hire their
36:05 co-founder
36:06 okay so big small it works across the
36:08 board
36:09 so um yeah so basically this capability
36:13 of machine learning researcher
36:15 so it could be a data scientist right so
36:17 it doesn't have to be somebody coming
36:19 from academia with
36:20 all this uh you know publications at top
36:23 conferences
36:24 phd it can be just a simple data
36:26 scientist who
36:27 has experience working at different
36:29 startups who knows how to process data
36:32 who knows how to i don't know train a
36:33 circuit learn model
36:35 uh am i right or there are some other
36:37 things that
36:38 let's say an average data scientist
36:40 needs to become
36:42 to to you know to to wear this heart of
36:46 ml researcher uh an average data
36:49 scientist i think we kill
36:51 the data science job title and try to
36:54 spread it
36:55 you know across it's like peanut butter
36:57 and and we're trying to spread it across
36:59 a 10-foot wide
37:01 piece of toast it just doesn't we can't
37:03 do it anymore
37:04 and so when i say researcher i mean
37:06 someone who understands
37:08 research the big r in software used to
37:11 have this
37:12 concept of big r research which
37:15 now in machine learning is a whole lot
37:17 more applicable because there's real
37:19 research that needs to be done there's
37:20 experiments that need to be
37:22 done and i talk about this process where
37:24 you start out with data
37:25 it's data you can't rely on it's garbage
37:28 it doesn't truly represent what you
37:30 think it does
37:31 and that first model that you build
37:32 based on that data is a hypothesis
37:35 this is how you think what it is that
37:37 you are modeling
37:38 actually works this best guess and
37:41 depending upon how well you can support
37:43 that hypothesis you should either go
37:45 forward
37:46 and keep working that direction or maybe
37:48 go back and rethink things
37:50 gather data in a smarter way based off
37:52 of what's wrong with your initial
37:53 hypothesis
37:55 that's research and now you create an
37:57 experiment
37:58 to once you have something that's solid
38:00 once you have a hypothesis that you can
38:02 support that initial model
38:04 is something that you can support with
38:06 data with performance in some cases you
38:08 test it alongside something else in
38:10 production and you say i see an
38:11 incremental improvement here
38:13 i see something interesting in this
38:16 particular
38:17 model and that's where a lot of the
38:19 automation software and workflow
38:20 automation
38:21 software comes in is taking your data
38:24 creating multiple models based off of it
38:27 and then displaying information to you
38:28 as a researcher where you can look at it
38:30 and say that's
38:30 okay that's interesting that right there
38:33 is interesting and now i want to pull
38:35 that model back
38:36 and understand how that model works
38:38 because there's something about it
38:39 some piece of that model's functionality
38:42 and this is where you get into
38:43 explainability
38:44 and sort of deconstructing your model to
38:46 understand how each feature works
38:49 in order to create a better outcome and
38:51 typically these models
38:52 reveal something about a system that you
38:54 didn't understand from the beginning and
38:56 so that
38:56 initial model that you create based on
38:59 your hypothesis and maybe this
39:01 iterative process that you do as
39:02 secondary tertiary hypotheses
39:05 you now go back and you say okay there's
39:06 something interesting here
39:08 that i've discovered and that's research
39:10 and you create an experiment to either
39:12 sort of refute or confirm that you found
39:16 something interesting and that model is
39:19 now giving you data about the thing you
39:21 want to
39:21 actually model that hypothesis and that
39:24 experiment and the results
39:25 that's research now i've gotten some
39:27 sort of tangible result about what it is
39:29 that i'm trying to
39:30 model and so i have a better
39:32 understanding of what data i need to
39:34 gather
39:34 i have a better understanding of how my
39:36 next iteration of models should look
39:39 i have a better understanding of an
39:42 additional experiment
39:43 to now discover more is there more
39:47 here is there more to go into and
39:50 understand
39:51 how this particular system works based
39:53 on my discovery and this is what you
39:54 find a lot this is the iterative process
39:56 of research
39:57 most data scientists don't understand
39:59 this they're stuck in statistics
40:01 and you hear this a lot people who talk
40:03 research will have people say oh you
40:05 don't understand statistics
40:06 it's like no you don't understand
40:08 research that's not it's not
40:10 all statistics yes we use statistics
40:12 heavily
40:14 it's a heavy part of research and
40:15 experimentation and exploring your data
40:17 and understanding your results and
40:18 trying to support them
40:20 but that's not everything there's way
40:22 more to this
40:24 and sometimes the statistics pushes us
40:26 away
40:27 from actual research we get statistical
40:30 results and statistical models
40:33 but that takes us away from the thing
40:35 that we're actually trying to model and
40:37 simulate and understand
40:39 and so that's the research side of this
40:41 anyone can be a researcher i mean i
40:43 don't have a phd
40:45 so anyone can get into the research side
40:48 of this but you need a strong
40:49 solid science background the only way i
40:52 got it
40:52 is early on my models got destroyed by
40:56 hardcore scientists
40:57 they looked at my models and they said
40:59 okay you've supported them with
41:01 statistics
41:02 here let me destroy your model now
41:04 because you're not using
41:06 any of the metrics that really matter
41:07 you're not modeling anything except for
41:09 the data
41:10 all you've produced for me is a
41:12 representation of the data in a
41:14 different
41:14 form that's worthless and i got taught
41:18 the process by some very
41:20 very smart and somewhat abrasive people
41:24 who gave me honest feedback and that's
41:26 what it takes to get into the research
41:28 side that's what it takes to move from
41:29 data scientist which like i said it's
41:31 kind of overextended
41:32 into a more rigorous research
41:36 role so it's more like a mindset right
41:39 so like
41:39 as i understood so what uh what the
41:42 researcher needs to know is they need to
41:47 be able to create come up with
41:50 hypotheses
41:51 they need to be able to test this
41:53 hypothesis to verify them or
41:55 reject them by experimenting they also
41:58 need to be able to do some sort of data
42:00 analysis
42:01 and first of all to understand that the
42:02 data is not garbage but then also
42:04 understand the results of uh
42:06 like kind of the drill like
42:09 go into the results of the model and
42:11 understand okay
42:12 why the model is behaving in a certain
42:15 way and
42:17 explain the why the model is doing that
42:20 and these are the core skills right and
42:21 then the the main thing
42:23 is the mindset okay i have a hypothesis
42:25 i want to
42:26 test it i want to to try to verify it or
42:29 reject this hypothesis
42:31 and this is where statistics also kind
42:33 of comes in uh
42:34 into play because this is one of the
42:36 tools you used actually to reject the
42:38 hypothesis right or
42:40 um yeah to verify it and then also where
42:43 more of the advanced
42:44 math comes in too people ask why you
42:46 need to understand differential geometry
42:48 why do you need to understand topology
42:49 why do you
42:50 need to understand some of these deeper
42:52 concepts
42:53 around graph theory in some cases you
42:55 know you can get very very niche
42:58 with the type of math that you need to
42:59 understand in order to explore your data
43:01 in order to come up with experiments
43:03 and that's part of the skill set is
43:05 really understanding how to creatively
43:08 build an experiment that's feasible
43:10 affordable
43:11 and then will probably get you the
43:13 results that you're looking for
43:15 get you a better understanding of what
43:16 it is that you're trying to model
43:18 so it's not only a mindset it's also a
43:20 skill set it is a capability to do
43:23 more of the science side of the field
43:27 yes we also need to cover i just looked
43:29 at the time and notice that
43:31 we still want to cover the the other two
43:34 roles
43:34 and we already talked about like this
43:37 niche angry users
43:39 and pairing with data scientists but i
43:41 guess this is where the role of a
43:43 machine learning product manager
43:44 uh appears right so this is somebody who
43:47 can actually
43:49 correct me if i'm wrong but i'm just
43:50 making assumption that
43:52 like when a user talks to a data
43:54 scientist they do not necessarily
43:55 understand
43:56 them right the data scientist doesn't
43:58 always understand that so this is one of
44:00 the things that a product manager does
44:03 and what i guess there are other things
44:04 that they do so maybe you can
44:06 talk a bit more what what kind of work
44:08 they do
44:09 so the product manager is going to have
44:11 to address a
44:13 wide range of audiences and this is one
44:14 of the reasons why they need to also
44:16 have a machine learning skill set
44:18 it's because they have to speak to a
44:20 machine learning team
44:22 and convey to that team and sometimes
44:25 it's a researcher sometimes it's an
44:26 architect
44:27 sometimes it's your more traditional r d
44:30 and dev
44:31 machine learning teams your model
44:32 development teams they have to speak to
44:35 them in their
44:36 language they can't be speaking in sort
44:37 of this abstract
44:39 you know fuzzy type of language they
44:42 have to speak about models they have to
44:43 be able to understand it
44:45 but then they also have to be able to
44:46 talk to users to get requirements and to
44:48 make sure that the users are able to
44:50 articulate
44:51 their needs because most most users
44:54 can't do that
44:55 in terms of a machine learning solution
44:57 or a data science solution
44:59 they don't understand what's possible
45:01 and a big part of what the product
45:03 manager does
45:04 is tells the c-suite this is possible i
45:07 listened into
45:08 your strategy planning and i heard
45:12 three or four different problems that
45:14 i've done a little back you know
45:15 back-end work and built you a very rough
45:18 business case
45:19 and this is exactly what i think we can
45:21 do in order to
45:23 solve some of these problems using
45:25 machine learning
45:27 and now what i need to do is give it to
45:28 a researcher to prove that we can
45:30 actually do this and that's where the ml
45:31 architect and the ml researcher come
45:33 into play
45:34 is that product manager has enough
45:36 understanding of user needs and user
45:38 requirements
45:39 and strategy listening in again to the
45:41 the planning process hearing business
45:43 problems hearing goals
45:44 and being able to then write a business
45:46 case saying with my knowledge of machine
45:49 learning
45:49 i i'm very sure that if i give this to a
45:52 researcher
45:53 this is something that we can solve
45:55 better
45:56 with machine learning than we could with
45:58 a traditional software approach or
46:00 whatever we're using right now
46:02 and that's the product management role
46:04 is being able to be that translator
46:06 create the initial business case frame
46:09 and reframe the business problem
46:11 gather requirements and work with users
46:13 sort of through the whole
46:15 life cycle and connecting all these
46:18 other groups
46:19 into the product development process
46:22 and then passing all this over to the
46:25 teams that are going to be responsible
46:27 for
46:27 researching and architecting it and
46:30 actually building deploying and
46:31 supporting it
46:32 and then also create a gated process
46:34 where that pdm is reviewing
46:36 at gates at particular checkpoints
46:40 or at achievement points i'm trying to
46:43 define this better management sort of
46:45 thing right like basically
46:47 making sure that the project gets
46:48 delivered no that's and that's one of
46:50 the key differences the project manager
46:52 is making sure the timeline is in place
46:54 the product manager is making a kill
46:56 or green light decision where they look
46:59 at the progress
47:00 with respect to the business is this
47:02 returning the value is this worth
47:04 investing more money in
47:06 it's almost like in academia you have
47:07 the grant and funding process
47:10 where you you sing for your supper every
47:12 quarter or every year
47:13 to try to get more grant money and the
47:15 product manager is really the one who
47:17 evaluates whether i should continue as a
47:20 business to fund you
47:21 whether i should go back to the c-suite
47:23 and say yeah this is worth another x
47:24 amount of money
47:26 because we've made tangible progress
47:27 here's what we've built here's what
47:29 we've done
47:30 here's why i think we should get funding
47:32 for
47:33 an additional round of research or why i
47:35 think we should put it on the roadmap
47:36 the product roadmap and go
47:38 forward with it and so they're in charge
47:39 of that gated process not so much
47:41 deadlines
47:42 but deliverables but that's a lot of
47:45 responsibilities right so they need to
47:47 talk to a user
47:48 and translate the requirements of a user
47:51 like translate
47:52 whatever user is saying do a bunch of
47:54 requirements to set of requirements then
47:56 they need to work with
47:58 researchers and kind of help them well
48:00 first of all they need to know like if
48:02 it's at all possible to solve it with
48:04 machine learning
48:05 right even before talking to researchers
48:07 then they need to talk to the
48:08 researchers and translate the needs of a
48:10 user to the researcher
48:12 and then they also need to talk to the
48:14 c-level people
48:15 and then translate this whatever
48:17 researcher did
48:19 in terms of like i don't know they may
48:21 be uh did some machine learning and then
48:23 they need to come to the
48:24 ceo and say okay this should result in
48:27 uh
48:28 whatever letter soup like metric like
48:31 a arr or mrr or something
48:34 else that the company cares they need to
48:36 know all that
48:37 am i correct yes that's that's like
48:40 product managers even in traditional
48:43 software development product managers
48:45 are they're the apex predators of
48:48 the business world because they are
48:51 engineer strategists
48:53 yeah it's like one single person or
48:54 maybe like it feels like a team of uh
48:56 of people it can feel that way the way
49:00 that it
49:00 ends up working is you have a product
49:02 manager who has all of those core
49:04 capabilities
49:05 and they'll rely on there's a
49:06 traditional requirements team you'll
49:08 have
49:08 technical writers and requirements
49:10 gatherers business analysts
49:13 who do the requirements gathering but
49:15 they need the product manager in order
49:16 to guide them
49:17 and help them understand what
49:19 requirements are they actually gathering
49:20 have they been written up correctly has
49:23 have the user needs actually been
49:25 captured so they're not personally
49:27 writing up the requirements when they
49:28 write up a business case
49:30 a lot of that business case is already
49:32 there other groups that are
49:33 interested in solving that problem have
49:35 presented a lot of the background
49:36 research
49:37 have done a whole lot of the legwork
49:38 around the business case and now what
49:40 the product manager is really defining
49:42 is how are we going to use machine
49:44 learning from a
49:45 proposal standpoint this is how i
49:47 propose us to use it
49:49 now they're giving that to a researcher
49:50 and saying hey is that you know
49:52 am i right is this something that we can
49:54 really do
49:55 did i nail it here and the researcher
49:57 will typically
49:58 then have this little bit of funding
50:00 from the c-suite who've seen the
50:02 business case we've seen this proposal
50:04 and said yeah i'll give you some funding
50:06 to do a two-week exploratory on this
50:08 and then the researcher will come back
50:09 and it'll be basically a feasibility
50:11 study
50:12 is this something you can do do i think
50:14 that you're right as a product manager
50:16 so you're right there's this ecosystem
50:17 around the product manager and the ml
50:19 architect gets involved as well
50:21 because they're looking at that proposal
50:22 and feasibility study from
50:24 a path to production standpoint from a
50:26 support standpoint
50:27 and then you've got another layer of
50:29 well yes this is a brilliant solution
50:31 great job scientist but here's what it's
50:32 going to cost here's what it looks like
50:34 if we actually put it into production
50:36 and so you're having a lot of different
50:38 roles being relied on
50:40 in order to support your product manager
50:42 but yes the product manager has
50:44 a significant skill set and a very deep
50:47 understanding not only the technical
50:49 side
50:49 but also of the business side and
50:52 basically they need to be able to
50:55 to communicate with people who are who
50:57 are collecting requirements who are
50:59 building the models who are
51:01 i don't know like this well architect
51:03 for example
51:04 and they need to be able to speak the
51:06 same language with them and
51:07 if need be they also can go ahead and
51:11 do this themselves but they typically
51:13 don't right usually they're like on a
51:14 higher level
51:15 uh and sort of more coordinating than
51:18 hands-on
51:19 right these are typically former data
51:21 scientists former ml engineers
51:23 they come out of that but they've also
51:25 spent enough time a lot of them come out
51:26 of startups because in a startup you're
51:28 really forced to do
51:30 product management and also
51:33 data science and machine learning and a
51:35 little bit of research in there too
51:37 and so you'll see these people coming
51:38 out of uh startups in a lot of cases
51:41 because they were forced to be unicorns
51:43 and they have just enough understanding
51:45 that they can quickly be upskilled
51:48 within the business to do
51:50 a larger range of activities and so the
51:53 product manager is not necessarily going
51:55 to be the person that builds anything or
51:57 prototypes anything
51:58 they're simply going to present the
51:59 problem in data science and machine
52:01 learning terms
52:03 so that a researcher more than them
52:04 telling researcher hey do this
52:06 it's more the research you're telling
52:08 them okay based on what you told me
52:09 about the problem
52:11 i think i can do this you know and
52:13 here's my proposal
52:15 and again very similar to an academic
52:17 model where they say here's my proposal
52:19 for what i'm going to do research on
52:21 what do you think the product manager
52:23 can then talk to the architect who says
52:25 okay based on that proposal here's what
52:27 it would take here's what i have to
52:28 build in order to support this
52:30 long term you know here's the
52:32 architecture and infrastructure i'd have
52:33 to build
52:35 what do you think and now the product
52:37 manager goes back
52:38 and handles that roi calculation so it's
52:40 really
52:41 them talking to the product manager the
52:44 product manager is doing a translation
52:45 to machine learning terms
52:47 and data science terminology but at the
52:50 end of the day
52:51 it's technical folks driving that
52:54 conversation about technical topics
52:56 so the product manager isn't the sole
52:59 technical owner of this they aren't the
53:02 technical
53:02 lead they're the business lead but like
53:06 i said they have to understand what
53:08 the researcher the architect the
53:09 developers and the engineering side are
53:12 telling them that's why you have to have
53:14 the skill set
53:16 so we already mentioned that so that
53:19 two usually data scientists and machine
53:22 learning engineers become
53:23 this like
53:26 product managers and typically they come
53:29 from startups
53:30 um but can usual product managers that
53:33 work in 80 companies
53:34 they they probably also have quite good
53:37 background to
53:38 to kind of become machine learning
53:41 product manager
53:42 right i've seen people try it with mixed
53:45 results
53:46 and depending upon how technical the
53:48 product manager is okay so they have and
53:50 what their background is
53:51 sometimes you'd be surprised somebody
53:52 with a background in economics does
53:54 very very well in the machine learning
53:57 world because
53:58 like i said you'd be surprised how much
54:01 you learn
54:02 that relates to machine learning from an
54:04 economic background from a hardcore econ
54:07 background
54:07 and so there are success stories
54:09 depending upon what the background of
54:11 the product manager is and how
54:13 deep they got into their you know
54:16 the technical side of it understanding
54:18 the platform
54:20 but also understanding it from a science
54:21 side and from a model development side
54:24 so you can upskill a product manager
54:26 into a data science
54:28 machine learning product manager role
54:30 but it really depends on their
54:31 background
54:32 in some cases project managers become
54:34 product managers
54:36 they're semi-technical and it's really
54:39 understanding how
54:40 well they're going to learn the data
54:42 science and machine learning side that
54:44 will
54:44 determine whether or not they're going
54:46 to be successful
54:49 yeah like i noticed that this product
54:51 manager person like he kind of is in the
54:53 center of
54:54 uh like the communication cup in a way
54:57 but
54:57 uh then like there's also this machine
54:59 learning architect
55:00 that we um we didn't talk in details
55:04 about
55:04 like from what i understood so far so
55:06 this is a person who
55:08 can like who looks at the proposed
55:12 solution
55:13 and then kinda first of all can
55:14 understand if it's
55:16 possible to implement at all or not and
55:19 then if it's possible they can also
55:21 attach
55:21 a price to this they can say okay like
55:23 if you want to go with this model
55:25 this is how much is going it's going to
55:27 cost you right
55:29 and then like i said okay this is too
55:30 much we probably need to
55:32 to do something simpler and then they
55:34 come back to maybe
55:36 do researchers and say yeah let's do
55:39 something simpler
55:40 right did they get it right that's
55:42 absolutely correct
55:44 the way that an architect provides value
55:47 is creating the larger vision for the
55:49 platform
55:51 based on the business needs and then the
55:54 platform becomes part
55:55 of the product roadmap that's the really
55:58 important piece of what an ml architect
56:01 does and you see this in
56:02 cloud architecture you see this in
56:04 software architecture as well
56:06 this concept of creating platform to
56:09 not only enable development so that
56:12 we've
56:13 automated as much of the development
56:14 process and the research process and the
56:16 experimental process as possible
56:18 but also now we need to create a path
56:21 for this model to get
56:22 into production and then be supported
56:25 and the ml architect
56:26 understands platform well enough
56:30 to say okay i'm looking at user
56:32 requirements i'm looking at business
56:33 requirements i'm looking at customer
56:35 requirements
56:36 i'm looking at what we have in
56:37 production right now and what platforms
56:39 we have in production right now
56:41 i'm looking at the scale of data that's
56:42 being proposed from
56:44 a research standpoint extrapolating out
56:46 exactly what this would look like in the
56:48 real world how much
56:49 you know as the streaming is this batch
56:51 what do we have right now
56:52 from a platform standpoint that can
56:54 support this internally
56:57 do we have something another team is
56:58 using that we can repurpose do we have
57:00 infrastructure already built out for
57:02 this can we do something on premises
57:04 or does this need to go to cloud is that
57:06 even feasible
57:07 you know because you have an architect
57:09 who's going to say look
57:10 yeah it's nice to say we're going to go
57:12 to on-prem we're going to go to cloud
57:13 we're going to go hybrid or we're going
57:14 to implement
57:16 you know kubernetes or we're going to
57:18 implement you know
57:19 it's great to say that but now let me
57:21 tell you what it's going to take to
57:22 actually do that
57:23 and how much it's going to cost and when
57:26 you start talking about it's in
57:27 production what is it going to cost to
57:28 maintain this thing
57:30 because a lot of models are very very
57:31 cheap to make
57:33 and after three or four months in
57:36 production they have to be continuously
57:38 retrained
57:39 so much that it's too expensive is this
57:42 hidden
57:43 you need to mature to overcome the
57:46 problem of retraining to actually
57:47 build a more efficient model that
57:50 performs better on the classes
57:51 and the regions and scenarios that the
57:53 business is most interested in
57:55 and again back to the product manager
57:56 they need to define that
57:58 so that the researcher and the architect
58:00 can do their job
58:02 yeah so what the skills they need to
58:06 have
58:06 is they need really they really need to
58:08 know well the tools
58:10 so probably they need to know cloud they
58:12 need to know like what are the
58:14 other other tools and then knowing the
58:17 scale of the problem knowing the
58:18 requirements
58:19 they can come up with a suggestion let's
58:21 say if we use cloud
58:23 and we can go with aws or google cloud
58:25 and then
58:26 these are the services from aws that we
58:28 can use
58:29 to solve this particular problem right
58:31 because we need to build this data
58:32 pipeline we need to store this data
58:34 somewhere we need to
58:35 then have this machine learning platform
58:38 that makes it simpler for
58:40 the researchers to deploy the models and
58:42 then they basically take care of all
58:44 this tooling that makes it
58:46 really easy for these researchers to
58:49 to roll out the things to production
58:51 right well and give it to the model dev
58:54 team because you have your research team
58:55 at the front
58:55 end they're going to create artifacts
58:57 like i said and those artifacts are
58:58 going to go
58:59 to a team who's going to use them to
59:01 create products
59:02 that you know for sale for efficiencies
59:04 that make things in the business run
59:06 better
59:07 and so the ml architect understands you
59:10 know clark
59:10 cloud architect is a very very good sort
59:13 of traditional role to look at and say
59:15 okay very similar
59:17 but more focused on the machine learning
59:19 side of
59:20 cloud architecture and in a lot of cases
59:22 the business already has
59:24 infrastructure in place and so the ml
59:26 architect is looking at
59:27 the infrastructure that's in place not
59:29 necessarily designing from scratch in
59:31 every
59:31 in every scenario they're looking at
59:33 what's in place and they're saying okay
59:34 what do we
59:35 you know what can we repurpose to do
59:37 what we need to
59:38 in order to support the products that
59:39 could come out of this research
59:42 is there's thing are do we have to do
59:44 anything can we just deploy on what we
59:45 have
59:46 what is it going to take for the team
59:47 responsible for deploying this
59:49 to rebuild whatever it is that we may be
59:52 incorporating into from an existing
59:54 product standpoint
59:56 what are we going to have to do in order
59:57 to support it what's new that we might
59:59 have to do to support
1:00:00 it and in some cases they'll make a buy
1:00:02 decision well they'll say okay we we
1:00:03 need platform but there's
1:00:05 you know there's a couple of product
1:00:06 solutions out there and we can buy and
1:00:08 it's cheaper
1:00:09 and if i look at the roadmap this buy
1:00:11 will also support
1:00:12 this product this product this product
1:00:14 in this project so
1:00:16 you know it right now for this project
1:00:18 alone it wouldn't make sense
1:00:20 but we're going to have to do something
1:00:21 for these three other projects anyway so
1:00:23 now it's justified from a cost
1:00:25 standpoint that's why the architect's
1:00:27 important because the architect can look
1:00:28 at a longer term vision
1:00:30 and say yeah this seems expensive today
1:00:33 but over a year over three years this is
1:00:35 going to seem a whole lot more
1:00:36 reasonable and we're going to have to go
1:00:38 this way anyway
1:00:40 so from what i understood like talking
1:00:42 about all these three roles
1:00:44 researcher architect and product manager
1:00:46 all these
1:00:47 uh like people who perform these
1:00:51 things perform like wear these hats they
1:00:53 already they are
1:00:54 quite experienced already right so they
1:00:56 probably worked already
1:00:57 like as cloud architects as software
1:00:59 engineers as
1:01:00 uh product managers as machinery
1:01:02 engineers
1:01:04 so and then this is like they have to be
1:01:06 pretty experienced
1:01:07 to be able to do these sort of things
1:01:09 right
1:01:10 or like can somebody like let's say a
1:01:12 fresh graduate
1:01:13 uh come and start working as a machine
1:01:16 architect
1:01:17 probably not i don't believe somebody
1:01:18 without experience it would be like
1:01:19 saying somebody without experience
1:01:21 could become a software architect um
1:01:24 maybe
1:01:25 i don't think so um you know or cloud
1:01:28 architect
1:01:28 maybe i don't i don't think you can
1:01:30 really step into that role
1:01:32 you can step onto an architecture team
1:01:35 you can walk on
1:01:36 as someone who's part of the team who's
1:01:39 a junior level
1:01:40 person on the team who's more hands-on
1:01:42 more like a machine learning engineer or
1:01:44 a very junior machine learning engineer
1:01:46 especially if you have a software
1:01:47 development background or some other
1:01:49 type of
1:01:50 architecture background and you're
1:01:52 upskilling into the role you can be very
1:01:54 very successful
1:01:55 because a lot of software engineering
1:01:58 best practices
1:01:59 are finding their way into machine
1:02:01 learning engineering machine learning
1:02:03 architecture and the more traditional
1:02:05 sort of what falls under the the better
1:02:07 known data scientist
1:02:09 model development type of roles
1:02:12 and so you can be successful coming into
1:02:15 one of those teams and being a
1:02:16 contributor
1:02:17 pretty early on but you do have to have
1:02:19 some experience
1:02:21 with architecture software development
1:02:23 best practices
1:02:24 of software engineering and eventually
1:02:27 transition into the ml architect role
1:02:30 it's not something that you should be
1:02:32 pushed out of or that you can't upskill
1:02:34 into but it's a longer journey
1:02:36 same thing with a researcher you know
1:02:38 it's not something that a data scientist
1:02:40 can't do you can come out of a master's
1:02:42 or phd role
1:02:44 having some experience in academia doing
1:02:46 publications or just doing applied work
1:02:49 and transition into a researcher role
1:02:52 so you can be successful coming out of
1:02:54 academia you can be successful coming in
1:02:55 from a research assistant or one of
1:02:57 those types of roles
1:02:58 it's not necessarily barricaded and
1:03:02 you know exclusionary but it's a longer
1:03:04 learning process than you would expect
1:03:07 for something like a data scientist who
1:03:08 you can train up pretty quickly
1:03:11 yes indeed and we talked about the posts
1:03:16 you made like when you made the
1:03:17 announcement and
1:03:19 one of the things you wrote there the
1:03:21 data science programs are still teaching
1:03:23 unicorn curriculum and producing people
1:03:25 with six inches of depth across
1:03:28 six different roles uh but data science
1:03:31 and machine learning field
1:03:32 is changing so most courses
1:03:34 certifications and programs
1:03:36 programs are two years behind
1:03:39 and yeah i'm wondering like it made me
1:03:43 think like when i read this
1:03:44 read this like what can actually
1:03:47 universities do
1:03:48 to address this if anything can they do
1:03:51 anything there
1:03:52 and well what to do about this mismatch
1:03:55 of
1:03:55 what we study and these three roles we
1:03:58 talked about
1:03:59 because uh they are pretty hands-on
1:04:01 right so you cannot just
1:04:03 read the textbook and uh go work as an
1:04:06 architect right
1:04:08 so like you have to to put a lot of
1:04:10 effort so how how
1:04:12 how can we bridge this gap and how can
1:04:14 universities help us
1:04:16 i see two routes to it internal to
1:04:19 companies a lot of
1:04:20 we don't look at the role of business
1:04:23 more
1:04:23 or as much as we should businesses
1:04:26 should be
1:04:27 sort of mini universities many are
1:04:29 trying to
1:04:30 where there should be a pipeline of
1:04:31 talent you should have a farm club as a
1:04:33 company
1:04:34 where you are upskilling people who are
1:04:37 in roles where they may become obsolete
1:04:39 very very soon which
1:04:40 in many cases the data science team
1:04:42 machine learning team are working to
1:04:43 automate and these are efficiency
1:04:45 projects where the company is looking at
1:04:48 automating something that's very very
1:04:49 expensive
1:04:51 and trying to become more competitive
1:04:53 and more efficient
1:04:55 those people that are in those roles our
1:04:57 domain experts have a lot of expertise
1:04:59 within the company
1:05:00 some may be semi-technical i mean every
1:05:02 role now is in some way shape or form
1:05:04 technical and so there is the potential
1:05:06 for that person to upskill
1:05:08 and i think we have to create a farm
1:05:09 club and a path for people that are in
1:05:11 roles that are losing value that are
1:05:13 going to become increasingly more
1:05:14 automated
1:05:15 and create a path for them to go into
1:05:19 these more technical roles so i see
1:05:21 companies
1:05:22 having a role in this because for them
1:05:25 it's
1:05:26 far cheaper to upskill and take people
1:05:29 and improve their
1:05:30 employee lifetime value we think a
1:05:31 customer lifetime value a lot
1:05:33 but you can do work to improve someone's
1:05:36 employee lifetime
1:05:37 value and now instead of consistent
1:05:39 turnover and all the costs that are
1:05:41 associated with
1:05:42 finding new talent and firing and laying
1:05:45 off
1:05:45 existing talent and losing all that
1:05:47 institutional knowledge in the process
1:05:49 you can preserve that knowledge reduce
1:05:51 those costs and transition people into
1:05:54 these roles
1:05:54 so that's one of the key things that we
1:05:57 can do
1:05:58 is as businesses become more like
1:06:00 universities and more like boot camps
1:06:02 and try to continually upskill and
1:06:04 reskill the people that are already
1:06:06 there
1:06:06 that is by far the least expensive way
1:06:10 to keep up with these ever changing
1:06:12 needs in the field
1:06:14 from an academia standpoint it's it's
1:06:17 very difficult
1:06:18 because universities are trying to
1:06:21 become more and more connected with
1:06:23 businesses they're trying to create
1:06:24 partnerships
1:06:26 but they haven't really gotten very good
1:06:27 at that there are some
1:06:29 you know standout universities which
1:06:32 obviously mit
1:06:33 harvard you know the big names in data
1:06:36 science and machine learning
1:06:38 and you can look across europe and you
1:06:40 find a lot of these companies that are
1:06:41 now
1:06:42 lining themselves up with universities
1:06:44 and research programs same thing in
1:06:46 india china there's a lot of countries
1:06:48 now which are
1:06:49 their core industries are getting very
1:06:51 good at partnering with universities
1:06:54 but it's a very small number of
1:06:56 universities
1:06:57 that are getting these partnerships and
1:06:59 they're only getting the top
1:07:01 most prestigious universities and we
1:07:02 can't have that we have to have
1:07:05 a more accessible educational system
1:07:08 so we have to have smaller colleges even
1:07:10 down to community colleges and high
1:07:11 schools
1:07:12 we need to be recruiting straight out of
1:07:14 high school
1:07:15 and into programs where
1:07:18 the person is recruited into a company
1:07:21 and you know when i talk about a farm
1:07:22 club being a huge part of
1:07:24 this that recruiting out of high school
1:07:27 becomes
1:07:28 sort of the beginning of the talent
1:07:29 pipeline the beginning of that farm club
1:07:31 the university is involved boot camps
1:07:34 can be involved
1:07:35 sort of this new paradigm of learning
1:07:37 and education that is
1:07:39 outside of academia that is purely
1:07:41 online
1:07:42 and more self-driven and self-directed
1:07:45 than classroom and teacher driven
1:07:49 and directed these are and this is why i
1:07:51 say we need to get into the high school
1:07:53 level because
1:07:54 if we're going to achieve any of our
1:07:56 goals
1:07:57 of education we have to redefine the way
1:07:59 that we teach at the high school level
1:08:01 and even the middle school level we have
1:08:03 to be teaching people not for college
1:08:05 not for memorization not to take tests
1:08:08 but to be productive and to eventually
1:08:12 with the path being eventually this
1:08:14 person is going to start a business
1:08:16 and create new value for
1:08:20 the entire marketplace and so we need to
1:08:23 that's the redefinition that we need and
1:08:25 it needs to go all the way down into
1:08:26 middle school
1:08:27 we need to be getting to the point where
1:08:29 we're recruiting out of high school the
1:08:30 same way a baseball team does
1:08:32 or the same way a basketball team or a
1:08:34 soccer team does where they'll have a
1:08:35 draft
1:08:36 and they're pulling people out of high
1:08:37 school they're looking at people in high
1:08:39 school
1:08:40 and they're so engaged in the athletic
1:08:42 programs and the sports and in the after
1:08:44 school programs
1:08:45 we need companies engaging at the high
1:08:47 school level in the middle school level
1:08:49 in the same way
1:08:50 where they partner with schools and they
1:08:53 make this more accessible
1:08:54 because they're going to as a company
1:08:56 improve our quality of education system
1:08:58 across the globe
1:08:59 and help transition from memorization
1:09:01 and test taking which
1:09:03 even the best education systems are
1:09:04 still focused on answering questions
1:09:07 that are true false multiple choice
1:09:10 writing essays that don't
1:09:12 they don't really have a whole lot of of
1:09:14 substance behind them when it comes to
1:09:16 being a creator
1:09:17 when it comes to being a thinker when it
1:09:20 comes to creating value from here
1:09:22 up not with these and we don't need
1:09:25 these we're automating these
1:09:27 we need these and that's where
1:09:30 the education system as a whole needs to
1:09:32 be overhauled in order to meet not only
1:09:34 these
1:09:35 needs but really we need entrepreneurs
1:09:37 we need people starting businesses
1:09:39 that's our future because if we keep
1:09:42 creating
1:09:42 employees and people who are good at
1:09:44 memorization
1:09:45 they have no future in the economy in 10
1:09:47 to 15 years
1:09:49 and basically so uh what you're saying
1:09:53 is
1:09:53 universities shouldn't even attempt to
1:09:56 catch up with the industry right
1:09:58 so like they should focus on fundamental
1:10:00 skills
1:10:02 help people learn things faster
1:10:05 and then let the industry take care of
1:10:08 you know getting people with this sort
1:10:11 of skills people who can
1:10:13 learn fast people who know the
1:10:15 fundamentals let's say
1:10:16 maybe computer science fundamentals and
1:10:19 uh
1:10:20 learn everything that is needed right so
1:10:22 like this is what universities they
1:10:24 shouldn't
1:10:24 try to cover everything they shouldn't
1:10:26 try to cover data science because
1:10:28 it's outdated anyways like it's behind
1:10:32 two years what universities used to be
1:10:34 and they need to be again
1:10:36 is places that build on the body of
1:10:39 knowledge
1:10:40 that's the point of a university is to
1:10:43 add
1:10:44 to the body of knowledge to do the
1:10:46 research
1:10:48 that creates ideas that can be
1:10:49 disseminated out
1:10:51 to businesses and so this this concept
1:10:54 of business dynamism
1:10:56 is something that a lot of economists
1:10:59 have been
1:10:59 looking at from a policy standpoint
1:11:01 going back to the 80s
1:11:02 businesses are not as dynamic they don't
1:11:04 have the dynamism because ideas are no
1:11:06 longer coming out of academia they're no
1:11:08 longer
1:11:09 state-funded they're no longer country
1:11:12 funded
1:11:13 they're no longer funded by research
1:11:15 grants from companies
1:11:16 to add to the body of knowledge and then
1:11:19 disseminate
1:11:20 that to all companies instead of just
1:11:22 one company
1:11:23 you're seeing that a lot happening with
1:11:25 google and the reason why there's so
1:11:26 much consolidation of intellectual
1:11:28 property and so much consolidation of
1:11:29 wealth
1:11:30 is because we don't have this business
1:11:32 dynamism and so
1:11:34 colleges and universities need to go
1:11:36 back to being
1:11:37 people as part of this organization
1:11:41 now adding to the body of knowledge
1:11:44 that's
1:11:44 that's the fundamental piece of all
1:11:47 these thesis
1:11:48 and all of this research and all these
1:11:51 grants and all of
1:11:52 this that's what a research excuse me
1:11:55 that's what a university
1:11:56 needs to evolve back into you know they
1:11:58 almost need to devolve
1:12:00 they're not factories for uh you know
1:12:03 test taking these
1:12:04 are you know when you look at liberal
1:12:06 arts a lot of the
1:12:07 the arguments for liberal arts degrees
1:12:10 are their focus on people
1:12:12 learning how to think learning how to be
1:12:15 creative
1:12:15 and to look at issues and look at
1:12:18 broader implications
1:12:20 and as engineers we should be and we are
1:12:23 in most cases forced
1:12:24 to take courses that are liberal arts
1:12:26 courses and
1:12:27 the reason for that is because those are
1:12:29 the ones that teach us how to think
1:12:30 those are the ones that
1:12:31 make us look at history and understand
1:12:34 broader perspectives see patterns
1:12:36 and become more useful because we know
1:12:38 how to think
1:12:40 that's where universities need to go
1:12:41 back to they don't need to teach
1:12:43 niche skills they don't need to try to
1:12:45 chase after
1:12:46 the latest trend and the latest
1:12:49 technology
1:12:50 when you're teaching software
1:12:51 fundamentals the fundamentals of
1:12:53 development and the best practices are
1:12:55 easy to keep up with
1:12:56 because those are not consistently
1:12:58 evolving but trying to teach the latest
1:13:00 programming language or
1:13:01 keeping up with platforms and trying to
1:13:03 update your curriculum every two months
1:13:05 one month to try to chase down the la
1:13:07 you just
1:13:08 it's not the way that they were designed
1:13:11 but they were designed
1:13:12 to add to bodies of knowledge i think
1:13:15 that's what we need to get back to
1:13:18 yeah so uh i think we are kind of
1:13:21 like taking more time uh than
1:13:24 uh like we originally planned but maybe
1:13:27 like
1:13:28 we can quickly go through like there are
1:13:29 a couple of questions that we still
1:13:31 haven't answered maybe
1:13:32 we can try to quickly answer them before
1:13:34 uh
1:13:35 before wrapping up so um do you think
1:13:38 machine learning product managers need
1:13:40 an mba or not
1:13:42 no no degree doesn't matter i i did it i
1:13:46 i got an mba and with an econ focus to
1:13:49 try to figure out business
1:13:50 i i i did a business when i was very
1:13:53 very young when i was going through
1:13:54 college
1:13:55 it i made every mistake possible went
1:13:58 into
1:13:59 you know the corporate world trying to
1:14:00 understand what i did wrong came out of
1:14:02 the corporate world
1:14:03 more confused than i started i did an
1:14:05 mba because
1:14:06 i was trying to understand how business
1:14:08 thought and worked and
1:14:10 no you don't need to be a product
1:14:11 manager and
1:14:13 uh well unrelated question
1:14:16 uh how soon we will see data science
1:14:18 role being split into
1:14:20 multiple different roles more specific
1:14:24 it's happening now it's very much
1:14:26 happening engineer
1:14:28 these roles we talked about like this
1:14:30 researcher
1:14:31 and i think more i think we're going to
1:14:33 see things like a
1:14:35 model quality model quality assurance
1:14:38 engineering and engineering
1:14:39 you know quality assurance groups
1:14:41 starting to come up so if you look at
1:14:43 software development
1:14:44 that's going to be the paradigm for
1:14:46 model development
1:14:48 research is going to be something
1:14:49 totally different like if you look at
1:14:50 biotech or pharma
1:14:52 they manage research they have
1:14:54 researchers they've learned how to
1:14:55 monetize
1:14:56 research they manage the research
1:14:57 process and so that's where the new
1:14:59 roles
1:15:00 within companies and new capabilities
1:15:01 are going to be going towards and being
1:15:03 focused on
1:15:05 but your traditional data science what
1:15:06 we call a data scientist
1:15:08 now is going to follow more of that
1:15:10 software development software best
1:15:11 practices paradigm
1:15:13 yeah makes sense so you said that angry
1:15:16 users are
1:15:17 important so what kind of metrics we
1:15:19 need to use to measure
1:15:20 uh their angriness or whatever they
1:15:24 like the satisfaction of these users
1:15:27 that's a good question
1:15:28 adoption adoption is one of the easiest
1:15:32 metrics to follow because if you're
1:15:34 creating a new product if you're
1:15:35 creating and defining a new category
1:15:37 it's really adoption
1:15:39 who's using it how long are they using
1:15:41 it how long does it take them to
1:15:43 complete a task that they used to do
1:15:46 either manually or they did with another
1:15:47 solution
1:15:48 what's the learning curve how long does
1:15:50 it take to get a user from
1:15:53 novice never seen it before to an expert
1:15:55 power user
1:15:57 once you get to a power user how long
1:15:58 does it take on task how much time does
1:16:00 it take per task
1:16:02 to complete work have you reduced the
1:16:05 total number of tasks that person has to
1:16:06 manually interact with are there fewer
1:16:09 tasks
1:16:09 in their chain and then in my domain
1:16:13 do a lot of decision support so what are
1:16:16 decision outcomes
1:16:17 what is the decision chain that leads to
1:16:20 a particular outcome what information
1:16:22 are they consuming
1:16:23 in order to to make that decision and
1:16:26 how do we improve
1:16:27 what information we are giving them to
1:16:30 drive
1:16:30 better decision outcomes and then that
1:16:32 feedback loop
1:16:34 measuring in you know measuring the
1:16:36 quality of decision you have 100 over
1:16:38 100 being the perfect decision
1:16:41 now what score did this particular
1:16:42 decision result in
1:16:44 if you have a product with a revenue
1:16:45 range for example
1:16:47 you have your top you have your expected
1:16:48 and you have your under perform
1:16:50 you have a decision chain that leads to
1:16:52 that product being deployed
1:16:53 being adopted and being monetized how
1:16:56 are your pricing decisions
1:16:58 were your pricing decisions correct to
1:17:01 achieve
1:17:02 your at least baseline or overperform
1:17:04 where did they underperform
1:17:06 what data did we use in order to make
1:17:08 those pricing decisions and then what
1:17:09 data can we change what data can we
1:17:11 improve
1:17:12 in order to help the next project
1:17:15 perform
1:17:16 better to get more to that mid or high
1:17:18 end of
1:17:19 the projected revenue or cost savings
1:17:21 range so those are really tangible
1:17:23 metrics when it comes to
1:17:24 adoption and when it comes to building
1:17:27 these solutions that we need to start
1:17:29 focusing on
1:17:30 and they're not necessarily related to
1:17:32 machine learning so these uh i would say
1:17:33 usual product management
1:17:35 like product metrics right so this is
1:17:37 something that a usual uh product
1:17:39 manager would care about and
1:17:40 uh right so yeah it's defining an
1:17:44 entirely new way
1:17:45 of connecting model output is what they
1:17:48 do
1:17:48 you know your prediction and model
1:17:51 quality
1:17:51 back to an actual hard number because
1:17:54 there needs to be a hard number on the
1:17:56 other side where you've mapped
1:17:58 here are my model metrics and if i can
1:18:00 improve a particular piece of
1:18:01 performance
1:18:03 that results in this happening on the
1:18:05 business side this happening on the
1:18:07 revenue or cost savings side
1:18:10 okay yeah i think uh that's all
1:18:13 so it's already you can see that it's
1:18:15 already dark so it's
1:18:16 uh yeah okay
1:18:20 thanks a lot thanks a lot for coming for
1:18:21 sharing i
1:18:23 wanted to ask you so much more than i
1:18:25 did
1:18:26 but we had a very interesting discussion
1:18:28 and i learned
1:18:29 a lot from you so thanks for coming and
1:18:32 i'm sure that the 33 people who
1:18:36 are still there they also learn a lot so
1:18:39 that's why they stayed
1:18:41 uh because this the information was
1:18:42 invaluable it was also interesting to
1:18:45 hear your thoughts about like
1:18:47 education and uh like how we can change
1:18:50 that
1:18:50 so thanks a lot for coming and thank you
1:18:53 for having me i really appreciate it
1:18:54 thanks for all the time you put into it
1:18:55 and thanks everybody who uh
1:18:57 stuck around for just over an hour's
1:19:00 worth of me talking
1:19:02 yeah but uh like they actually this um
1:19:05 so now it's 5 20 p.m
1:19:08 and we started at noon so actually like
1:19:11 uh i don't know if all all these 30c
1:19:14 people
1:19:15 started at noon together with me but
1:19:17 yeah it's
1:19:19 it's been a while okay so i'm not taking
1:19:22 uh
1:19:22 your time anymore thanks a lot for
1:19:24 coming thank you
1:19:26 yes so we will chunk this long video
1:19:30 for like four or five hours video into
1:19:32 multiple things
1:19:33 this conversation we will upload also as
1:19:36 a podcast
1:19:37 and yeah thanks a lot for coming and
1:19:39 next week we have another day of the
1:19:41 conference where we will talk about
1:19:43 machine learning in production so thanks
1:19:46 finn
1:19:47 all right bye goodbye