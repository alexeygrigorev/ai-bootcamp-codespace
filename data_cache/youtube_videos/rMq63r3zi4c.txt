0:00 hi everyone Welcome to our event this
0:03 event is brought to you by data do club
0:05 which is a community of people who love
0:07 data we have weekly events well lately
0:10 they're not so weekly but we're getting
0:13 back on track and this week we will
0:15 actually have two events anyways so if
0:18 you want to find out about all the
0:20 events we have in our pipeline which is
0:22 currently I think two there's a link in
0:24 the description go check it out and I
0:26 think I should already update this
0:28 number cuz we have more than 50k
0:31 subscribers and if you want to become
0:32 one of them so there's this subscribe
0:35 button don't forget to click on that and
0:37 very important we have a SL Community
0:39 where you can hang out with other data
0:41 in USS during today's interview you can
0:45 ask any question you want there is a
0:47 pinned Link in the live chat click on
0:49 that link ask your questions and we will
0:51 be covering these questions during the
0:54 interview that's all the
0:56 intro I'm going to stop sharing my
0:58 screen actually I must admit we didn't
1:01 we haven't had the podcast interviews
1:03 like in a while maybe in a month we're
1:05 getting back on track so don't worry we
1:07 will have soon a lot of new
1:10 stuff uh but today we have Rafael
1:14 and if you're ready we can
1:17 start yeah definitely
1:20 yeah BR the
1:24 questions and yeah so this week we'll
1:27 talk about mlops and we have a very
1:29 special guest today Rael Rafael is a
1:31 leader in the ml op space with
1:33 background in data science and machine
1:34 learning you must have seen him on
1:37 LinkedIn where he regularly shares
1:39 content on mlops I see him daily I don't
1:42 know how often you post but like every
1:44 time I open my LinkedIn feed I see a
1:46 face there which as we found out is AI
1:48 generated right so now everyone knows H
1:52 so Rafael is currently leading a team of
1:55 Engineers at anesco which is a major
1:58 sustain sustainable energy
2:00 provider and uh yeah Welcome to our
2:05 interview hey yeah hi Alexi thank you so
2:07 much for having me today good to be here
2:10 it's big pleasure and for the record
2:12 like we've been trying to do this for
2:14 quite some time but finally this day has
2:17 happened
2:19 and uh the questions for today's
2:21 interview are prepared by Johanna Bayer
2:23 as always thanks you Han for your help
2:26 and before we go into our main topic of
2:28 mlops let's start with your background
2:31 can you tell us about your career
2:32 Journey so far yeah definitely um so
2:37 I've been working in the data space for
2:40 about 10 years now just over 10 years
2:42 it's coming and I've done a few
2:44 different things um I I started as a
2:47 data scientist um and yeah it was quite
2:52 challenging for me to get into the to
2:54 the field there were lots of things to
2:56 learn and um I wasn't sure if I could do
3:00 it and I just sort of kept grinding and
3:02 what did you do before that yeah so
3:05 something a bit different uh the five
3:07 years before I worked I've been working
3:09 I guess for just over 15 years now I
3:11 worked in sustainable agriculture so
3:15 yeah I did a few different things first
3:17 I was a project manager and a lobbyist
3:20 uh for a green
3:22 organization um so lob completely not it
3:25 related right no in the in the end it
3:28 was I saw some things in the big project
3:31 that they really elected uh good
3:33 administration of their data like lots
3:36 of farmers having all kinds of data on
3:38 their crops that was super important to
3:40 improve quality and sustainability was
3:43 mostly paperwork or or on Old machines
3:46 so yeah that planted some seeds uh no
3:49 pun intended in my mind like oh there's
3:52 work to be done here and then in the end
3:54 I was um working on innovation in
3:57 agriculture and food like the last year
4:00 um and one of the topics we focused on
4:03 like uh me and my business partner is
4:05 actually technology in agriculture and
4:07 food and then mostly it and data so
4:10 that's really what got me into the field
4:12 so I went from sort of project manager
4:15 and campaigner uh to
4:17 Consultants um just freelancing and then
4:20 I was like hey there's there's something
4:22 to this I'll I'll try to do something
4:24 with data in the field of Agriculture
4:26 and Foods uh which which was quite
4:29 challenging because it's it's yeah in
4:33 some countries it is a highly
4:35 technological sector but it and data
4:38 wise I would say there a sector that's
4:41 mostly following um so I try to do the
4:44 hardest projects first I think um yeah
4:47 and then at one point I I was working
4:50 for a client and we did Proof of concept
4:53 right like 10 years ago uh all data
4:56 science it was all proof of Concepts and
4:58 um the clients said like yeah we quite
5:00 like this um can you put it in
5:02 production for us and I was like what do
5:04 you mean production yeah like production
5:06 like I didn't even know what that was so
5:09 I did some research and uh learned some
5:11 it Concepts so I was like wow if I if I
5:14 want to do something in this field I
5:16 have to learn more about these types of
5:18 things so I ended up joining a it
5:21 consultancy it was just a like a
5:24 Microsoft Platinum partner doing
5:26 everything in the Microsoft stack so
5:28 quite interesting we had everything in
5:29 the house
5:30 they call it it consultancy but it it is
5:33 it
5:34 implementation and there um my data
5:36 career started and I worked as a a data
5:40 scientist in a data analytics team um
5:42 which was mostly doing bi engineering so
5:46 so this is data engineering and
5:48 dashboarding and uh we were about three
5:50 Health Data scientists on a little
5:52 island in a team of
5:54 50 yeah yeah like one was bit more on
5:59 the data engineering side as well so so
6:02 that was challenging um and then I moved
6:05 to another consultancy which was much
6:06 more data science
6:08 focused uh which was nice I worked there
6:10 for a couple of years became a lead data
6:13 scientist um learned about putting stuff
6:15 in production and then one of the
6:17 lessons I
6:20 uh yeah I was taught in consultancies
6:22 that everything takes time so most of
6:25 our clients we were serving at like a
6:27 year or two year stops and as so the
6:29 data science projects took more time to
6:33 finish them end to end from ideation to
6:35 something running in production so I
6:37 decided to uh join a company just
6:40 internally and that's where I started um
6:44 getting introduced to mlops so um we had
6:47 lots of great models there they were
6:50 adding lots of business value and they
6:52 were really well developed like by data
6:54 scientists talking to the business
6:56 stakeholders um engineering some really
6:58 clever features and and like yeah we we
7:01 were making money and mitigating risk
7:04 but everything was running as a sort of
7:07 yeah spaghetti script style setup on a
7:10 old R server so yeah I got a chance
7:13 there to to um uh give it a bit of a
7:16 lift and shift Implement some best
7:19 practices got lucky to work with like a
7:22 really clever guy who was helping us
7:24 once every two weeks and then I thought
7:26 like hey this mlov thing I quite like it
7:30 and I also felt um I could add more
7:33 value there because so many of the data
7:35 science projects fail and then yeah what
7:38 was it all for right some learnings and
7:41 I saw that with the mlops projects we
7:43 were not always adding value but most of
7:46 the time and the engineering side I also
7:48 quite liked so um then I started getting
7:51 into MLS I guess that about
7:54 three yeah about three years ago now
7:56 time's going fast so um yeah I worked
8:00 there for a couple years and then a year
8:01 ago I started
8:03 freelancing um and here I am I'm I'm
8:06 working as a contractor now for my
8:07 current company um I will become
8:10 internal uh soon because well you have
8:13 to after a year pretty much um and I'm
8:16 staying with the company for a while
8:17 because we're in this big
8:19 reorganization uh I built a team uh I've
8:22 done it a few times in a few different
8:24 companies and I feel like there's so
8:26 much work still to do like yeah we're
8:29 not ready yet and it would be so nice to
8:31 just just finish it I mean it's never
8:33 finished but so yeah um not Contracting
8:37 the coming year or two years I guess but
8:39 very happy where I am yeah it's an
8:42 interesting story and like you mentioned
8:44 that you started in agriculture and
8:46 you're from the Netherlands and I know
8:48 that the Netherlands is pretty advanced
8:50 in this aspect so I know that it's a
8:52 relatively small country and half of
8:54 this is covered with water yet like I
8:58 can see cucumbers from the Netherlands
9:00 in pretty much every European country
9:02 and I don't know how you manag to do
9:03 that right on such a scale with so so
9:06 little land like it's some agricultural
9:08 Marvel probably but like it's it's
9:11 really
9:12 cool yeah it is cool it's part of the
9:15 national pride and and and you can you
9:18 can give it a good Spin and you can give
9:19 it a bad spin so often we say in the
9:23 Netherlands like we're the second
9:25 largest agricultural exporter in the
9:27 world but this is a false statistic
9:30 because they are that's also the import
9:32 going through when you actually count
9:34 what we produce uh we're actually 22nd
9:37 in the world which is still impressive
9:38 because we are tiny and then if you ask
9:41 me like how is it possible it's like
9:44 well we're highly technological uh
9:46 there's a lot of knowledge here from
9:48 like the seed level and the genes level
9:52 uh to producing the crops growing the
9:56 livestock um so that's something really
9:58 good at and then
9:59 I guess the the other side of the coin
10:01 is that the inputs are like really high
10:04 so we take all these grains soy mice all
10:09 this stuff have to be super effective
10:11 right super efficient yeah yeah we take
10:13 it from the Americas and we feed it to
10:15 animals and that then the yeah in a
10:18 sense the footprint is also really high
10:20 right so we have a problem that we have
10:21 too much manure and air quality is bad
10:25 and so yeah you win some you lose some I
10:28 guess but I feel if we move forward in
10:30 the right way we can be like a future
10:33 proof player that's still really
10:35 important yeah so coming back to mlops
10:38 so if I open your LinkedIn and I guess
10:42 many people who see your posts also open
10:45 your LinkedIn to just see what you do
10:47 right and what do you have under your
10:49 picture I think it's called slogan or
10:51 whatever like the
10:52 title so you have some things there and
10:55 one of the things say creating the
10:56 future's technical depth today
11:00 what does it even
11:01 mean um yeah it's uh it's a bit of a
11:04 joke um like I couldn't help myself
11:08 because that's kind of how I am but um
11:10 you mentioned the spaghetti cat that
11:12 like you had to put in production I
11:15 guess right yeah but it's also a serious
11:20 take because I feel um the world is
11:23 moving so fast and yeah technology is
11:27 rapidly evolving especially in our space
11:30 that sometimes it almost feels like what
11:33 we decide to do uh and then when we
11:36 eventually get to implement it is
11:39 already bit outdated so I I think
11:41 there's a gap between like making a
11:44 design decision and actually
11:45 implementing it and then yeah we've
11:47 chosen this now oh but look at here uh
11:50 there's another tool or there's another
11:51 method or there's another model um so is
11:55 that technical
11:56 depth I wouldn't call it technical that
11:59 per se um I would always measure between
12:03 what you decide to do as an organization
12:06 and and what you actually have the Gap
12:08 there that is technical depth so what
12:12 you have and what is out there in the
12:14 world yeah no I wouldn't call that depth
12:16 but sometimes it does feel like
12:18 that but it's in avoidable right so
12:21 sometimes like you want to create a
12:23 prototype you want to move fast and you
12:24 don't know like out of 10 prototypes how
12:26 many will actually survive maybe it's
12:28 just one you don't necessarily want to
12:31 invest uh like a lot of effort into each
12:33 of those prototypes but when one goes
12:36 off then you know okay like yeah like I
12:38 might have cut some Corners there but
12:41 now like I have to it's kind of running
12:43 it proved its value so now I have to
12:45 repay the debt
12:47 right yeah yeah I couldn't agree more
12:49 and um these are conversations and
12:53 decisions um yeah we're we're trying to
12:56 make the right ones every day and we
12:58 have conversations about this every day
13:00 between tech leads and product managers
13:03 but also amongst tech leads like some of
13:06 the ones we're working at now at the
13:07 Nico they really have this startup
13:09 mentality like cut Corner fast uh
13:13 you know is this generating value for
13:14 the customers and others are a bit more
13:16 like well this is this is the correct
13:18 way maybe we should do this first before
13:20 we deploy to prod maybe we should stop
13:22 ping corner site for some things yeah
13:24 exactly yeah um so this is an
13:27 ongoing thing and and the cliche in
13:30 engineering is like everything is a
13:31 tradeoff right and the same is true on a
13:35 product
13:36 level and when you were talking about
13:39 your career path you mentioned that you
13:42 have built a team multiple times already
13:45 so you're building it again um so you
13:47 have experience in building teams and
13:50 mops teams specifically if I understand
13:52 correctly so
13:55 why did you choose to focus on teams
13:57 like why teams specifically like and
14:00 what does what do teams have to do with
14:02 uh mlops in
14:04 general yeah great question um I think
14:08 for me it was a natural extension of of
14:10 what I was doing in earlier parts of my
14:13 life um so playing sports I always
14:16 really valued like you're better if
14:20 you're a well coordinated team with a
14:22 great culture and and everyone helps
14:24 each other and then I played some
14:26 computer games like some some really
14:28 nerdy
14:29 text based games as a teenager and in
14:32 this one game we're like a group of 25
14:34 people having to work together in rounds
14:36 of 13 weeks and again I invested in the
14:39 team there so we could perform well and
14:41 then I was a student I worked at an art
14:43 housee Cinema there were like 50 of us
14:45 running the art housee Cinema and I was
14:47 doing sort of
14:48 the um yeah like the HR part um and then
14:55 when I got to data I was like well I've
14:56 been doing this type of stuff um feels
15:00 natural for me to take this role and
15:03 particularly looking at like data
15:05 science AI mlops what I noticed is that
15:09 um you really need a good team like it's
15:12 it's hard to deliver something
15:15 successfully and you know I'm going to
15:18 mention another cliche sorry but it's
15:20 like if you want to go fast go alone if
15:22 you want to go far go together and I
15:25 think small teams can be successful and
15:28 solo people can do a
15:30 lot but most um organizations I work in
15:35 uh are non- Tech organizations in the
15:37 sense that they're they're like non IT
15:40 Tech or non data Tech um and then you're
15:43 trying to do data and it there and it
15:46 can be very challenging so you need all
15:48 kinds of different
15:49 roles um to ensure success and then
15:53 within your own little group of of data
15:58 people you really need to be aligned and
16:00 be able to trust each other and
16:02 communicate well and I think when I came
16:06 in I saw a lot of focus on the tech
16:09 always like how do we do things or what
16:12 you know what are we building to build
16:15 the product we want and in my perception
16:18 like lots of the work is process and
16:21 people work as well um and there were a
16:24 few few projects where I I focused uh on
16:28 the text like as a tech lead working
16:30 with a small team and then in my
16:33 experience in the end we we lost or the
16:36 project failed because we had no say in
16:40 in the strategy process part or people
16:43 were badly managed you know then they
16:45 leave um it's really hard you know in
16:48 these complex projects when the turnover
16:51 is too high to offboard and onboard
16:53 people so I started focusing more on
16:56 that part MH so you
16:59 mentioned two words good team good and
17:02 team right so team is clear right so a
17:04 bunch of people who together but what
17:08 does make a team good right so what kind
17:12 of people do we need inside the team and
17:14 how we well let's start with roles like
17:17 who would do we need in mlops team like
17:19 is it just I don't know data scientist
17:21 mlops ml engineer data engineer data
17:24 analyst or like how do we even know who
17:27 we need mhm yeah again great great
17:31 question thanks um so I think it really
17:34 depends on the context
17:37 um you know how many people can you hire
17:40 for such a team is it going to be the
17:42 two of you or are it GNA be like if we
17:45 10 people does it mean we
17:48 should maybe really it really depends on
17:51 the context so the type of organization
17:53 and the maturity um of the organization
17:57 um I think
17:59 there are some patterns you can identify
18:02 I think one of the roles that is often
18:05 forgotten is uh the role of
18:08 evangelist so either you need someone
18:12 really rooting for you um and it can be
18:16 someone in the team right but it's some
18:18 someone has to have this role it's not
18:20 even so much about stakeholder
18:22 management it's it's before that even
18:25 and it can be on the side of the team
18:28 but it can also be on leadership side it
18:30 can be a sponsor so it can be a sponsor
18:32 on the executive level um or just below
18:36 and I think this is super important
18:37 we're talking about non it teams right
18:39 so you mentioned non it companies where
18:41 it is may be secondary right so you said
18:44 like there in such companies success is
18:48 even lower than in let's say traditional
18:50 it companies that's why it's very
18:52 important to have this
18:53 evangelist yeah yeah or a sponsor on the
18:56 executive level just below because
18:58 question there often is like does the
19:01 company have a CTO or a CDO or C CIO
19:05 whatever and if they have one um do they
19:08 get this particular part because they
19:10 have a lot on their
19:11 plate um like like more than machine
19:15 learning operations so I think for for
19:19 both data science and machine learning
19:20 operations you need Buy in on that level
19:22 or if you don't have it you need a
19:24 really good yeah evangelist supporting
19:26 your
19:27 ca um and then the team
19:30 itself I mean it's
19:32 always nice um and in some organization
19:37 crucial to have like a good Tech
19:39 translator could be a tech translator or
19:42 an analy analytics translator or both
19:44 and this can be your product manager or
19:47 or product owner uh but sometimes the
19:50 roles are split right sometimes maybe
19:52 the product manager is a bit less
19:54 Technical and somebody has to do it
19:56 because stist maybe right yeah exactly
20:00 yeah because there's so many
20:02 complexities involved in the work um
20:05 that you need to keep uh explaining them
20:07 in the right way so briefly and clearly
20:10 enough um and you also have to
20:13 understand your audience as a good
20:15 translator because the audience is
20:16 changing all the time it's not just the
20:19 one story you're putting out there it's
20:21 like hey are we talking to these
20:23 Executives and understanding what makes
20:25 them pick and then all the other
20:27 stakeholders so these two roles are
20:29 super important evangelist and a team
20:32 Tech translator right yeah and a
20:34 translator um and again it could be one
20:38 and the same person doing those two
20:39 roles but yeah depending on the skill it
20:42 can get hard and then if you look at the
20:44 team itself of course it's nice to have
20:47 an experienced Tech lead like someone
20:49 who knows um mlops principles and
20:52 components
20:53 well uh maybe it's bit more familiar
20:56 with the stack you're working in
20:59 um and then yeah if you look at the team
21:02 itself specifically for envelops like
21:04 it's a luxury if you can split between
21:08 mlops Engineers who are maybe really
21:11 focused on building your platform you
21:14 know like doing the infrastructure and
21:16 automating away all kinds of parts from
21:19 the machine learning life cycle building
21:21 like little Tools around it interfaces
21:24 maybe utility packages if they can just
21:27 focus on that and then on the other part
21:30 you might have a machine learning
21:31 engineer who's working closer uh with
21:34 the data scientists or working in the
21:36 product teams um and this also really
21:39 depends on the type of machine learning
21:41 you're doing I think because some
21:43 machine learning Engineers they really
21:45 need to focus on efficient machine
21:48 learning in terms of memory um computes
21:52 data usage and and costs with that as
21:55 well you know some models are like
21:57 €100,000 to train or or even more so
22:01 this is more like in the Big Data uh uh
22:04 realm which is more often unstructured
22:06 data as well so you see yeah the term
22:09 machine learning Engineers bit
22:11 ambiguous uh also like when we're
22:14 getting in resumés we see like a few
22:16 different type of categories so we see a
22:18 lot of like computer vision machine
22:19 learning Engineers for example they're
22:21 usually a bit more closer to the
22:24 academic world and they're really good
22:27 but we working more with tabular data
22:29 and we're working in a product
22:30 organization so they need to be able to
22:32 work with like data scientists and
22:33 business as well but I think if you can
22:35 split between these two roles between
22:37 mops engineers and machine learning
22:38 Engineers you're in a great position
22:41 because what you see in lots of
22:43 companies is you just see like one
22:45 centralized mlops team it's like a
22:48 couple of
22:49 Engineers they have to build something
22:51 that works um and then it's hard to get
22:55 it adopted um or to have like a good
22:58 connection with the end users and the
23:00 business MH and then maybe this is
23:04 something I should have asked even
23:05 before what makes a good mlop steam what
23:08 is the actual role and focus of the mlop
23:11 steam what do they do cuz you mentioned
23:14 that okay we need evangelist we need U
23:16 translator we need mlops Engineers ml
23:19 Engineers techs you didn't mention data
23:21 scientists data analy so I assume that
23:23 the role of this mops team is to help
23:26 other teams right we can more what does
23:29 this team exactly do yeah yeah so one
23:34 thing I often repeat is I think the
23:36 focus should be on three things um easy
23:41 deployment um easy maintenance and easy
23:45 monitoring um I think those are three
23:49 key
23:51 drivers um like for for what your mlop
23:54 team should deliver and then there are
23:56 like a lot of other things they can
23:59 do um what you see in
24:02 organizations what usually goes under
24:04 the radar is you can actually save a ton
24:06 of costs as well um which can be a good
24:11 success to have as an amols team because
24:13 in most organizations they are viewed as
24:15 cost centers so if you're saving a ton
24:17 of costs you're actually well generating
24:20 some money in a sense um which can
24:23 validate your team uh from certain
24:25 perspectives right but these three
24:27 things are are really important I think
24:29 like deployment maintenance monitoring
24:31 so did I understand correctly that this
24:33 is a central team that helps other
24:36 teams oh it depends on the organization
24:39 I would say like the scale but I think
24:41 it yeah it is good to have a central
24:45 team and it can be small I think you
24:47 need some people dedicated um to setting
24:50 up a platform in terms of INF
24:53 tooling CU say imagine like I don't know
24:55 in your case what kind of use cases you
24:57 have but they that are different use
24:59 case like demand forecasting right could
25:01 be one one use case right and then maybe
25:04 another use case could be maintenance of
25:07 like whatever energy suppliers right so
25:09 it could be another team and then yet
25:10 another team could be doing
25:13 um I don't know
25:16 like something else right anything yeah
25:19 marting intelligence the pr4 product
25:23 teams right and each of them might have
25:26 their own data Engineers data scientists
25:28 Engineers I don't know Engineers like
25:31 product teams but then there is another
25:33 a separate team that helps all these
25:36 teams when it comes to ml operations
25:38 right so this is the mlops team they say
25:40 okay like we want to make it easier for
25:43 you to roll out models to production so
25:45 we have mops Engineers we have like the
25:47 SML engineer that can help you with best
25:50 practices uh is it there the kind of
25:53 setup that uh you see or like what what
25:57 do they do like what what is the
25:59 difference between like a mop team and
26:01 like just usual product
26:03 team um so we're approaching it from a
26:07 from an agile perspective so we do have
26:09 a lot of product teams more than 10
26:10 product teams and and exactly like
26:13 you're describing like each product team
26:14 is a mix of different
26:16 roles uh and then people from the
26:18 business side as well and then maybe
26:20 from like web and app development as
26:23 well um and it's not always the same mix
26:26 um and then for us the mlov team in the
26:30 in the agile framework is a little bit
26:32 more like a platform and an enablement
26:34 team uh but our team is not just like
26:38 the handful of mlops Engineers we're
26:40 actually like one team together with all
26:42 the ml Engineers so I think at the
26:44 moment we have three mlops engineers and
26:47 three ml engineers and two managers of
26:50 which I'm one um so we do it
26:53 together um and we're working on best
26:56 practices in terms of
26:58 like this is how we think it should work
27:01 and then we write like design
27:04 documentation um all the codes and the
27:06 tools like the the the uh private
27:09 packages that are being reused we're
27:11 sort of doing that together and now
27:14 we've come to a stage because if you
27:15 look at our
27:17 organization um we're working together
27:19 with four different departments and I
27:22 think we have about 45 data scientists
27:25 in total but I'm not sure there might be
27:27 more around
27:29 um and then even more data engineers and
27:31 data analysts as well um but we're
27:34 focusing on our current department and
27:37 once we have our house in order we'll
27:39 fan out to the other
27:41 departments but for us it's really a
27:44 luxury to have both a centralized MLS
27:47 team and the ml Engineers working in the
27:49 teams like it's not something I've seen
27:52 uh in other places before so so we're in
27:55 a good
27:55 spot and I imagine if you have like 45
27:58 at least 45 data scientists and data
28:00 scientists like usually there Al data
28:02 science I so diverse like there are so
28:05 many ways to get into data science you
28:06 can be like a PhD in physics you can be
28:08 software engineer you can be data
28:10 analyst like there are so many ways to
28:12 do this and then because of that also
28:15 the way people write code could be
28:17 different right so the way phys wres
28:20 code is different from the way an former
28:22 software engineer Rights Code right and
28:24 then you have all these diverse people
28:26 who create models right and then like
28:28 you end up with like 45 different ways
28:31 of like having a model right and then
28:34 what you need to do is in the mop team
28:35 to say hey like how about we try to
28:37 standardize it and have one or two or
28:40 three ways of that right yeah for sure I
28:43 think this is one of the the interesting
28:46 and challenging parts of of our field
28:51 um and you have to find a sweet spot
28:54 because if you don't standardize
28:56 anything and you just say like oh the
28:58 data scientists do something they have a
29:01 notebook or whatever they're doing and
29:03 they kind of maybe throw it over the
29:05 fence uh or give it to an ml engineer or
29:07 whatever and you kind of make sure it
29:10 works um then you're creating a lot of
29:12 work um so so you do need some
29:17 Frameworks that you want to work in but
29:20 if you are too opinionated it's like oh
29:22 this is this all encompassing mlops
29:25 framework and we have a template that we
29:28 are enforcing somehow and only if you
29:31 you adhere to this template or whatever
29:33 then we will deploy it for you and else
29:34 it doesn't work then you kind of lose uh
29:38 the larger part of the data science
29:40 population in my experience there's like
29:43 25 30% of data scientists that are open
29:47 to this it resonates with them and
29:50 others are more like well I'm already
29:51 focused on this really complex modeling
29:54 and then I have the business and it's
29:55 too much for me so you have to find a s
29:58 Sweet Spot in between those two
30:00 extremes and you do need some standards
30:03 um which maybe are a bit
30:06 opinionated and then you kind of have to
30:08 find out together with your data
30:10 scientist and the data science leads
30:12 like what are the standards are going to
30:14 be and and do they fit into the data
30:16 science way of working because they
30:18 already have their own ways of working
30:20 in different teams um and maybe across
30:23 their chapter so uh yeah it's I think
30:26 it's something you have to be
30:28 really aware of and delicate about so I
30:31 see a lot of small mops team there mop
30:33 teams they're centralized they're
30:34 pushing out the standard and then nobody
30:37 uses it right
30:39 so there's like yeah I don't know it's
30:41 taking too much time and
30:44 um and it takes time to build the trust
30:47 and the relationship like you're adding
30:49 all these bells and whistles and
30:50 Engineering practices so you also have
30:53 to invest that time in terms of not only
30:56 writing documentation but like building
30:59 the relationship and organizing
31:01 workshops and doing like PA programming
31:04 um for people to buy
31:06 in how do you standardize uh when only
31:10 like only 25 30% is on board with like
31:14 only for a third of people the ideas
31:18 resonate and like how about the rest uh
31:20 like 70% like how do you standardize in
31:22 such a way that everyone can use your
31:26 tools
31:29 M uh I think I always say iteration is
31:32 king So sort of just like we do in data
31:35 science you test
31:37 um project or yeah you test you explore
31:41 but mostly you talk to people um so so
31:44 you you have to invest time in this you
31:47 have to talk to your end users uh data
31:50 scientists are really important end
31:52 users um and you you have to keep
31:54 talking and testing and getting feedback
31:58 uh it's going to take some time and then
32:00 at one point you meet in the middle
32:02 right you can't please
32:04 everyone um but I think some parts you
32:08 know are like a a no-brainer you know
32:12 you you want proper CI for
32:14 everyone um you want some structure for
32:18 the
32:19 repository um you want to maybe package
32:21 your Solutions so these are things data
32:24 scientists can do for sure but then when
32:27 you look at the ual Source codes that
32:29 that's a big question I think like how
32:31 opinionated are you there are you going
32:33 to say like oh you always need these
32:35 modules and you always need these
32:37 functions and they need to be embedded
32:38 in these classes and that's a bit of the
32:41 danger zone I think where you start
32:43 losing
32:45 people yeah and how do you go about
32:48 talking and getting feedback like do you
32:50 just select a few projects that are
32:53 maybe the most important or
32:56 maybe not so important because you don't
32:58 want to touch the important projects
33:00 like walk us through the process of like
33:02 trying to understand uh what kind of
33:05 Standards we can have as a team and what
33:08 kind of Standards we'll get
33:12 adoption from data science side um I
33:16 think you know in my current situation
33:19 again like we're in a position of luxury
33:21 because we have many ml
33:23 Engineers um but if you don't have it if
33:27 you're just like isolated mlops steam I
33:29 would really uh approach it as a product
33:32 manager uh the process itself so how
33:36 products get developed for users you try
33:39 to develop your mlops platform in that
33:42 way for developers so people talk about
33:45 user experience but I think developer
33:47 experience is a huge uh driver for
33:51 Success here um so I am I am not a
33:55 product manager but I kind of do
33:58 uh for MLS and I think to create the
34:02 buyin from the
34:03 organization one of the first things you
34:05 do is you collect the pain points so
34:08 what actually are people struggling with
34:11 and then you can make a little matrics
34:14 maybe it's like oh this is what I the
34:17 mlos lead or whatever think we should
34:19 work on uh and this is what the others
34:24 day or the data scientists bus think we
34:26 should work on and then in those Matrix
34:28 you will have four quadrants and yeah
34:30 you start with the one where you overlap
34:33 you agree just to create some successes
34:36 and some wins even though if you might
34:39 not think that's the right thing to do
34:41 first you need to build trust and and
34:44 prove your
34:45 value and then I think what's really
34:48 important is once you have the pain
34:49 points you
34:51 also you have to show a clear uh before
34:54 and after so before you start you have
34:56 to paint a clear pictures like hey this
34:59 is where we are now I know I'm asking a
35:03 lot of you now uh and it's going to take
35:06 time and it's going to take maybe some
35:08 time of your regular work but when we do
35:11 it look at where we will be these are
35:13 the clear gains we'll have um these are
35:16 the risks we will have mitigated this is
35:20 the time we're saving every week or
35:22 every deployment every Sprint whatever
35:25 this is maybe the money we're saving and
35:27 what once we save those
35:29 resources uh you actually the data
35:31 scientist will have much more time uh to
35:34 do your actual work because what you can
35:37 observe in a lot of organizations that
35:39 don't do proper machine learning
35:41 operations is that at some point the
35:44 data scientists get stuck in operations
35:47 so the organization starts doing data
35:50 science some cool models or some cool ml
35:53 systems or Solutions get built a few
35:55 more a few more a few more and then the
35:57 data science team starts getting
36:00 criticized by the business because the
36:02 pipeline didn't run or something is up
36:05 you know and then oh yeah they have to
36:07 debug and they sort of what I've seen a
36:09 lot of people do uh over the years is
36:12 they just go through the code run it
36:15 like chunk by chunk or sell by sell and
36:18 start inserting uh print statements in
36:21 between to see what's up and this this
36:23 takes a lot of time so a lot of
36:25 organizations get stuck
36:28 in at the point where there's like so
36:30 much Ops work just so much and you kind
36:33 of have to show them like hey this is
36:35 where you're going or this is where you
36:36 already are if we start implementing
36:39 these tools and practices we're going to
36:41 free you up again and you can make you
36:44 can improve the models or you can make
36:46 new ml Solutions which you kind of love
36:48 doing like you don't like fixing these
36:50 pipelines right then yeah well let's do
36:54 it maybe so that's why you said you
36:56 start with paino
36:58 cuz like there are clearly as a data
37:00 scientist I don't like debugging
37:02 pipelines right and then you kind of
37:03 figure out okay like this is what they
37:05 don't like cuz otherwise you would risk
37:07 like as you were talking I imagine that
37:10 you as a platform engineer you might
37:11 think okay like this is this the best
37:13 way of deploying models and everyone
37:15 should just use it and then and people
37:17 like oh we kind of use Sage maker and it
37:20 kind of works like it's not really a
37:21 problem for us yeah and then like okay
37:23 you have this fancy thing but like it's
37:26 not really so in any pain points of the
37:30 like product teams right yeah exactly
37:33 and then you start rolling your amazing
37:35 practices out and the data scientists
37:38 will be like oh the these tests are not
37:41 accepting uh what I've just built you
37:44 know even the pre-commit hooks like this
37:46 what is this mypie thing I I can't even
37:48 merge my code now oh well that is if
37:51 they use franches but you know and then
37:53 you lose you lose the Buy in um so you
37:56 really have to show what it's going to
37:58 bring and from the other side I think
38:01 from leadership one thing that is really
38:03 important and and hard to do in mlops is
38:07 people often want
38:09 kpis um or okrs everyone's like own okrs
38:14 these last couple of years but then they
38:16 want measurable results and I think for
38:18 engineering cost
38:20 centers this can sometimes be
38:23 challenging because from the engineering
38:25 side it can feel a little bit like yeah
38:28 but if we weren't here nothing would
38:29 work you know why are you why are you
38:32 bugging us with these uh kpis we have to
38:35 present every month or every quarter um
38:38 but you have to do it like you you have
38:40 to make things it could be as simple as
38:41 the number of deployed models through
38:43 the platform right exactly yeah so like
38:46 there are ways to to measure that and I
38:49 think one of the key points and this is
38:52 what we just talked about too like when
38:53 it comes to pain points is like cop's
38:55 team is at the end is also a product
38:57 team but more like internal product
38:59 right you need to approach it as such so
39:01 like talk to users instead of assuming
39:05 what they need right yeah yeah for sure
39:08 okay and um we briefly touched what kind
39:12 of good practices or the set of tools or
39:16 set of best practices we should have um
39:20 so you mentioned we should have proper
39:22 CI we should have structure
39:24 for uh ml repos
39:27 and you packages right
39:30 packaging is there anything else that
39:33 like would be can a maves for when it
39:38 comes to standardization and best
39:40 practices yeah I think it's always good
39:42 to isolate your
39:44 parameters um in whatever Solutions
39:47 you're building so for software
39:50 Engineers this is maybe like a a
39:53 no-brainer but I think in in data
39:55 science it's good that we isolate our
39:57 parameters uh probably in a standard way
40:00 right so every team is doing it like not
40:02 like one team is using in files another
40:04 team is using yam files their team
40:06 exactly variables But like everyone
40:08 sticks to the same standard yeah yeah
40:11 exactly um then I think you know in in
40:15 terms of your testing Suite you can do
40:18 all kinds of things and it's hard to get
40:21 like code coverage like unit test for
40:23 everything you write but I think
40:26 whatever you do in in data
40:27 transformation so the pre-processing and
40:30 postprocessing of your data should
40:33 always be
40:34 tested um and this people can actually
40:37 do on the development side
40:40 themselves um then another thing to pay
40:44 attention to I think
40:46 [Music]
40:47 um is when people are developing stuff
40:50 they do a lot of data exploration and
40:53 there's a lot of knowledge captured in
40:56 there and I think the data
40:58 expiration holds a lot of keys for uh
41:02 the monitoring setup so even if you
41:05 don't have an
41:06 advanced monitoring setup because this
41:09 is maybe one of the harder things to do
41:12 and you're going to uh productionize
41:14 your code that that part
41:17 disappears or well before we would just
41:20 comment out that part of the code right
41:22 it would be like uh GG plot or something
41:25 we commented out and uh we don't run it
41:28 but I think if you productionize your
41:31 code then you want to keep this part
41:34 because these are like the keys to root
41:37 cause analysis so really simple part
41:39 could be like hey I saw you had this
41:41 notebook or whatever reproduction IED it
41:43 now could you maybe just make like an
41:47 isolated uh exploration
41:50 notebook uh because it will help us in
41:52 the
41:53 future so this is not so much about the
41:56 productionizing itself
41:58 more like right how we organize code
42:00 okay here we have like this exploratory
42:02 stuff here we have like the deployment
42:05 stuff here we have tests right and
42:07 everything is kind of clear where which
42:10 think
42:12 is yeah for sure for sure but I think
42:15 there's a risk of the um exploratory
42:19 stuff disappearing sometimes and it's
42:22 like there's productionize code it's
42:24 version controlled but where's this
42:26 original thing yeah it was on so and
42:28 so's desktop and they left okay so what
42:32 you say is like if we have a g repo we
42:34 should just have we just need to make
42:37 sure that like let's say we have a
42:38 notebooks folder where we keep our
42:40 exploratory stuff even if it's like
42:42 somewhat messy or like
42:44 Messi like we just commit it there we
42:47 just push it there so even if maybe we
42:50 will never need it but who knows maybe
42:53 we will yeah yeah for sure there's
42:56 usually like loads of value in there so
42:58 keep it
43:00 around um yeah other best practices I
43:04 think if you get to a more advanced
43:07 level
43:08 reproducibility and traceability is
43:10 important so traceability depends on the
43:14 sector you're in the the legal framework
43:17 but I think reproducibility is
43:19 interesting and um there's there's
43:22 different ways to do it uh and like to
43:25 have something 100%
43:27 reproducible is hard but if you can tie
43:32 the uh code um that you used to to do uh
43:38 certain deployments to the data
43:41 versioning you already quite good
43:44 compared to the
43:45 field um so you need data versioning for
43:48 that first of course but then you just
43:51 kind of need to know like hey what
43:52 version of the data um is connected to
43:55 this deployment
43:57 then we can sort of reverse engineer it
44:00 when we want to know something else it
44:02 would be nicer if you had more stuff you
44:04 know like the model
44:06 artifact uh or a doer image but yeah
44:09 again it's not for everyone um so to
44:13 really have some like minimal and I I
44:16 can't call it reproducibility because
44:17 it's not officially that but at least to
44:19 have a lineage there and at what point
44:22 of organization maturity do we need to
44:25 think about data versioning cuz like to
44:27 me sometimes it feels like too
44:30 much um like if we just want to have a
44:33 simple model and maybe we don't don't
44:35 have a lot of models in our let's say
44:37 portfolio yet like do we really need to
44:40 care about data versioning from the
44:42 start or it's something we can add
44:45 later yeah no I agree with you it can
44:48 feel like a lot and um I think it really
44:51 depends on your
44:53 sector um what you have to do in terms
44:56 of
44:57 uh obligations to your to your customers
45:00 or in the B2B uh customer domain or
45:05 legislation but yeah it's not easy I
45:08 agree um yeah we have a few questions
45:11 from the audience so the first question
45:14 is is it important to first work as a
45:16 data scientist before moving into mlops
45:19 and maybe here we can also think about
45:20 like what actually mlops means in this
45:23 context and in general right CU like cuz
45:26 I think there is this
45:28 um idea that mlops is strictly about
45:31 tools right so as a data scientist has
45:33 started uh doing this tools and then I
45:35 move into mlops right but we also talked
45:39 about other things that are mlops
45:41 related which is pro which is
45:43 processes uh Team structure and all that
45:46 right so with this in mind like what do
45:48 you think do you do we need to work
45:50 versus data scientist before doing theml
45:53 stuff or it's not
45:55 necessarily yeah you do need these
45:57 skills in your team so not everyone has
45:59 to come from the data science s but you
46:01 do need these skills in your team in the
46:03 mix um in the mlop team right yeah and
46:07 then it's good to have a mix of uh
46:12 skills I guess or maybe previous uh
46:14 professions so mlops has a lot of
46:18 overlap with
46:20 Sr um site reliability engineering which
46:23 some people tend to call devops um
46:28 which yeah which is you know interesting
46:30 I I learned not too long ago that devops
46:33 is a movement nobody maybe knows exactly
46:36 what it is but Sr is a really
46:38 well-defined practice so I started
46:40 calling this SRE as well and mlops has
46:43 like a lot of overlap with that um so
46:46 it's it's useful to have someone from
46:48 that side it's also useful to have like
46:51 good software engineering
46:53 experience because I think uh at the end
46:55 of the day as data scientists we are we
46:58 are you know quite poor software
47:01 Engineers um in general and then it's
47:06 funny because some of these skills like
47:08 SRE platform engineering they are
47:11 actually just called Data engineers in a
47:13 lot of
47:14 organizations um so yes people are
47:16 building data pipelines or maybe doing
47:18 some data warehousing but then they're
47:20 doing a lot more so it's
47:22 also yeah quite interesting in many use
47:25 cases to really at the data Engineers
47:28 what they can do and maybe add like one
47:30 or two of them to your mlop
47:33 team so in general like we aim at having
47:37 a a diverse set of skills having
47:40 somebody from engineering having
47:41 somebody from with platform experience
47:43 having somebody with data science
47:45 experience right and then plus the extra
47:48 roles that you mentioned um
47:52 so for a specific individual it's not
47:55 important to work as a data scientist
47:57 before doing mops but there should be
48:00 somebody in the team with this
48:01 experience yeah preferably more than one
48:04 but you definitely need this this um in
48:06 the mix I would say yeah probably the
48:08 translator role right is uh they should
48:11 have this experience at least to some
48:14 extent yeah yeah that could help for
48:16 sure yeah a question from
48:20 Sam what will you say is the best place
48:23 to start in terms of implementing mlops
48:25 in a new team the team has Loosely
48:28 experimented with vertex
48:30 AI so what was the question what is the
48:32 best place question is like um you want
48:35 to start implementing mlops practices in
48:37 a new team how do you do
48:41 this
48:42 um well I think it's important again
48:45 from a sort of product management
48:48 perspective to to think about what is
48:51 most needed in the organization so so
48:54 what is the um challenge you are trying
48:56 to
48:57 solve um and I'm not too familiar with
49:02 verx AI it's just yeah but I
49:05 think you know is the requirement that
49:09 hey we have models running in production
49:11 and we don't really know what they're
49:13 doing so we want
49:15 monitoring um then you start there or is
49:18 the challenge like it's taking so much
49:21 time to deploy new versions of models we
49:24 actually want to deploy a new model
49:26 every month month but the deployment is
49:28 taking multiple months um then you start
49:31 there so that's a hard question to
49:34 answer uh without more context but
49:37 having said that I think there's always
49:41 um some low hanging fruit in mlops and
49:45 like I mentioned earlier for me it's
49:48 always the CI I think CI you can set up
49:51 quickly so basically speaking with users
49:56 data is asking the them about their pain
50:00 points right and going from there yeah
50:05 okay and and if you want to start with
50:07 mlops one thing you should do early is
50:10 you should be
50:12 aware of the opportunity or not um to
50:16 build mlops with the with the tools you
50:19 have um and if you have tools that you
50:22 can build it with you should do it with
50:24 those tools um sometimes people want new
50:27 tools depending on the type of company
50:29 you're in this can take a lot of time so
50:31 if you're in a startup it's just like
50:33 hey need this can we get the credit card
50:35 number okay we have it the same day but
50:38 in corporate or semi corporate
50:40 environments the procurement processes
50:42 can take so so long um so if you want a
50:45 particular thing that's better than what
50:47 you already have just go with the thing
50:50 that you have at first but if you
50:52 realize that you want to start with
50:54 mlops and you actually have nothing to
50:56 work with then it's good to realize that
50:59 early so if you if you look at um all
51:03 the different melops components so maybe
51:06 the first one is Version Control if you
51:08 have absolutely nothing for Version
51:10 Control okay like flag that straight
51:13 away with your leadership so like hey we
51:15 need to get a subscription to so and so
51:18 because we're want to
51:20 start and another question that um came
51:23 up right now as you were speaking so you
51:26 said buildops with tools you have and
51:30 like I like this buildops and I was I
51:32 started to think like what is actually
51:34 mean to build M mlops and how do we know
51:37 that we have built mlops like is there a
51:40 set
51:41 of things we need to have to say okay we
51:44 have some mlops as compared to mlops
51:48 before yeah yeah great question so so
51:51 there are a few different Frameworks
51:53 um for mlops and uh
51:57 um so last year I was writing with
52:00 marvelous mlops a Blog and content
52:02 platform and there is a framework like
52:05 uh the mlops tool
52:07 belt and this is the one I like best U
52:11 not to pet ourselves on the back they
52:13 actually made it before I joined so a
52:15 lot of credit to bashak and Maria who
52:18 did that but they just um based on the
52:21 literature out there made their own set
52:23 of components and it's like oh if you
52:26 you have something for all of these then
52:30 yeah you have good envelope setup in
52:32 place but these are things like
52:34 experiment tracking or model registry or
52:38 like monitoring or deployment just so
52:41 Version Control
52:43 cicd uh
52:45 containerization model registry indeed
52:48 and uh different variety of that is
52:50 indeed experiment tracking um then
52:53 there's your container registry as well
52:56 uh
52:58 monitoring compute and serve of course
53:01 and something I like to add as well is a
53:04 package registry so you you have a
53:06 private package registry with why do we
53:08 need that like you mentioned packages
53:10 multiple times but like why do we need
53:12 to like let's say I have a project and
53:15 this is I don't know demand for casting
53:18 why do I need to bother with packaging
53:20 is a is a package and then like can't
53:23 they just you know put it in Docker and
53:25 call it a
53:27 yeah for sure you can do it but what I
53:30 like about packaging is that you can
53:33 throw a lot of stuff together and and
53:35 package it so to say so what do you mean
53:38 by package actually like is this python
53:40 wheel or yeah exactly so most of the
53:44 time what we do within mlops is a lot of
53:46 python so it's python packaging and then
53:49 an important part of that is uh version
53:52 independency management and
53:54 configuration management and the current
53:55 setup of python packages it's nice
53:58 because it's lets you configure some of
54:01 the important stuff in the package
54:04 configuration um and I think it's um a
54:08 good way to keep your well software
54:11 compatible like why don't we just use
54:15 Docker well in the end you can build a
54:18 Docker image but what usually happens is
54:21 you're not working in isolation
54:24 so your package
54:26 operate um on the scope together with
54:30 different pieces of software right so
54:33 one nice thing about coming from a
54:36 package side is that you can can
54:38 configure um your
54:41 dependencies um so you can Loosely
54:44 Define them in your package for example
54:47 so everything that you're importing so
54:49 import something in the in the python
54:51 code you put in the configuration and
54:53 you give it a range in terms of versions
54:56 that's compatible with the other ones
54:58 you
54:58 using um so at the point where all the
55:03 dependencies are loaded and you sort of
55:05 pin them and build a Docker image then
55:08 you're fine right you have you have a
55:10 working reproducible thing you can ship
55:13 but the point before that maybe your
55:15 piece of software needs to work together
55:17 with other pieces of software so other
55:19 packages and if you have a package
55:21 defined with ranges it is compatible
55:24 with most of the other pieces of
55:26 software if you don't have that if you
55:29 like pin everything for example you
55:32 might be like the
55:34 Troublemaker um because you are trying
55:36 to use different yeah versions of the
55:40 same package uh that are not compatible
55:43 with each other of course you can also
55:45 go for a setup where each component is
55:48 its own
55:49 container um but yeah it could create a
55:53 lot more
55:54 overhead okay I imagine that cuz um now
55:57 when you were talking about that I was
55:59 thinking okay if everything isn't is its
56:02 own container then like everything has
56:05 its own pandas or whatever like numai
56:08 like all this stuff and when we deploy
56:11 to our plat for multiple models then
56:14 every each
56:16 single uh model has its own bunch of
56:19 dependences and we are kind of multip
56:23 multiply well it adds up quickly right
56:27 while if we just have packages then
56:30 maybe like all of these can have the
56:32 same version of pandas I don't know well
56:37 hopefully it can be resolved within the
56:39 ranges that's that's what we Tred to a
56:41 for what I understood from you is like
56:43 there are some use cases where it's just
56:45 easier to have a package rather than
56:47 like build um a full
56:50 container well we usually do both I mean
56:53 now we're we're using data braks but we
56:56 also have a setup with kubernetes so we
56:58 actually use our package to build our uh
57:01 Docker
57:02 image and run that but yeah it depends
57:06 on the complexity of your setup so one
57:08 of the first things I saw as a data
57:09 scientist in 2019 was someone advocating
57:12 for a separate Docker image for each
57:15 logical component of your ml pipeline so
57:18 one for data handling one for
57:19 pre-processing one for modeling Etc and
57:22 then you can easily swap them out as
57:24 something changes so I was like oh this
57:25 is amazing
57:27 but I think the question you have to ask
57:29 there is like does it make it easier or
57:32 more complex for teams to be autonomous
57:34 and for data scientists to use this type
57:36 of
57:38 stuff I noticed that we have a few
57:41 questions in live chat sorry I wasn't
57:42 monitoring live chat I was just looking
57:44 at slido uh maybe we can do you have
57:46 time for maybe one more question I
57:49 actually have time I knew we uh
57:51 originally needed to finish early but I
57:52 do have time I have like another half
57:55 hour yeah well hopefully we will not
57:57 need that much we cover multiple
58:00 questions right it's okay surely okay a
58:03 question from s I'm about to start on
58:06 data management site and I like your
58:07 point about addressing pain
58:09 points uh first to make people use your
58:12 solution do you have some example of
58:15 when this worked well and when it
58:20 failed yeah so um a successful example
58:24 is something you mentioned earlier
58:25 actually like showing the frequency of
58:27 deployments and then just showing the
58:30 business that we're only deploying a few
58:32 times a
58:32 year and then showing them that in the
58:35 new situation we can deploy every day so
58:38 for them the deployment was a paino
58:40 right yeah yeah it was taking ages like
58:44 uh deployment was taking ages also
58:48 training in terms of compute how it was
58:50 set it was taking ages testing was
58:51 taking ages like it it just took forever
58:54 so trying to sell ml hey you can all do
58:56 it within like a few hours that that
58:59 worked
59:00 um and when it failed I mean yeah for
59:04 sure
59:05 [Music]
59:07 um once for a client we built a
59:10 successful uh uh data science solution
59:15 in a proof of
59:16 concept and then um for the second part
59:20 we sold them a data platform this was in
59:22 2019 so it's like hey you need to get a
59:25 data Lake to start a data here you
59:27 needed data braks it was a bit different
59:28 back then to run these models and we
59:31 successfully sold all of them these
59:34 projects and we built them but where we
59:36 failed was they had a sort of
59:38 integration freeze because they had to
59:41 uh filled migrations on like a storage
59:44 side and workplace site so the board had
59:47 decided that no Integrations were
59:49 allowed so we had like a this whole data
59:52 platform but it wasn't allowed to
59:53 connect to data sources and we could
59:55 jump
59:56 high and low and do everything and we
59:59 completely failed to convince them and
1:00:01 in the end you know we worked there for
1:00:03 like two years and that was
1:00:05 it that must be quite
1:00:08 frustrating oh yeah yes I could
1:00:13 do yeah yeah I had two difficult
1:00:16 projects in a row like two times uh
1:00:19 little under a year and this was the
1:00:20 second one and after after that I was
1:00:22 done for a bit like I also had some
1:00:24 challenges in my my personal life but I
1:00:27 I pretty much burned out on that project
1:00:29 yeah I can imagine that like this is
1:00:31 when there is like a decision that you
1:00:33 don't have any power to influence and
1:00:36 they just okay we're not integrating
1:00:38 like okay why did I spend two years
1:00:40 building this thing yeah they they made
1:00:44 us uh build something that would ran on
1:00:47 uploaded csvs so that's what we did but
1:00:52 that's not what you
1:00:53 want and there's an interesting question
1:00:55 with which perhaps we should have
1:00:57 started with at the very beginning of
1:00:59 this episode is what is mlops in simple
1:01:04 terms um it is the operational part of
1:01:09 building machine learning Solutions so
1:01:11 you build machine learning
1:01:13 Solutions and then they start running uh
1:01:16 in your business and you have business
1:01:19 operations you have HR operations and
1:01:22 that this is machine learning
1:01:24 operations so so it's basically a set
1:01:28 of tools best
1:01:31 practices right and other things to make
1:01:33 sure that and machine learning models
1:01:36 run yeah that they keep
1:01:38 running in the right way this is the
1:01:41 tricky thing right because the data is
1:01:42 changing all the time so it's not just
1:01:45 the one thing yeah and by just adding in
1:01:47 the right way you just made it so much
1:01:49 more complex yeah yeah it's unfair com
1:01:53 compared to other software operations
1:01:56 right because of the data part yeah I
1:01:59 think you said like the focus
1:02:02 was uh the focus of mlop team is easy
1:02:06 deployment easy monitoring easy
1:02:08 maintenance right and this is actually
1:02:12 quite difficult to achieve like all
1:02:14 three yeah so like it has to be quite
1:02:18 mature to in order to like make make it
1:02:21 easy to do all these
1:02:23 things yeah yeah it's a challenging
1:02:25 field
1:02:26 [Music]
1:02:28 um yeah you need to know a little bit
1:02:31 about a lot and then a lot about a few
1:02:33 things so yeah okay like have t profile
1:02:39 yeah yeah definitely yeah okay I think
1:02:44 um that's it for today so that was a lot
1:02:49 of knowledge that you shared with us
1:02:51 thanks Rafael for doing that I have a
1:02:54 lot of notes like
1:02:56 I took this and yeah that's and I'm
1:03:00 super happy that we finally managed to
1:03:03 record this it's amazing and like quite
1:03:06 actually quite a few people joined us I
1:03:09 say it's above average so thanks
1:03:10 everyone for joining us today asking
1:03:12 questions being active and again thanks
1:03:14 Rafel for sharing all your experience
1:03:16 with us I hope this thing U with like
1:03:20 the integration does not happen again in
1:03:23 your career CU like must be devastating
1:03:26 and yeah thanks for sharing it with us
1:03:28 too yeah thank you so much for today
1:03:30 thanks everyone for joining and I just
1:03:32 want to give a big compliment to you and
1:03:34 Johanna for the way you do things like
1:03:37 you prepare so well and like the
1:03:39 questions you've prepared and the way
1:03:41 you're doing this I I really enjoy it
1:03:43 like watching all the others as well and
1:03:45 so happy to be here today so big thanks
1:03:47 to you all the credit goes to you Hana
1:03:48 So yeah thank you yeah for sure for sure
1:03:52 really good okay okay thanks everyone
1:03:55 thanks Rafel and tomorrow actually for
1:03:57 those who don't know we have another
1:03:59 podcast episode so join too and um see
1:04:03 you soon yeah hopefully see you again
1:04:06 and have a good day yeah bye bye