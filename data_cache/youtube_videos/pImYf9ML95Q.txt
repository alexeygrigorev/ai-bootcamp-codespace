0:00 hello everyone
0:01 uh
0:02 thanks for joining our event this event
0:04 is brought to you by data talks club
0:06 which is a community of people who love
0:08 data we have weekly events
0:10 and this event of one of such weekly
0:12 events so if you want to find out more
0:14 about the events
0:15 we have you can go to the description
0:18 there is a link click on this and you
0:20 will see all the events we have
0:21 then don't forget to subscribe to our
0:23 youtube channel if you still haven't for
0:25 whatever reason i don't know what can be
0:27 a good reason of not subscribing so
0:30 please do
0:31 and then last thing is we have an
0:33 awesome slack channel where you can talk
0:35 about
0:36 amazing
0:37 topics all data related things can be
0:40 discussed there go there and the
0:43 register and then finally during today's
0:45 conversation you can ask any question
0:47 you want there is a pin linked in the
0:49 live chat click on this open and ask any
0:52 question you want to ask and we will be
0:55 covering these questions today
0:57 and this is the last light i have so now
1:01 let me just
1:03 get my questions
1:09 are you ready
1:11 i'm ready
1:12 you're ready okay
1:14 so this week we'll talk about business
1:16 acumen and we have a special guest today
1:18 tom
1:20 tom is a data scientist phd multiphysics
1:23 engineer and python loving geek living
1:26 in the united states
1:28 it's probably not a very long
1:30 bio but
1:32 tom knows a lot of things so i watched a
1:35 lot of different events with tom
1:37 and i know that tom can talk about
1:39 pretty much everything any data related
1:42 topic tom knows
1:44 something from this
1:45 and to me it's great pleasure to welcome
1:47 you tom today on this show hi
1:50 hi alexi i'm really glad to be here and
1:53 i want to qualify something you said
1:57 i know a little bit about a lot of
1:59 things but i don't know a lot about a
2:01 few things
2:02 or maybe i know a lot about a few things
2:05 i hope so
2:07 but one thing that helps a lot i always
2:10 like to emphasize is
2:12 you can learn a lot more if you focus on
2:14 concepts than details
2:18 yeah interesting so actually i wanted to
2:20 invite you to this event for a long time
2:23 but i was struggling to think what can i
2:26 because usually we have um topics like
2:30 themed discussions of discussion about
2:32 something like business acumen today
2:35 but i knew that you can talk about
2:37 anything so we talked together about
2:38 full stack data scientist and i saw you
2:40 talking with danny about pretty much
2:43 everything so whatever audience wants to
2:45 know you were there being able to answer
2:47 that then i know you host events talking
2:50 about transformers uh like you know
2:53 very theoretical things
2:55 and then what you share on linkedin is
2:57 also like can be sequel it can be
3:00 you know machine learning uh
3:02 comparability theory basically a whole
3:04 range of different things
3:06 so but i finally found a topic business
3:09 acumen
3:10 so um but before we go into this main
3:12 topic of business acronym i wanted to
3:14 ask you to tell us um in a few words
3:17 about your background can you tell us
3:19 about your career journey so far
3:21 absolutely um i was born and raised in
3:24 dallas texas
3:26 and um i had the honor of being senior
3:29 class president of my very large dallas
3:31 high school and i was an aqua jock
3:34 growing up a competitive swimmer
3:36 and then i went off to the big bad
3:39 university of texas at austin
3:42 to get a bachelor's in mechanical
3:45 engineering
3:46 right after soon after that
3:49 i went into my nation's naval nuclear
3:51 program and i went through the same
3:54 training that a naval ensign would go
3:56 through but i was working for one of the
3:58 contractors that served the naval
4:00 nuclear program
4:02 so when i arrived at
4:05 the prototype training on real naval
4:07 reactors but they were land-based
4:09 back then
4:11 i went through the same training with
4:13 the naval officers but when
4:16 we completed they went out to sea
4:18 whereas i stayed at the plant and helped
4:20 with the operations maintenance and
4:22 training of the new naval personnel
4:24 coming through
4:25 and then um
4:27 i wasn't happy enough with that so i
4:29 went to grad school for a while i
4:32 managed the research reactor at texas a
4:34 m university
4:36 and then um
4:37 got my match masters
4:40 and uh phd in mechanical engineering
4:43 there my master's focused on robotics
4:46 and
4:47 for the research
4:49 and
4:50 my phd focused on
4:52 uh design and modeling of hybrid
4:55 electric vehicle power plants
4:58 and that's when i really started to dive
5:00 into uh
5:02 data science type topics we didn't call
5:04 it data science back then so i was
5:06 learning neural networks
5:08 what's that what did you call it back
5:09 then
5:11 just whatever sub topic we were learning
5:14 so i i first realized oh there are
5:16 limits
5:18 to what we can do with classical
5:21 physics based modeling and control
5:23 system design so one of my controls
5:25 professors was teaching fuzzy logic and
5:28 expert systems love that course
5:30 and then i i started taking uh studying
5:33 neural networks too
5:36 and then we were doing there was no
5:38 python back then so we were coding this
5:40 up from scratch and c or whatever and
5:44 and doing our own memory allocation but
5:46 did some pretty cool things
5:48 back then with that and then ended up
5:50 needing
5:51 some ai in the modeling i did for my phd
5:56 then i moved to the boise area way back
5:59 in
6:00 97
6:01 started out with a small
6:03 it was a manager of advanced products
6:06 for a small
6:08 company that made automated wet etch and
6:10 cleaning tools for the semiconductor
6:13 industry but
6:14 i i felt like the leadership was going
6:16 to bury the company so i moved over to
6:18 hp i was there almost 17 years
6:21 and then moved over to on semiconductor
6:24 and over the course of that i mentored a
6:27 lot of younger people either working on
6:30 their advanced degrees or needing help
6:32 with
6:33 modeling things
6:34 of course we were very test centric and
6:36 laser jets but i did a lot of other
6:38 things there too
6:41 and then at on semiconductor that was
6:43 really like a factory of data science
6:45 type work
6:46 algorithm development primarily but um
6:50 was able to try out and achieve some
6:52 really cool
6:54 machine learning there that was
6:56 a combination of unsupervised but where
6:59 the model could figure out its own
7:02 labels on the fly
7:04 and then
7:06 most recently i was at ul as lead data
7:09 scientist for their prospector sas
7:13 prospector serves up
7:16 a
7:17 database through their sas for
7:20 it's the world's largest database for
7:22 plastics paints coatings personal care
7:24 and cosmetics
7:26 and was developing an ai to process
7:29 unstructured data for them
7:31 and uh now i'm i just took some time off
7:34 to look for a new job because i realized
7:36 i needed to move on
7:38 so that's where i'm at and then probably
7:40 the thing i'm most proud of alexi is
7:44 about
7:45 a couple of years ago
7:48 young people on linkedin started
7:50 reaching out to me for help and
7:52 to make a long story short
7:54 my help was shocking to me it was
7:58 considered very helpful
7:59 and uh my followers grew and i ended up
8:03 being overwhelmed by one-on-one
8:05 mentoring requests so
8:07 now we do a thing we call integrated
8:10 mentoring
8:11 and we call it it's
8:12 it was originally the name of my blog
8:14 integrated machine learning and ai but
8:17 now it's a community
8:18 uh we're approaching a thousand people
8:20 on our slack work group
8:22 but we have a
8:24 saturday morning integrated mentoring me
8:26 and one of the other gentlemen who's
8:28 like about my best friend in the world
8:30 guys and kari were writing a book
8:31 together uh we're teaching a course for
8:35 free to test out our book material
8:37 and then i have a couple of tech time
8:39 chats each week so
8:41 we're still figuring ourselves out and
8:42 growing but we're we have a motto
8:45 called more together
8:47 we we just all want to grow and learn
8:49 and we're helping each other do that
8:51 that's our spirit
8:52 yeah that's that's very cool so i'll
8:55 make sure to add any links uh you will
8:58 send me about the course you're doing
9:00 you mentioned the book uh
9:02 you mentioned the community
9:04 linkedin so i'll make sure to include
9:06 that and i also want to talk a little
9:09 bit about that maybe towards the end
9:11 sure but um yeah so
9:14 coming back to our main topic business
9:16 acumen so before this before this
9:20 meeting so i looked it up what acumen
9:22 means and document means the ability to
9:24 make good judgments and take quick
9:26 decisions
9:28 and i wanted to ask you
9:29 what is business acumen and why is it
9:32 important for data professionals for
9:34 data scientists and others
9:36 so i want to share with the audience
9:39 what i'm about to share
9:41 is stuff that i learned the hard way
9:45 quite humbling i should add
9:48 now when it when it came to leading a
9:49 group of engineers in design
9:52 and applying design methodology
9:55 i i felt pretty skilled at that but when
9:58 it came to really
10:00 designing a product for the market
10:03 i realized i had a lot to learn and the
10:05 first thing that helped me a lot was
10:07 discovering after i'd learned some great
10:10 design methodology
10:11 and i'd learned the six thinking hats
10:14 for
10:14 managing egos and debate that are
10:16 prevalent in my culture
10:19 i came across a gentleman
10:21 named steve blank out of stanford he was
10:23 a professor there at the time now he's
10:26 just he's he's a consultant i think he's
10:28 retired from being a professor at
10:30 stanford but
10:32 really got my attention with the spirit
10:35 of customer centric design
10:38 and just at a very high level in a in us
10:42 to get the spirit of it across
10:45 i would say it's this
10:48 and and by the way
10:50 i'm speaking to business acumen in the
10:53 sense of how would a data scientist fit
10:56 into
10:57 exercising good business acumen well the
11:00 first thing i would say is
11:02 don't burden yourself with being a
11:05 domain expert or a subject matter expert
11:08 or
11:10 having exceptional business acumen at
11:13 the company or organization you're
11:15 serving why do i say that
11:17 i'm not saying don't try to get good at
11:19 it but if you go in and tell a leader of
11:22 a business
11:24 what they need to hear from
11:26 you they're gonna look at you like i run
11:30 this business i know what the concerns
11:32 are so i encourage all data scientists
11:36 don't go in that way go in with what are
11:39 your biggest concerns
11:42 what are the things that cause you to be
11:45 afraid
11:46 what are the things that keep you up at
11:48 night i want to know those things then
11:50 what i want to tell you i'm going to do
11:52 i'm going to go look at our current data
11:54 assets
11:56 and i'm going to create a matrix and i'm
11:59 going to look for the strongest
12:01 intersection of business need and
12:03 current data assets
12:05 and
12:06 if there's a business need that was
12:08 really high that we didn't have
12:10 adequate data assets for i will
12:12 encourage collection of the data we need
12:15 to answer questions for that but i want
12:17 to get started right away
12:20 then it's a spirit now let's bring steve
12:22 blank into the picture
12:25 sorry for interrupting you i'm just
12:27 like it's a bit controversial the the
12:29 device i just mentioned so you're saying
12:31 do not focus on uh
12:35 being the
12:36 best domain expert because this is not
12:38 your job as a data scientist
12:40 but ask your management about like what
12:43 is important did they get it right or
12:46 exactly because
12:47 how can you be a really good data
12:49 scientist
12:51 and domain expert
12:53 in fact
12:54 when i'm in an interview
12:56 where someone seemingly wants me to
13:00 show that i'm a domain expert
13:03 in their domain i almost intended alexi
13:06 to say
13:07 i think i'm in the wrong interview i was
13:09 interviewing for a data scientist
13:11 position
13:12 and the kind of questions you're asking
13:14 me right now
13:15 i would create a framework and go fill
13:18 it in by talking to the domain experts
13:20 because how can i be a domain expert and
13:23 a data scientist i want to serve the
13:25 domain experts and the business leaders
13:29 and if that's controversial i will
13:31 continue to be politely controversial on
13:34 these points
13:35 because and it makes little sense
13:38 i think it's important to improve our
13:41 business acumen in the domain that we're
13:43 serving
13:45 but
13:46 let me say this
13:48 you you've heard this like uh 80
13:51 of machine learning models don't make it
13:53 into production
13:56 well my first question and i speak on
13:58 this with my dear friend and we call
14:00 each other brothers greg quia
14:03 he's a
14:04 he's a technology specialist manager at
14:07 amazon
14:08 and we make the point that
14:10 hey let's take the focus on that what
14:12 we're really looking for is a return on
14:14 data
14:16 what if as we're developing
14:19 as we're looking for opportunities to
14:20 develop machine learning models
14:23 we've got gained so many insights along
14:25 the way that now we have a good data
14:27 story
14:28 and that data story can help the
14:30 business well we're going to deliver
14:32 that before we worry about putting a
14:34 machine learning model into production
14:37 so let's take the focus off of
14:40 how many machine learning models get
14:41 into production and let's have the focus
14:43 on how much value are we deriving from
14:46 our data
14:48 that
14:49 when we talk about that 80 percent
14:52 that we do on data munching and
14:54 preparation before we get to the
14:56 modeling phase in developing machine
14:59 learning pipeline i would say 80 percent
15:01 of the insights you can give back to the
15:03 business come from that 80
15:07 of the machine learning preparation for
15:08 example
15:10 i may not always use linear and logistic
15:13 regression
15:14 for
15:15 my
15:16 machine learning production
15:18 my model that goes into production
15:20 but i will always look at it why
15:22 because it gives me a great pareto of
15:25 feature importance
15:26 well
15:27 wouldn't that be as important maybe more
15:30 than predictions from a model i mean
15:32 yeah you can react predictions and model
15:35 to them from a model but you can proact
15:39 to understanding what features are most
15:41 important
15:43 like
15:44 you think of the wisdom of the gallup
15:46 strength finder poll they're they're
15:47 like exploit your strengths well
15:50 if we know this features most important
15:52 business-wise we can focus on the
15:54 variables coming in
15:56 for that feature how can we get that
15:58 even stronger how can how can we get the
16:00 variables more toward the the positive
16:03 end of that or
16:05 there's a negative feature
16:07 that's really strong
16:08 that's important knowledge too well how
16:10 can
16:11 you know we reduce that
16:13 so that we get the performance we want
16:15 but back to steve blank
16:19 as you're developing your pipeline
16:22 i think and
16:24 i suck at this but i'm trying to get
16:26 better at it
16:28 deliver crap
16:29 as fast as possible
16:32 let me say it again
16:33 deliver crap
16:35 as fast as possible
16:38 yeah thank you
16:39 and and you know i'm leveraging a little
16:41 bit from dave and andy the pragmatic
16:44 programmer
16:45 they talk about tracer bullets
16:47 and um
16:48 can i can i use bad language on this
16:51 show
16:52 um just a little bit a little bit okay
16:55 okay i have a term well i'll modify it a
16:58 little bit but y'all will know the word
16:59 i would have used
17:01 i believe now in a crappy tracer bullet
17:05 and that means i want an end-to-end
17:07 solution it may not have all the
17:09 features i wanted to have but i've
17:11 tested it end-to-end
17:13 and i'm just making sure the end-to-end
17:15 works now i can build the thickness of
17:18 that process
17:19 get it all get all the features in it
17:21 that i wanted
17:23 but even before you get that end to end
17:25 if you get some insight
17:28 check and you're doing customer centric
17:30 development again your customers can be
17:33 a combination of your domain experts and
17:35 your business leaders have a spirit of
17:39 getting frequent feedback
17:41 during the course of your development
17:44 now here's the other part of getting a
17:48 better return on data
17:53 you're marching toward this and
17:55 you're helping the domain experts and
17:58 the business leaders understand what
18:00 you're doing and why
18:03 but if you're really going to get a good
18:05 return on data the collaboration needs
18:07 to go both ways you've been working to
18:10 understand their needs
18:12 they need to understand why you're doing
18:14 your processes and why they're important
18:16 again we're not asking them to become
18:19 data scientists or data evangelists
18:21 themselves we're saying
18:24 appreciate what we're doing appreciate
18:25 why we're doing it because then our
18:28 collaboration will be optimized it'll be
18:32 much better
18:33 instead of you just saying go off and do
18:35 this and then we try to do it no there's
18:38 so much more value in the actual process
18:41 and you
18:43 me understanding what's worrying you and
18:45 you understanding how why i'm serving
18:48 your questions your needs the way that i
18:50 am
18:51 see if i can summarize what you said so
18:54 you said deliver crap as fast as
18:55 possible and then you show it to your
18:59 end users to the business to
19:01 and then you get feedback and then yeah
19:03 you really want to use this crappy
19:06 solution that you develop really fast
19:08 to get if this is serving their need you
19:11 want to get feedback from your users so
19:13 you want to get insights from your users
19:15 and then you learn a lot just by doing
19:17 this right so you don't have a lot of
19:20 time a lot of effort in developing
19:23 your solution but you are learning from
19:26 what you get as a result as a feedback
19:28 right and then you iterate all right
19:30 that's the essence
19:32 yeah exactly let me give you some for
19:33 instance
19:35 okay
19:36 the first thing you're you're doing your
19:39 etl extract transform load i i don't
19:42 like that acronym but it's not bad
19:45 acronym it's just the spirit of yeah
19:47 we're getting the data
19:49 well
19:50 was that very smooth if it if it's not
19:54 like
19:56 really
19:57 reliable and easy to do that
20:00 you need to go ask the organization hey
20:03 just some constructive feedback it would
20:05 make it better for our etl work in my
20:07 data science group if you all could fix
20:09 these things
20:11 now we're marching along
20:13 we start to visualize the data and we
20:15 start obviously just to discover some of
20:18 the dirty data
20:20 well a lot of data is collected by data
20:23 management systems of some kind where a
20:26 programmer has made sure the data coming
20:28 in will go into sql safely and it
20:31 provides an insulation of the database
20:33 too
20:35 but let's say you're getting a lot of
20:36 null values
20:38 why
20:39 no values aren't missing values are not
20:41 good for me can you make sure people
20:44 have to enter a
20:46 value for this field oh we don't like to
20:48 do that well
20:50 it's costing us money and let me make
20:52 the case and so
20:54 i would say this is where we need to be
20:56 the most
20:59 how do i put this
21:01 adamant the most
21:04 you know
21:05 there used to be a term
21:07 a strong arm to just say no
21:10 this is not good
21:11 data is our platinum data is our
21:15 most valuable asset you can't just
21:18 nearly really allow people to not enter
21:20 a field here well can't you automate
21:22 your missing but yeah i could but it's
21:25 not going to help our modeling it's not
21:27 going to help our data storytelling just
21:30 make sure this field can't no i'm not
21:32 saying you would normally get into an
21:33 argument like that i'm just saying
21:35 be prepared to be very strong about
21:37 clean data do you do this as a data
21:40 scientist like as a data scientist or
21:44 you know
21:45 you go to your manager and then
21:47 your manager does that like as a usual
21:49 data scientist you don't always have
21:52 this
21:53 possibility to to code to go to the
21:55 users who are not entering the data and
21:57 then
21:58 making a case for them it depends on the
22:01 size of your business in your company it
22:03 depends on the culture you're in
22:06 but here's the spirit
22:09 who does david data governance belong to
22:13 i think it belongs to everyone
22:15 and if people are data literate and they
22:17 understand the power of data who is not
22:20 going to care about clean data
22:23 people that don't care about clean data
22:25 are people that don't know how important
22:27 data is how it affects the profits of
22:29 the company how it affects the affects
22:32 the
22:33 decision-making abilities of the company
22:35 so
22:36 data government governance is everyone's
22:39 responsibility a big part of that is
22:41 making sure we have clean complete data
22:44 so that that's a that now we go to we
22:47 continue down the pipeline hopefully
22:49 we've instigated or initiated
22:52 some better data collection practices we
22:54 might realize too
22:56 this is data we don't have we need to
22:58 start collecting and so we get a
23:00 collection effort going there and i
23:02 agree with you lexi we really want to
23:03 kind of hand these things off to the
23:05 manager if we're but if we are the
23:07 manager we want to read those efforts of
23:09 course so
23:10 as sorry for interrupting you i'm just
23:12 trying to connect these new values to
23:16 um to business acumen so
23:18 like for us when we see okay there is no
23:21 value so we don't just um no okay like
23:25 whatever no is no but we ask
23:27 ourselves why it's no how many new
23:30 values are there we try to
23:32 relate this
23:33 i don't know four bytes record in a
23:35 database to something real like what
23:38 does it mean right you try to understand
23:40 that and then you
23:41 it turns out that it's just people
23:44 are lazy they don't want to feel this
23:46 field even though they are supposed to
23:48 right and then you get this business
23:50 understanding is it right
23:53 yeah but let's let's think of it this
23:54 way
23:55 a lot of people are correctly shifting
23:58 from saying data driven to data informed
24:01 i i kind of like the tony stark
24:03 mentality is it too much to ask for both
24:05 you know we can we can also be i mean
24:09 market analysis causes us to be data
24:11 driven right
24:12 but when we're talking about data
24:14 science
24:15 more often yeah it's data informed
24:18 um so
24:20 i would like businesses to think you
24:22 still need to be data driven but
24:24 as far as your data scientists that's
24:26 probably more data being data informed
24:29 what's this what's that actually what's
24:31 data data informed
24:33 yeah those are two different um
24:36 philosophies that your business should
24:38 be data driven
24:40 um
24:40 [Music]
24:42 it's
24:44 are you doing marcus market analysis for
24:46 example to make sure you understand why
24:48 you're taking the direction you're
24:50 taking
24:51 have you really done enough analysis to
24:53 know what feature needs improvement
24:56 right away
24:57 things like that whereas data informed
25:00 is
25:01 okay there's a separate realm of saying
25:04 okay
25:05 the business leaders have the business
25:07 expertise yeah they may have a different
25:09 group that's helping them understand
25:12 what initiatives to take but then at
25:15 that point the kind of work that data
25:16 scientists and machine learning
25:18 engineers do data storytellers is
25:22 we're informing the business with data
25:24 we're giving them information very
25:27 refined even to the level of a
25:29 prediction
25:31 and
25:33 but back to your earlier point
25:37 how does making sure you don't have a
25:40 missing value in a critical feature
25:43 relate to business acumen well if you
25:45 want to be business and if you want to
25:47 be data informed
25:50 now you have less
25:53 you're not being as well data informed
25:55 if you have missing values for a
25:56 critical feature
25:58 and that's my point is
26:00 that really
26:02 this is
26:03 this is a system
26:05 business is a system and your data
26:07 scientists
26:08 are part of your feedback for that
26:10 system that's how you stay data informed
26:12 think about a feed that control system
26:16 if the data scientists and the data
26:18 storytellers the data evangelists the
26:20 data specialists aren't monitoring
26:23 the data performance of the company how
26:25 do we have feedback to know where we
26:27 need to improve the business
26:29 but also
26:30 where does the business go
26:34 i think it's a little premature
26:36 personally
26:38 to take the focus off being data driven
26:41 in business because
26:43 what
26:44 how are you going to know
26:46 where to drive your business without
26:47 data it may be a different type of data
26:50 than what your data scientists work on
26:52 but the spirit is
26:54 if you want to improve business acumen
26:58 that's
26:58 that's not just a burden on the data
27:00 scientists to understand the business
27:02 it's also a burden on the business
27:04 leaders and domain experts to understand
27:07 how data informs their decisions
27:10 and so it's it's a complete cycle it's a
27:12 complete system
27:14 where
27:16 this isn't just about us having better
27:18 business acumen it's about the business
27:20 leaders that are the business experts
27:22 improving their business acumen but with
27:25 data in a collaboration with their data
27:28 evangelists
27:29 by the way i like to say data
27:31 evangelists because there's a lot of
27:33 valuable data specialists out there that
27:36 would say i'm not a data scientist but
27:38 when you look at what they do
27:40 they're doing at least 80
27:42 of the work a data scientist would do
27:44 but they're doing it very thoroughly in
27:46 a very explainable way
27:48 and i'm always encouraging people that
27:50 come to me for mentoring oh you want to
27:52 be a really good data scientist then
27:54 become a really good data storyteller
27:56 that's a great way to start oh you're
27:58 afraid of the math right now get good at
28:01 power bi and processing data and telling
28:03 stories with data that will make you a
28:06 better machine learning engineer a
28:07 better data scientist
28:10 so basically invest in uh
28:12 analytical skills right so how do you
28:14 can make sense of this pile of data how
28:16 you can
28:17 crunch it how you can summarize it and
28:19 how you can visualize it in a way that
28:22 is digestible and understandable for
28:25 even folks outside of the data
28:28 organization for business exactly let me
28:30 ask you a question to prove the point
28:33 alexi
28:34 do you think we always need a machine
28:36 learning model
28:38 to get to give value to the organization
28:41 about the data we're
28:42 analyzing yeah well uh probably not
28:46 i mean like sometimes
28:48 sometimes good data storytelling will do
28:51 the job and that's something we can
28:53 deliver very quickly
28:55 while we continue to work on a model to
28:57 see what additional value it might be
29:00 yeah and to your point about new values
29:02 and then convincing people to actually
29:05 feel this thing you mentioned that you
29:06 can
29:08 build a case to show how important it is
29:10 so instead of coming there and screaming
29:12 saying hey you must fill this in you're
29:14 responsible for the quality of data
29:16 instead you show that if they fill it in
29:20 this is or if they don't fill it in this
29:22 is how much money you lose right or if
29:24 you fill it in this is how much uplift
29:26 you're getting right and this is one
29:28 point you you can do this by so this is
29:32 this means being data informed right so
29:33 you show that you show a story you show
29:36 that
29:37 this is an important feature
29:39 but it's missing in 90 of the cases like
29:41 if it wasn't missing at all then this is
29:44 how much money we will get right or this
29:46 is how much uplift in some important
29:48 business metric we would get
29:50 absolutely
29:52 informed
29:54 exactly but let me give you another
29:56 for instance let's say
29:59 you're having a polite discussion with
30:00 your
30:01 your programmer that manages this data
30:04 management system
30:06 for controlling the way data goes into a
30:08 database
30:10 and i've seen cases where there was a
30:12 null value meaning a missing value and
30:14 when you really studied the set and you
30:17 looked at more of the data you realize
30:19 oh it's missing because
30:22 it's just implied that when that's
30:24 missing
30:25 it's because that item doesn't exist
30:30 but i still have to fix that
30:34 and it's still an uncertainty did
30:37 someone just forget to enter that or is
30:39 it really because that doesn't exist for
30:41 this record
30:43 it still
30:44 costs time for the data scientists where
30:48 if people care when they're entering the
30:50 data to get it complete
30:52 it just saves everyone time and it makes
30:55 the data more crisp more clear
30:57 it's less
30:59 it's
31:00 i don't think
31:01 we'll ever get rid of the need to clean
31:03 data but if data literacy improves
31:07 enough at the level that you and i are
31:09 talking about
31:10 we can at least reduce
31:12 that data cleansing work to a more
31:14 modest level
31:17 yeah i keep interrupting you so uh no
31:20 we're talking about etl so probably
31:22 maybe we can go back to that so we get
31:25 the data we see how smooth this process
31:27 is
31:28 we try to optimize it then we get the
31:30 data we visualize it we
31:33 find dirty data we try to fix it and
31:35 what is next like i imagine this was
31:38 some sort of sequence and we stopped at
31:40 you know visualizing so what is going to
31:42 be next
31:43 yeah i call what we're walking through
31:46 right now the machine learning
31:47 development pipeline
31:49 and
31:50 obviously too once you've completed this
31:52 development
31:54 you're putting a completed machine
31:56 learning pipeline into production
31:58 so the next stage after you've cleaned
32:01 is to condition your features
32:04 let's remember
32:06 all machine learning problems are math
32:08 problems
32:09 um really all data science work is math
32:12 problems they say oh wait what about nlp
32:14 well to do nlp you're converting all the
32:17 words or tokens or whatever you want to
32:19 call them
32:20 into math into numbers so you can do
32:23 math with it then yeah
32:25 based on some
32:26 index to word
32:29 after the machine had the math machine
32:31 has processed everything
32:33 it gives it back as words sure
32:36 but what's going on in the bowels of the
32:38 machine the math machines that are
32:40 hooked together saying a big giant
32:42 transformer that's all numbers
32:45 so
32:46 feature conditioning
32:48 we need to convert text
32:50 to numbers
32:52 and that can be as simple as one hot
32:54 encoding or ordinal encoding then it can
32:56 get into tokenization of documents etc
33:02 and then there's all sorts of processing
33:03 that goes with that so this is all
33:05 feature conditioning
33:08 and it can get quite complicated for
33:10 example in a modern transformer
33:13 the tokenization isn't written by a
33:15 human it's learned by the machine and
33:18 then it even adds positional encoding
33:20 now it's
33:22 it's mind-bogglingly elegant and
33:24 beautiful the way it goes about it
33:27 it's embarrassing to see what the
33:28 machine comprises for tokenization
33:32 because of how inconsistent we are with
33:34 our language and how consistent it's
33:36 trying to be with the language we're
33:38 feeding it but then
33:40 once you have your features
33:42 conditioned well and you may have to
33:44 condition your labels too
33:46 you probably
33:47 many times do
33:49 now we need to say well i've got all
33:52 these features but which ones are
33:54 important and which ones aren't
33:57 and so that's feature reduction i
33:59 actually
34:00 would prefer to call it
34:02 feature set optimization but we've all
34:05 said feature reduction now
34:07 and it's not the best term but in just
34:09 the spirit of
34:11 i need
34:12 these set of features
34:14 that are important to this prediction
34:16 i don't need more and i certainly don't
34:18 need fewer i need
34:20 this specific set and there are some
34:22 cool arts to determining that yeah so
34:25 that's how you develop business acumen
34:27 one of the things as well so you look at
34:29 the important features and you try to
34:30 map it again to the business problem
34:33 right even though it's math but uh
34:36 you don't look at this as just numbers
34:38 you're trying to connect it to
34:40 whatever business problem you're solving
34:42 right and this is how you develop
34:44 your
34:45 domain expertise in a way like you you
34:48 understand okay this is what it means
34:50 and this seems important right so let's
34:52 keep this feature
34:54 this is a great point you're making and
34:56 let's let's think of it this way too
35:00 it would be a mistake
35:02 to go to your domain experts and say
35:06 what are the features and trust that
35:08 blindly now i would say what do you
35:10 suspect the features will be
35:13 but then
35:14 i will come back and show them hey you
35:16 were right i'm finding that these are
35:19 the features but i might say
35:21 what would you say if i said this
35:23 feature had this relative importance
35:26 they go wow
35:28 that makes sense but i hadn't thought of
35:29 that
35:30 now they're being data informed
35:32 the business leaders knowing right away
35:34 these are the features we're finding
35:36 important for this dynamic for this
35:39 modeling
35:40 wow that's helpful thank you
35:42 and so
35:43 but that doesn't mean our work's done
35:45 um oh also scaling i i'm not sure i said
35:48 that and why do we need to scale our
35:50 features
35:52 to get them on a level playing field
35:55 now
35:56 i can imagine some purists which i tend
35:59 to be thinking
36:02 well if i scale the feature
36:05 um isn't that
36:07 changing it from you know the original
36:10 values and so well
36:12 if i start reporting
36:14 feet in miles instead because there were
36:17 so many feet does that concern you as
36:19 long as i have a enough decimal decimal
36:22 places no
36:23 well if i convert
36:25 you know anything to to just a new scale
36:29 is that really taking away from
36:32 what the features are telling us i guess
36:33 not when you think of you know just
36:36 changing scale of unit from like miles
36:38 to feet or meters to kilometers or
36:40 whatever so that's what we're doing
36:42 because if we don't get those
36:46 features
36:47 on a common numerical scale
36:50 then when we go to find the weights of
36:53 the features
36:54 using modeling
36:56 and this is just initial modeling it's
36:58 not necessarily the modeling we put in
37:00 production
37:02 how would i then know
37:05 the relative importance of those
37:06 features because the big number ranges
37:09 are just going to have
37:11 huge weights or small weights and the
37:14 the small ones that are important might
37:16 have an inflated one
37:17 so if we put them all on the same
37:19 playing field the scaling becomes
37:22 essential
37:23 uh
37:24 just
37:25 it's a an absolute prerequisite to being
37:28 able to understand feature importance so
37:30 but
37:31 going back to feature reduction or
37:33 getting that optimized feature set that
37:36 doesn't mean we're done
37:38 it might now we have to say
37:41 all right
37:42 what feature engineering might we need
37:46 and i'm not sure everyone realizes that
37:49 skilled
37:50 i've done a lot of experiments with this
37:55 if you engineer
37:57 a feature from
38:00 say
38:01 i'm sorry if you get an engineered
38:03 feature from an original feature and
38:05 it's not interacting with other features
38:08 that's highly co-linear by the way
38:11 and you need to be prepared to not be
38:13 alarmed by that so this is
38:15 the to me there's this ongoing debate in
38:17 my mind
38:19 should i do feature engineering before
38:21 feature reduction and all i can say is i
38:23 think it's going to be a cyclic
38:26 and it just depends on each individual
38:28 problem but
38:30 there are some times where feature
38:32 engineering is absolutely important
38:35 and you can even
38:37 drop the original feature in favor of an
38:40 engineered feature so for example i've
38:42 got just
38:44 some values as a feature
38:47 now i try the square of those values
38:50 and i try some different modeling and i
38:52 find that when i take away the original
38:54 feature and only use the square of those
38:56 feature values
38:58 it's much more accurate that's okay
39:01 it happens but sometimes there's high
39:04 degrees of interactions and high orders
39:07 of feature engineering in order to model
39:10 what we need to model and that's very
39:12 insightful too and i think also coming
39:16 back to this future engineering and
39:17 creating new features i think
39:20 by doing that you also learn about learn
39:22 more about the business so for example i
39:24 work at elix and this is like online
39:26 marketplace so we have sellers we have
39:28 buyers and they exchange goods on the
39:30 platform
39:32 and what we track is the number the like
39:35 chat messages right so you can see that
39:37 it's just a number so
39:39 like for these two people they had so
39:41 many like this man so this person had
39:44 that many uh messages right that many
39:46 messages coming or incoming but a good
39:49 feature there was a number of meaningful
39:51 conversations between people like how
39:54 many and meaningful meaning like
39:56 somebody sent a message somebody replied
39:58 and somebody replied again like you know
40:00 that there was uh you know some
40:02 communication
40:04 and this is an engineered feature
40:06 right so we look at the raw data and we
40:08 created this feature called meaningful
40:10 conversation
40:12 and this gives us a lot of knowledge
40:14 about what happened so we by engineering
40:16 in the future we were able to
40:19 understand the business process better
40:20 like how
40:22 uh
40:23 like how this data actually
40:24 affects our model and uh
40:27 yeah and there is also some meaning
40:29 behind this feature right so these
40:30 people had some conversation it wasn't
40:32 just hi and nobody replied but they
40:35 actually talked right so
40:38 and then you learn about the
40:41 process i think this is important when
40:43 you create such features
40:46 no that's that's uh
40:48 that's awesome i agree with you
40:50 and then once we've engineered the
40:52 features
40:54 we still have other questions before we
40:57 go into choosing models
40:59 for example
41:02 a lot of times the way we experiment
41:05 with engineered features is to
41:08 throw a lot of polynomial features into
41:10 the mix with the polynomial features
41:12 class from scikit-learn
41:15 well now we have to go through that
41:16 process again of saying
41:19 which of these features might i be able
41:22 to excuse me which of these engineered
41:24 features might i be able to drop
41:27 and we've got great tools to help us
41:28 with that analysis
41:31 and then
41:32 if your problems really sticky and that
41:35 it's really hard to get rid of the
41:36 co-linearity from the original feature
41:39 set
41:39 and it's really hard to get the right
41:41 interactions
41:43 for
41:44 uh the engineered features
41:46 we have this magic tool
41:49 called principal component analysis
41:52 and
41:53 i've been a fan of that since grad
41:56 school
41:58 we use those kind of things in robotics
42:01 in electrical engineering
42:04 in other words electric circuits
42:06 we use it in vibrations analysis control
42:10 system design
42:12 because
42:13 there's not a dynamics field where you
42:16 don't care or it doesn't have to be just
42:18 dynamics but
42:19 we don't care about the eigenvalues and
42:21 the eigenvectors
42:23 they're very informative they tell you
42:27 the singularities that can happen in
42:29 your system and so
42:31 but for us as data scientists and
42:34 machine learning engineers where pca
42:36 becomes
42:38 super important
42:39 is
42:42 to figure out well now that i've
42:44 i want i want to emphasize
42:47 being in pca space
42:49 is not the same as being in the original
42:51 feature space
42:53 it's a totally different perspective
42:55 now you can relate the two through the
42:57 eigenvalue excuse me through the
42:59 eigenvectors and you want to do that
43:02 let's say you end up using pca
43:05 now the burden of explanation is harder
43:07 on us as data scientists and machine
43:09 learning engineers because we got to say
43:11 this was the most important pca feature
43:15 but when we transfer that back to
43:16 original space it's a combination
43:19 of this proportion of original space
43:21 features
43:22 and when the
43:24 you know hopefully we've been we've
43:27 educated in simple layman's terms enough
43:30 our domain experts and business leaders
43:32 to help them understand
43:34 we went into pca
43:36 kind of as a last resort we went into
43:39 the eigen space as a last resort because
43:42 we have to explain it's harder to
43:43 explain it's not impossible
43:45 but we did it because
43:47 there was such messy co-linearity and
43:51 my family and i of integrated machine
43:54 learning and ai family members like to
43:56 explain it this way
43:59 co-linearity is just like let's say you
44:02 have a football team i'm speaking
44:04 internationally not american
44:07 soccer team for americans and
44:10 you're saying
44:11 there's there's two guys
44:13 playing the same position
44:15 well what happened to the
44:17 position that one of those guys should
44:19 have been playing now there's three guys
44:21 playing the same position
44:22 hey we need to fix that
44:24 we just want
44:25 one feature
44:27 emphasizing each important aspect of
44:30 this problem when we have co-linearity
44:32 it's saying no those are too closely
44:34 related we don't need all of we just
44:36 need the strongest one
44:37 well when it's really hard to divide
44:40 that up pca magically decouples all that
44:43 it gets rid of all the co-linearity
44:46 but it also allows you to do this fancy
44:49 thing that's actually quite simple
44:51 called parsimony
44:53 and we're just saying
44:55 hey we always want
44:57 the simplest model that does
45:00 a great job
45:02 and i've violated this principle
45:04 sometimes too
45:05 going for a more complicated model but
45:07 the spirit is
45:09 it's really elegant and easy because you
45:11 can say well which eigenvalues are very
45:14 small
45:15 then we obviously don't need those
45:18 pca features related to those
45:20 eigenvalues now
45:22 we have the we've reduced the problem
45:25 we've got it all decoupled and it's
45:26 quite easy to do the feature engineering
45:29 in the eigenspace too but again that's
45:33 that magic space and then we go into the
45:34 model in realm that's uh who wanted to
45:36 say that it's first time so i've been
45:38 doing this podcast for like i don't know
45:40 10 months almost a year first time
45:42 somebody mentioned
45:45 these terms eigenvalues and eigenvectors
45:47 and it's funny because this episode is
45:50 about business argument
45:52 oh
45:53 when you get down to it yeah you have to
45:56 throw
45:57 pca into the mix and you're trying to
45:59 give insights from each step in the
46:01 pipeline back to the business
46:04 you do have a burden to say well we we
46:07 did analysis that we explained here but
46:09 we ended up using pca
46:11 the business leaders
46:13 may not care
46:14 and when they don't i think shame on
46:16 them they should at least appreciate
46:19 why we had to do that but if if they're
46:21 saying no i don't want to hear that
46:23 that's that's regrettable
46:26 and you should be prepared to explain it
46:28 in layman's way
46:29 but
46:30 but when we get into the modeling
46:33 um you know we have metrics to help
46:35 choose the models we we
46:38 don't fall into the accuracy trap
46:42 you want good accuracy
46:44 but you want consistent accuracy that
46:47 means good general
46:49 generalize it's
46:51 in other words
46:52 it's a generalized model it'll work
46:54 across a lot of data or as much data as
46:57 possible so we use
46:59 obviously the method of cross-fold
47:01 validation
47:02 for that but literally we want to see
47:06 a distribution of accuracies across
47:09 those folds
47:10 with the least variance and when we find
47:13 the one with a good balance of accuracy
47:16 and low high accuracy and low variance
47:18 that's our model
47:19 not your favorite algorithm the one that
47:22 general you know has that best balance
47:24 of
47:25 accuracy and generalizability
47:28 and all of that's important
47:30 it's and it's important for the business
47:32 leaders to understand
47:34 we have these battles to figure out
47:35 which model's best and then
47:38 let's say you do get a machine learning
47:40 model into production and it's informing
47:42 the business and the business acumen of
47:44 the organization has increased through
47:47 this model
47:49 the work's ongoing
47:51 it's constant human overwatch to say
47:53 okay we're collecting more data assets
47:56 we hadn't approached the central limit
47:57 theorem yet with our data assets and
47:59 these feature groups
48:01 so we're going to have data drift
48:04 you know what we may have to adjust the
48:05 hyper parameters on this model we might
48:08 need a whole new model algorithm to do a
48:11 better job
48:12 based on the shift in data assets now
48:14 when might that go away
48:18 probably never but if you approach the
48:19 central limit theorem
48:22 and there's no data drift
48:25 for years that model can be useful for
48:27 years
48:28 but
48:30 things usually do change in society
48:33 will cause in other words the central
48:35 limit can start to change itself
48:38 or
48:39 you can have concept drift what if a new
48:41 feature is introduced into a process
48:44 that's concept
48:46 that may mean that oh i have to add a
48:48 new feature so we're constantly
48:51 as much as we have time with to do
48:54 bandwidth do
48:56 we're look we're challenging is that is
48:58 the model in projection
49:00 continuing to be the best model for
49:02 production
49:03 now i would i would just submit
49:06 from a data science point of view
49:08 them feeding back this info them
49:10 educating the greater group
49:13 on why data science is important why
49:15 machine learning is important
49:19 this improves business acumen not just
49:21 for the data sciences but for the
49:23 business leaders and the domain experts
49:27 yeah that's that's interesting so i'm
49:29 just trying i was thinking now
49:32 of all the things we discussed i'm
49:34 trying to summarize it into
49:37 uh the most important business skills
49:39 for data professionals and i was
49:41 thinking so first we mentioned data
49:43 storytelling right so
49:45 being able to
49:46 analyze the data crunch the data and
49:48 present it in a digestible form
49:51 to people who might be
49:54 not in the data world might not be data
49:56 scientists like business people
49:58 then explaining things in alignment
50:00 terms even if it's pca but you still
50:03 need to be able to explain what's going
50:05 on
50:07 what is happening like all these
50:08 eigenvectors eigenvalues to be able to
50:11 translate it into
50:12 a common language people understand
50:14 right
50:16 um then educating why data science is
50:18 important so this is uh also
50:20 you as a data professional should also
50:23 be able to do
50:24 like saying okay you you really need to
50:27 be careful about this value like you
50:29 really need to pay attention and not
50:30 forget to feel it right and then
50:32 be able to show convincing arguments why
50:35 you need to do this so what are the
50:37 other important business skills that i
50:40 missed
50:41 well
50:43 i'm
50:44 i'm laughing because of something i
50:46 learned the hard way
50:48 and i'll share it as a story because i
50:50 think it'll be more powerful that way
50:52 so
50:53 and i'll just use first names but
50:55 they're the real names
50:57 so my buddy rick he's vp
51:01 of this business in this big company
51:04 and
51:06 i send him an email
51:09 about an idea i have that's data science
51:11 related experimentation platform related
51:13 based that would help us understand a
51:15 lot of things we've been trying to
51:16 understand better but i make the fatal
51:19 mistake of see seeing some other people
51:21 now
51:22 i'm just an engineer
51:24 but rick's my buddy he's a vp but all
51:27 these ants act like their
51:29 anthill was stepped on and another
51:32 distinguished technologist came in the
51:34 middle of the conference and dressed me
51:36 down for sending that email and
51:39 i i had an appropriate reaction to him
51:42 anyway
51:44 long story short and then my whole team
51:46 rallied around trying to save tom from
51:48 this email he said
51:51 we gave this big formal presentation
51:53 that was cleansed and everything
51:56 and uh
51:58 later i see rick in the hallway after
52:00 he's asked a lot of challenging
52:01 conversations and listen to this dog and
52:04 pony show presentation
52:07 rick
52:08 all i really was trying to get at is
52:11 why can't we just experiment with these
52:13 devices that we
52:15 own and just lease to the people they're
52:18 ours
52:19 we can do some small
52:21 factor analysis experiments with the
52:24 nova and stuff he said tom i've had that
52:26 same question
52:28 and so here's what i'm trying to get at
52:33 and this is all you need to remember
52:34 lunch and or beer
52:37 and do it frequently in other words rick
52:40 can we go to lunch rick let's go out for
52:43 a beer after work
52:44 i want to talk to you about something
52:46 that would have been far more productive
52:48 and we could have had a lot of micro
52:50 meetings
52:52 then
52:52 me
52:54 making the mistake of sending a formal
52:56 email and see seeing a lot of
52:57 stakeholders
52:59 like no just kind of you know try to be
53:02 culturally savvy too
53:05 make a lot of these check-ins
53:08 these frequent
53:10 your frequently seeking feedback make
53:12 them very informal
53:15 hey
53:16 i just want five minutes of your time i
53:17 want to show you something
53:19 and then say
53:20 i'll always ask for help like i
53:23 think i can communicate this to you in
53:25 layman's terms but i may fail to do that
53:28 so i need you to let me know when you're
53:30 not really getting it and then that way
53:32 we're always in a continual improvement
53:34 mode
53:35 on how we talk data scientists to smart
53:38 people that aren't data scientists
53:40 excuse me how we talk data science to
53:42 smart people that aren't data scientists
53:45 but we're doing it in a very informal
53:47 frequent way and before we give that
53:49 formal presentation
53:50 now we have this host of friends
53:53 that know what we're doing and how
53:54 passionate we are to help the business
53:57 and they can inform
53:59 our presentation like oh don't say that
54:02 they won't get that say this and then
54:04 okay great thank you yeah you know the
54:06 way you described that the other day
54:07 that was perfect but the way you
54:09 described that last week that was really
54:11 hard for me to get let's find a better
54:13 way to do that
54:14 what i've found alexi when i do it this
54:16 way where i've had those frequent
54:18 check-ins with domain experts or
54:21 business leaders once we get to the
54:22 formal meeting and someone's just gotta
54:26 ask the challenging question you know to
54:28 show off
54:30 i'm not the one answering those
54:31 questions
54:32 the people that i've been meeting with
54:34 are defending everything i'm saying
54:36 but it's because i've cared too i've
54:39 cared enough to say i need your feedback
54:42 i need you to affirm that i'm on the
54:44 right track
54:45 to serve the needs of the business to
54:47 answer the questions the domain
54:50 expertise has here where where you're
54:52 weak in knowledge i'm trying to get it
54:54 more data informed so it's this constant
54:57 spirit of
54:59 do it frequently but if you're doing it
55:01 frequently formally that's going to kill
55:03 you
55:04 do it frequently informally lunch and
55:06 beer that's my summary lunch and beer
55:10 okay so basically the most important
55:12 business skill for data professionals is
55:15 networking being able to network with
55:17 people right networking making friends
55:20 making friends okay yeah
55:22 it's like this daily
55:25 now by the way
55:27 i wish i could say i learned all this
55:29 from doing it super well no i'm learning
55:32 a lot of it from painful hindsight but
55:35 getting better at it myself i'm a
55:37 student of it but it makes perfect sense
55:39 because i'm leveraging alexi the wisdom
55:42 we have from all of our beautiful arts
55:44 in stem
55:46 how
55:48 so what about alternatives in today's
55:51 world so there is a comment from
55:53 somebody named d so it's not always an
55:56 option in this working from home days
55:58 like once
56:00 when companies are now going full remote
56:02 like how do you
56:04 have a lunch with somebody who is even
56:06 in a different location but you have to
56:08 work together
56:10 so uh that's a great question
56:12 and
56:15 my best friend in the world right now is
56:18 someone i've never met face to face
56:21 so
56:22 i'm a an american born
56:25 to
56:25 worse i'm a texas born
56:29 convert to roman catholicism
56:32 and my best friend in the world
56:34 is a syrian born
56:36 arab muslim
56:38 now working in germany and we're writing
56:40 a book together but
56:42 we start all our conversations with i
56:45 have a confession
56:46 and then we but then we talk about our
56:49 work and then we spend maybe
56:52 more time usually talking about our
56:55 personal lives and things that are
56:57 important to us
56:58 fears we have
57:00 struggles we have
57:02 and it helps a lot but
57:05 i think
57:07 i don't have to drive to a lunch
57:09 location
57:12 then pay the bill
57:14 i can say
57:15 hey okay if i eat while we talk i
57:18 encourage you to do the same
57:20 um
57:21 i'm going to show this
57:22 one of my
57:24 sons see bought me this for my birthday
57:27 recently
57:28 but he couldn't ship it from england so
57:31 he said go buy it and i'll then mow you
57:33 the money
57:34 deal
57:35 you know what i'm getting at is i have
57:37 this close friendships more friendships
57:41 now that covet forced us to be virtual
57:44 like this i don't even like calling it
57:46 virtual i think i would like to call it
57:48 electronic or something or video
57:51 to me
57:52 yeah it would be nice to be face to face
57:54 with you alexi but the time to travel
57:57 to where you are
57:59 the expense this is pretty cheap
58:02 relatively speaking and yet we're still
58:04 you and i got to interact with that
58:06 great group in kenya together that's how
58:08 we first met we're getting to do this
58:10 now
58:12 please don't let this limit your
58:14 informal meetings just hey can you get
58:17 on a quick
58:18 zoom or a quick google me
58:22 yeah
58:22 i think it's possible
58:25 get good at sending memes to each other
58:28 that builds camaraderie
58:31 do you have a couple of more minutes
58:33 absolutely yeah because i wanted to talk
58:35 about integrated machine learning and ai
58:39 that you're doing so
58:41 can you tell us more about this you said
58:43 that like at some point of time you
58:45 started doing this
58:46 because you were getting a lot of
58:49 requests and to your surprise
58:52 you were very helpful right so how did
58:55 it
58:55 start and what you're doing now
58:57 so this is just
58:59 i have to confess that can be pretty
59:01 dense sometimes and uh
59:05 at my last three companies
59:08 it was obvious that people like to come
59:09 to me for help
59:11 and i'm still not getting it that okay
59:13 you're a good mentor tom
59:15 and
59:16 i like the way one of my daughters in
59:18 india put it again self-appointed
59:21 adoptions here not legal but not illegal
59:24 just non-legal
59:26 and uh
59:28 manpreet bhutraja she's been one of my
59:30 biggest cheerleaders and she's growing
59:32 rapidly herself now
59:34 but
59:35 she announced on a show it's not that
59:37 tom's
59:39 only a great mentor
59:41 he's a great learner and i'm just a
59:44 passionate learner really and i'm always
59:46 trying to improve the way i'm growing
59:48 and learning but i share that and i want
59:50 to hear how others
59:52 grow and learn better
59:54 well
59:55 when these
59:57 when these requests for mentorship
59:59 because
1:00:00 people that i helped they would write
1:00:03 really nice posts about me on linkedin
1:00:05 my followers went up but also
1:00:08 my direct connection requests and
1:00:10 you know will you help me we have a
1:00:12 one-on-one call and i would do it i
1:00:14 would make time for it but i took this
1:00:17 adage i i
1:00:18 i feel like i'm really living this now
1:00:21 do what you can
1:00:23 then do what's possible
1:00:25 and soon you'll find you're doing the
1:00:27 impossible
1:00:28 so from the very first time that i had
1:00:30 to go from one-on-one calls to a weekly
1:00:32 call-in i said look
1:00:36 there's a lot of people here
1:00:38 we need to we need to create
1:00:40 three things to make this work really
1:00:42 well first you have to be brave to ask
1:00:45 your question in front of others
1:00:48 and i might get this count wrong
1:00:51 then
1:00:51 i'm going to answer but i think everyone
1:00:54 else should give their thoughts too
1:00:56 because that will be even better and
1:00:58 will probably all be helped by doing
1:01:00 that
1:01:01 well it worked from the very first
1:01:04 question
1:01:05 and i can't remember her last name at
1:01:07 the moment but nevina she was the first
1:01:09 one to bravely ask a question and now we
1:01:12 have people all over the world saying
1:01:13 how much our family means to them
1:01:15 because it's a safe place to come to
1:01:17 really air their fears their concerns
1:01:20 when they're overwhelmed how to deal
1:01:21 with it because it's hard to be a data
1:01:23 scientist
1:01:25 it's hard to get into this field it's
1:01:26 hard to grow in this field
1:01:28 and i keep
1:01:30 if and they emphasize it now too
1:01:32 we will be we can do it better if we're
1:01:36 more together
1:01:37 and the more together spirit is
1:01:39 i don't want to be the best
1:01:42 i want to be a best what do i mean by
1:01:45 that
1:01:46 as i'm getting good at something alexi
1:01:48 and you want to get good at it too i
1:01:50 want to help you because if you get good
1:01:52 at it too you're going to have
1:01:54 perspectives and abilities in that that
1:01:56 i might not have
1:01:58 such that when you come up to my level
1:02:00 i could grow faster
1:02:03 with you than i would have without you
1:02:06 well now imagine that there's a group or
1:02:08 a family of people that feel that way
1:02:12 let me ask you this
1:02:14 would you like it
1:02:16 if dennis rothman considered you his
1:02:20 brother
1:02:22 maybe i didn't think about this
1:02:24 now dennis rockman he's this brilliant
1:02:27 ai mind he's written many books with
1:02:30 pact
1:02:31 he decided to have a show recently he
1:02:33 got his linkedin live he invited
1:02:36 us
1:02:37 from the family because he said i'm
1:02:39 you're my family now well
1:02:42 he was bringing up some really
1:02:44 important
1:02:46 topics that we hadn't even thought about
1:02:48 before
1:02:50 we wouldn't have that ability to do that
1:02:53 if
1:02:53 we hadn't just had this more together
1:02:55 spirit he got infected by it because we
1:02:58 invited him we wanted him to talk about
1:03:00 one of his books we asked him questions
1:03:02 he loved it he started just showing up
1:03:04 on his own
1:03:06 and uh
1:03:08 but
1:03:08 dennis isn't the only one we have these
1:03:11 other fantastic family members
1:03:14 who
1:03:15 this time last year
1:03:17 wouldn't have considered themselves data
1:03:19 scientists now
1:03:20 they're already mentoring new people
1:03:22 coming into the field
1:03:24 and
1:03:25 they're seeing the power it's having on
1:03:27 them
1:03:28 to have a more together spirit and a
1:03:30 best spirit
1:03:32 and
1:03:33 it's infectious because you grow
1:03:36 yeah so how can people join that how can
1:03:39 people uh
1:03:41 do this i will share
1:03:43 i will share a link that will always
1:03:45 work
1:03:46 they can just uh join our slack work
1:03:49 group
1:03:51 with this link and you can post this
1:03:54 and um i just asked that if you would
1:03:57 ask them to say hi
1:03:59 in the family chat channel i'll put that
1:04:02 in there too
1:04:03 can you send this link me afterwards and
1:04:06 linkedin because now this uh will be
1:04:08 lost
1:04:10 i will i'll send it to you over link
1:04:12 then i'll add
1:04:14 the description and uh anyone who is
1:04:16 interested you will find this in the
1:04:18 description
1:04:19 probably not right now in a couple of
1:04:21 hours
1:04:22 uh i'll put it there so if you want to
1:04:25 get the link now
1:04:27 maybe you know what i can actually send
1:04:28 it to live chat
1:04:31 i just need to
1:04:33 i i can put it in the uh linkedin later
1:04:36 but i think if you capture it right now
1:04:38 i'll just put it to live chat but it
1:04:40 will be gone uh
1:04:42 later yeah you can save the chat or you
1:04:44 can just copy and paste it now but let
1:04:47 me know if you need it again over
1:04:48 linkedin messaging and
1:04:50 uh to everyone listening
1:04:52 uh please follow me on linkedin i've got
1:04:55 my
1:04:56 my profile there real quick
1:04:59 let's see
1:05:00 take me just a second
1:05:02 i should have it memorized but it's
1:05:04 easier to copy and paste it anyway
1:05:08 okay going
1:05:11 it's being slow to load there we go
1:05:14 i
1:05:15 find the link it's uh like i
1:05:17 have it in my history because i was
1:05:19 chatting with you
1:05:21 almost there anyway oh it's being
1:05:24 no i found it i found it okay good
1:05:26 good good good
1:05:28 yeah it's just uh the normal stuff and
1:05:30 then tom ives all together
1:05:33 yeah but i think your name is pretty how
1:05:36 to say
1:05:37 look up
1:05:39 is it the word
1:05:40 yeah i think findable
1:05:43 yes right
1:05:45 okay yeah but i i think look up
1:05:47 should be a word that's it yeah well uh
1:05:50 it is from now right
1:05:52 there you go i did put it in our chat so
1:05:54 you have it okay thanks tom uh
1:05:57 a lot for
1:05:59 joining us today for sharing your
1:06:00 experience with us
1:06:02 your knowledge your stories and uh
1:06:06 yeah and thanks everyone for joining us
1:06:08 today as well for being here for asking
1:06:10 questions
1:06:12 and yeah do you want to say anything
1:06:14 before we finish
1:06:15 it was an honor to be here and i really
1:06:17 enjoyed our discussion i know i was
1:06:19 doing most of the talking but i really
1:06:21 did appreciate your questions it was
1:06:24 helpful
1:06:25 yeah that's the idea behind inviting
1:06:28 people you know that they talk most of
1:06:30 the time of course
1:06:34 we would love to have you come visit our
1:06:36 family and and give a talk about what
1:06:38 you do that would be uh
1:06:40 awesome