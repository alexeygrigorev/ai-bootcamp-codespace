0:00 hey everyone Welcome to our event this
0:02 event is brought to you by datadox club
0:04 which is a community of people who love
0:05 data we have weekly events and today is
0:08 one of such events if you want to find
0:10 out more about the events we have there
0:12 is a link in the description go there
0:14 click on this link and you'll see all
0:15 the events we have in our schedule
0:18 do not forget to subscribe to our
0:19 YouTube channel this way you will not
0:21 miss any future streams like the one
0:23 today and we have an amazing slack
0:26 Community where you can hang out with
0:27 other and date enthusiasts so
0:30 during today's interview you can ask any
0:33 question you want there is a paint Link
0:34 in the live chat although there are some
0:37 problems with my internet so I don't
0:39 know if this time I was able to
0:41 post the link but I will be monitoring
0:45 live chat too so in case the link does
0:47 not appear
0:48 and yeah
0:51 so I will be covering this question
0:52 student I will be asking this question
0:54 student interview
0:56 and with that I will stop sharing my
0:58 screen
1:00 and I will open the document
1:02 we prepared for you and
1:06 um
1:07 if you're ready to start we can start
1:09 yeah let's do this
1:13 foreign
1:15 this week we'll talk about GPT
1:18 s and building MLP products and
1:22 interestingly
1:24 in the last year we did not have any
1:26 talk about llams or GPT but today is our
1:31 second one in a row so the previous
1:33 interview the previous podcast interview
1:34 was also about the lamps so this is
1:37 purely coincidental we did not plan that
1:40 to have two talks about two interviews
1:43 about llms but this is how it happened
1:45 we try to
1:48 cover something new that we did not
1:50 cover previously and we have a special
1:52 guest today Sandra Sandra he is not new
1:55 to data talks lab
1:57 you might have seen her answering
1:59 questions in our book of the week event
2:02 with your book about gpt3 building
2:05 Innovative NLP products using language
2:08 large language models
2:10 so um Sandra is an AI entrepreneur
2:15 evangelist Community Builder and she has
2:19 done a lot of amazing things she will
2:21 probably tell us more about that today
2:23 so welcome to our podcast
2:26 thanks for having me Alexei super super
2:28 excited to be here
2:30 um yeah let's do this I'm not surprised
2:33 that there's it's it's a second
2:35 interview about Lance because they're
2:37 everywhere right now so yeah I mean we
2:40 are kind of late to the party because
2:42 like everyone was talking about the
2:43 lamps half a year ago and we were I
2:46 don't know how it happened but we were a
2:49 bit late but now you have we have two
2:52 events in a row so
2:56 the question for today's interview are
2:59 prepared by Johanna Byron thanks Johanna
3:01 as always for your help
3:03 and yeah let's start with interviews so
3:05 before we go into our into our main
3:07 topic of llms and GPT let's start with
3:11 the overground can you tell us about
3:13 your career Journey so far
3:15 yes so
3:17 um in terms of
3:19 when I joined the space it was five
3:23 years ago
3:24 um and I was always interested in
3:27 artificial intelligence
3:29 adoption so what will people do with AI
3:33 tools once they're out there how it will
3:36 impact their everyday life how it will
3:38 impact business Etc
3:40 um I started by actually starting my own
3:43 project
3:45 um an AI accelerator for startups called
3:47 Next grid together with my co-founder
3:50 Matthias and then
3:52 um with nextgrid we were aiming to
3:56 support startups at the earliest stage
3:59 so POC or pre-poc Sage
4:03 um
4:04 that want to be more business savvy and
4:07 want to gain further financing and
4:09 validate their Concepts further
4:12 next to next grids we also co-founded it
4:15 an a hackathon event platform
4:21 it used to be called Deep learning Labs
4:23 but it was rebranded to lab Lab AI so if
4:27 you want you can check it out if you
4:28 look yes love love AI so if you're
4:31 looking for
4:32 participating in a hackathons that use
4:35 the latest tech that's that's the one
4:37 for you
4:39 um and so through that we basically
4:41 tried to get closer to artificial
4:44 intelligence ourselves
4:46 but also let others play with the latest
4:51 tech out there it was around 2018
4:54 so the access to models started getting
4:58 easier and easier and so we were able to
5:02 you know
5:04 like spit off an environment and plug
5:06 into open AI gym and train a
5:09 reinforcement learning lunar ladder or
5:11 something like this so make a hackathon
5:13 out of it so we started doing these
5:15 hackathons and at some stage
5:17 um
5:19 I stumbled upon Next Generation models
5:23 so at that time GPT 2 was out and the
5:28 gpt3 was about to be out
5:31 um and I really wanted access to it so
5:35 I uh I have a friend called box
5:39 um
5:40 that I
5:42 say hi to he has a YouTube channel and
5:44 he started making YouTube videos about
5:46 gpk3 and also how he got access to gpd3
5:50 how he got into the Beta list and he got
5:54 it by making a video about it
5:56 so I figured that I might do the same
6:00 because I really wanted to play with it
6:01 so basically that's how my YouTube
6:04 channel started
6:06 um and it actually works like I did two
6:08 videos about different types of gpt3
6:11 demos I've seen out there at our
6:13 hackathons but also Beyond
6:15 um and I got access to it so I started
6:18 fooling around with it basically and and
6:22 the child got traction I I wasn't
6:25 expecting such attraction so quickly but
6:28 there seemed to be already back then
6:31 it feels like ancient history because
6:32 that was like three years ago
6:35 um you know interest in exploring this
6:38 subject it was quite a small community
6:41 at the time but once you talked about it
6:43 you were pretty recognizable
6:47 um so I did all sorts of things talk to
6:49 the founders that were building with
6:50 gpd3
6:52 um tested new tools that were coming out
6:54 to the market
6:56 um like playing
6:57 a dungeon and stuff like that you know
7:00 it was really fun generating Christmas
7:03 present ideas things like that so
7:06 um yeah then
7:08 I got approached by my future book
7:12 author Shaban Sabo
7:15 um and he offered to write a report
7:18 together about gpd3 but then the
7:21 publisher we were working with
7:23 offered that we write a book about it
7:25 and for me it was a great
7:27 opportunity to kind of get out of my
7:29 imposter syndrome and start diving
7:32 deeper into the field
7:33 so the book was kind of like
7:36 talking about the business side of
7:38 things but also the tech side of things
7:39 and once I
7:42 went down the rabbit hole I just felt
7:45 like this is really my domain and I
7:46 don't want to get out of it so so I
7:49 stayed and now I am working for cohere
7:54 um which is developing state-of-the-art
7:56 llms and I am building Community there
8:01 and I'm focusing on education about
8:03 large language models which brings me
8:06 here today as well
8:08 that's a quite a fascinating story like
8:11 how you made a video to just get access
8:14 to gpt3 I'm wondering if today I still
8:17 don't have access to gpt4
8:19 and uh I think because I never used my
8:22 API I didn't put any money there I only
8:26 even though I'm paying for chargept I
8:28 never used the Open Eye API with money
8:31 so I still do not have access to gpt4
8:34 then wondering now if I make a video
8:36 about gpt4 it will not help
8:38 because the community is so large yeah
8:42 it exploded like the scale of things is
8:45 just uh mind-blowing there are so many
8:47 videos right now about this like but
8:49 back then three years ago you know it
8:52 was a handful of people just exploring
8:54 it it was very new and yeah now now it's
8:59 exploded and now the market adoption and
9:03 interest is huge so we are
9:06 in a very interesting time when it comes
9:08 to elements
9:10 how did you actually make a video
9:12 without having access to gpt3
9:15 I was just talking about different types
9:17 of use cases I see in the future
9:20 and also different types of like Play
9:22 Projects toy projects that people were
9:25 having at the time that I found pretty
9:28 fascinating and that seemed to be enough
9:31 to get me into
9:33 if you if you're looking for a hack for
9:36 the future
9:37 yes try try any angle you can
9:40 to get somewhere no matter you know
9:43 whether you know about it or not whether
9:46 you have access or not yeah you can do
9:48 that or maybe with GPT is kind of late
9:52 because like the community is now very
9:54 large but for the next big thing could
9:56 be a good solution really yep
9:59 quite interesting
10:00 see your book is about business and Tech
10:04 side of GPT and telems right so what are
10:09 business cases for using GPT
10:13 yeah so
10:14 um
10:15 that's a huge question actually right
10:17 now especially at the at the time when
10:19 we were writing the book that was two
10:21 years ago
10:22 um we were talking to folks across
10:26 different verticals like entertainment
10:28 industry like creative Studios or
10:31 sales Assistance or code generators or
10:34 chat book providers and they were all
10:38 using GPT models text generation models
10:41 in their particular context
10:43 and already at the time you could see
10:46 both startups and more mature companies
10:48 playing with it and trying to adopt it
10:51 slowly slowly but since then so much
10:53 happens on the market that's really I
10:55 don't see
10:57 um
10:58 I don't see how
11:00 text generation models
11:02 are not relevance to a particular
11:05 industry you can basically use them for
11:07 any type of Industry I like to say that
11:10 um
11:13 with with llms we're kind of in this
11:17 next technology wave like in the past we
11:21 were with a web browser or even even
11:25 before with a personal computer so
11:29 we got this completely new type of tool
11:33 to interact with our machines
11:37 um using human language and
11:40 through that I can
11:43 Envision that we are just at the
11:45 beginning of it even though it's already
11:46 five years since Transformer
11:48 architecture which is the foundational
11:50 architecture for for LMS was founded but
11:55 um this is very very early days of the
12:00 very long
12:02 you know future business adoption and
12:05 all sorts of projects built on top of it
12:08 um it's also worth mentioning that
12:12 you know GPT type of architecture right
12:15 now it's trademarked by open AI but you
12:20 can have similar generative pre-trained
12:22 models that don't have a GPT in the name
12:26 but have very similar capabilities so
12:30 overall we just call them text
12:32 generation models so you know things
12:35 like
12:36 cloth or coherence command or open
12:40 source models that generate text that
12:43 are not coming from open AI then so
12:46 these are like text generation models
12:48 and next to them there is also
12:50 another group of
12:53 language models called
12:56 um text understanding models
13:00 that
13:01 well they're not called they are text
13:04 understanding models they help
13:06 machines to understand text better but
13:08 they're called embedding models so with
13:12 these two you have all sorts of business
13:14 use cases right now
13:16 and you can also merge the two like
13:18 combine the two to power like even more
13:22 creative use case
13:24 um right now roughly speaking
13:27 um
13:28 for text generation you have very
13:31 popular use cases like any type of
13:34 text manipulation so it can be a copy
13:36 creation
13:38 it can be
13:40 support chat assistant you know
13:42 personalized chat Bots AI friends a
13:46 therapists any kind of like use case
13:49 where you converse with the models very
13:50 popular right now
13:52 and also with which you manipulate text
13:55 when it comes to the text understanding
13:59 um very popular use case is
14:02 memory
14:04 um for these chatbot type of systems
14:08 where
14:10 for the model to be able to
14:13 converse with you in a personalized
14:15 personalized way
14:18 remembering all the intricate details of
14:21 your conversation all the contexts that
14:23 you have given it so far
14:25 it has to translate all this into its
14:29 own sort of you know way it translates
14:33 it to numbers and then it retrieves it
14:36 from there and then
14:38 keeps talking to you but basically this
14:40 is this is what you use embeddings for a
14:43 lot these days and also you can use them
14:45 for semantic search which is
14:50 roughly speaking
14:52 a new type of search engine where
14:56 instead of keyword matching you use
14:59 semantic similarity between different
15:01 words and sentences to look for
15:05 um to retrieve information based off any
15:07 query
15:08 and
15:10 this is a more accurate way to retrieve
15:14 information that
15:17 has a better chance of hitting precisely
15:20 the user intent behind it because
15:22 oftentimes when we do keyword search we
15:25 don't necessarily find what we look for
15:27 I mean Google search is a very common
15:30 experience like this like you're typing
15:31 in something and then
15:33 you need to scan through all these
15:35 results and you know maybe on the first
15:37 page you'll like most of the time you'll
15:39 find something but a lot of this
15:41 information is just like
15:42 not really relevant with semantic search
15:46 it helps you to to hit that sweet spot
15:48 faster and and more accurately
15:53 and are you still um so you mentioned
15:56 that you had a company NeXT grid where
16:00 you supported startups
16:04 POC stage are you still doing any of
16:06 that or are you fully focused on here
16:08 right now I'm fully focused on cohere
16:11 um but I am kind of like I exited the
16:14 company but I'm within the orbits let's
16:17 say
16:19 I the reason I'm asking about that
16:21 because I'm pretty interested in next
16:23 Grid or many or maybe other incubators
16:26 how more use cases of GPT or llms do you
16:31 see right now
16:33 um because like 50 30 percent or do you
16:36 have any number or most of them are LM
16:38 based
16:39 pocs now
16:42 I mean most of them like at the
16:44 beginning when we were founding next
16:46 grid there were no
16:48 startups that were trying trying out to
16:51 to adopt
16:52 um
16:53 the text generation or text
16:55 understanding models LMS but uh right
16:59 now I mean it's also because because
17:03 right now it's kind of like the most
17:05 popular thing there is
17:07 um from the VC side of things
17:10 folks are really interested in the big
17:14 phrases like generative Ai and large
17:16 language models so startups have a huge
17:19 incentive to somehow figure out a way to
17:21 use them in their own company if they
17:24 want further financial support so that's
17:26 kind of how it works right now as far as
17:27 I know
17:29 um but it's a it's a great time it's
17:32 like the it's a wonderful time to go out
17:34 there and explore
17:37 um different problems where you can
17:39 apply llms and you can solve actual
17:42 things
17:43 um my opinion is that and I and yeah
17:48 I think it's a popular one that
17:51 you
17:52 first and foremost you need your tool to
17:55 be useful
17:57 for it to be adopted by others and for
18:00 others to start using it on a daily
18:02 basis and you know just like
18:05 stop envisioning life without it in the
18:08 future
18:10 um
18:11 and uh and and it takes a lot of
18:15 insights into how people are doing
18:18 things and what bothers them to be able
18:20 to find it
18:23 and then to kind of like use elements to
18:27 solve it further so copywriting is a
18:29 great example like we have all sorts of
18:31 social media right now social social
18:33 media platforms and
18:35 it's overwhelming to be able to
18:38 sustain uh presence on YouTube Tick Tock
18:43 Twitter LinkedIn
18:45 what have you probably missed something
18:46 twitch discards there are all sorts of
18:50 places where you can be at right now
18:53 spreads oh yeah recently for its
18:55 Instagram Facebook Etc so
18:59 um
19:00 the reason these these copy generation
19:03 platforms are so popular right now is
19:05 because we just want to automate a lot
19:07 of the writing for social media we don't
19:10 like that it's it can be repetitive but
19:14 it's important to communicate with the
19:16 world these days so yeah this is where
19:18 allowance can help a lot that's just one
19:20 one example
19:21 with this example it's actually a pretty
19:24 interesting example so it's good that
19:27 you brought this up because like to me
19:28 it feels like right now if we use if we
19:31 rely on LMS for generating content on
19:33 social media
19:35 does doesn't it become less authentic
19:38 when now instead of just writing a copy
19:42 ourselves we rely on a AI model to do
19:46 that and then we just float all these
19:48 social media platforms with generated
19:50 content so it not only become it becomes
19:52 less authentic it kind of becomes
19:55 repetitive and sometimes you just can
19:58 recognize that okay this is not this is
20:00 clearly not written by a human because
20:02 like it's uh
20:04 sometimes you just start seeing these
20:07 generated uh post side so what I think
20:10 about like this is it actually a good
20:13 idea to replace copywriters with lamps
20:16 or maybe we should instead of replace it
20:18 somehow
20:21 help them
20:24 so yeah I totally get the
20:27 the example of like being able to tell
20:31 whether something was generated by the
20:34 model or not I can see that myself on my
20:36 social media feed lately where I am
20:41 sometimes I'm very confident to be able
20:44 to tell that okay this was probably
20:48 done use using chat GPT or or something
20:51 similar
20:53 um
20:54 so in my opinion this is
20:57 the the way it works is llms are a
21:01 amplifier a tool that amplifies already
21:04 existing process and already and
21:07 executes already existing intent
21:10 behind this process so
21:13 if a given person
21:16 doesn't particularly care about being
21:19 authentic but rather get to a certain
21:22 place
21:23 number of followers number of sales Etc
21:27 um
21:28 they will not prioritize being authentic
21:31 they will prioritize
21:32 getting the message across doing it as
21:35 fast and as widely as possible
21:39 um and so you had a lot of innocentric
21:42 messages even before llms right like you
21:45 had people just doing it for the sake of
21:48 not connecting with others but rather
21:50 maybe selling it
21:52 um
21:53 and now they just have a way easier time
21:56 doing that so so maybe you you just like
21:59 see more of it
22:00 but the
22:03 sort of you know that the initial
22:04 process it was already there the initial
22:07 intent behind it was already there
22:10 I understand so it's what you're saying
22:12 it's uh
22:13 actually good for some purposes and we
22:16 already had this sort of generated
22:17 content except maybe before it was
22:19 donated by by humans it was the worst
22:23 quality and it was more expensive right
22:26 now we can rely on llms on GPT to
22:29 generate this content and get maybe more
22:33 exposure for our content right or brand
22:36 yeah I mean it's it's helpful especially
22:38 when you're small
22:40 um or when when you're at a certain
22:42 scale and like you just want to grow
22:45 bigger and bigger which is usually what
22:46 businesses want so you just have like
22:50 you can do it faster you can you can
22:52 have a better quality of the output
22:55 I still think that there is a lot of
22:58 curation of the content generated by
23:01 text generation models to be done before
23:04 you press publish if you don't do that
23:07 then you risk being discovered
23:12 by attentive by attentive readers but um
23:16 but yeah I think I think if you want to
23:19 have a consistent
23:20 brand and consistent communication you
23:22 need to create these things so you need
23:24 to be the final decision maker when it
23:27 comes to the shape of things
23:29 so instead of fully automating and just
23:32 letting GPT go wild and generate all the
23:35 social media posts we still have we need
23:37 to have a human envelope maybe a
23:38 copywriter that edits these things
23:41 before they go live before we publish
23:44 them right definitely I mean it's not
23:47 hallucinate
23:52 that are not accurate that are not there
23:56 in reality or twist certain things or
24:00 you know mix up mix up a communication
24:03 style or yeah like there are so many
24:07 things that they can
24:10 have a
24:12 bump with that I think I think it
24:17 totally makes sense to have a human in
24:18 the loop and always make sure that
24:20 there's somebody very attentive
24:23 like who really invested in making sure
24:26 that this content whatever whatever it
24:29 is is coming out as coherent consistent
24:33 you know good for the brand or
24:35 consistent with the brand
24:37 um
24:38 otherwise you you risk
24:41 some random stuff here and there my
24:45 favorite example is
24:46 um
24:47 when you type in
24:48 as an AI model into Amazon search
24:54 um you get a lot of a lot of product
24:56 descriptions a lot of products where
24:58 people are just like copy pasting from
25:01 a copy generation tool and this as an AI
25:05 model is a common phrase but they didn't
25:06 edit it they didn't delete it they just
25:09 like pasted it there published it on
25:11 Amazon and then now we have a lot of
25:13 descriptions including this phrase
25:15 that's pretty hilarious
25:17 um
25:18 yeah
25:19 it usually says that as a like as an AI
25:22 model I cannot be sure that this thing
25:25 actually like sometimes it says this
25:27 thing as an air model I cannot know the
25:30 future right
25:31 yeah it tries to it tries to be
25:35 um
25:36 a bit reserved when it comes sorted can
25:38 and cannot do
25:40 that's usually
25:42 having users in mind because people are
25:45 asking models about all sorts of things
25:47 and they personify the models very
25:50 easily
25:51 they assign them a certain Authority
25:53 that the models don't have so it's just
25:57 uh
25:58 it's just a precaution to make sure that
26:01 um
26:02 you don't take medical advice without
26:06 consulting somebody from an AI model or
26:08 a legal advice you know or
26:11 or there are all sorts of things that
26:14 the model is not qualified for but but
26:16 it's being asked about so
26:18 it tries to be helpful but within a
26:20 certain
26:21 with certain constraints as an ammo
26:24 though
26:25 yeah I remember I wanted to talk to
26:28 somebody about the contract I wanted to
26:31 sign
26:31 and of course I thought let me ask
26:34 chargpt so I copied the contract put it
26:37 there and asked hey like is there
26:39 anything suspicious about this contract
26:40 and then I said ah it looks like a
26:42 typical contract but as an AI model I
26:45 cannot give you legal advice so if
26:47 you're if you really want to be sure
26:49 like talk tiller or something like that
26:51 right
26:52 yeah
26:54 yeah I mean another thing is just copy
26:57 pasting your information uh and giving
26:59 it to to at all that's safe yes in terms
27:04 of your your personal data safety uh
27:08 it's also probably not the best idea
27:11 um
27:12 so we need to be a bit cautious with
27:15 that stuff and and the companies that
27:18 are
27:19 um training and and
27:21 giving access to large language models
27:24 they understand that very well they
27:27 understand that users tend to
27:30 assign more Authority or personality to
27:32 the model than actually has and just try
27:35 to you know
27:37 make sure that there are some guard
27:38 rails of course they won't always work
27:41 but
27:42 um and they are very annoying at times
27:44 when you are looking for help and you
27:46 cannot get it because the model is just
27:49 keep saying I'm sorry I don't know I I
27:51 cannot say it I'm just I'm just a simple
27:53 AI
27:54 um
27:56 yeah I know I know but but then um
28:01 I I think the the user experience there
28:03 will get better with more um specialized
28:07 Next Generation models towards specific
28:09 use cases so for example in case you're
28:12 in in the example of your contracts
28:15 you will be able to access
28:17 um to have a conversation with a chatbot
28:19 that has the same capabilities but is
28:21 trained on a specific law maybe I don't
28:24 know which you know country this
28:26 contract was written in but it could be
28:28 the German law or like it could be
28:31 polish law here where I am
28:33 um
28:34 and uh
28:36 and also secure enough so that you can
28:39 have it on your machine without it going
28:41 outside and using your data further
28:44 um
28:45 and and being able to interact with
28:48 chatbot that is
28:50 as close to Legal Assistant as possible
28:53 and I think uh this is where we're
28:56 heading kind of when it comes to both
28:58 Maybe not maybe that's when it comes to
29:01 personal productivity because charge up
29:04 it is still great for it but
29:06 when it comes to
29:08 more professional productivity
29:12 um and uh and trying to use it for for
29:15 any sort of like business tasks
29:18 I imagine it can be useful even for
29:20 lawyers right so safe because like they
29:23 cannot remember all the laws
29:25 um see in Germany in Berlin it's pretty
29:27 common to uh like for example if I don't
29:31 need a book instead of throwing it away
29:32 I just put it on the street saying uh
29:35 partaking right so and like it's a
29:38 present anyone can take it interestingly
29:41 I saw a box
29:43 full of law books
29:45 and they are huge like they are super
29:48 thick like they are like gigantic books
29:52 and there were many of them like a pile
29:54 of these books and I was wondering like
29:56 oh oh my God it's good that I'm not
29:58 there I don't need to remember all these
30:01 things
30:02 and I imagine for lawyers it's pretty
30:04 difficult because they need to go
30:06 through these books they need to know
30:09 what the things are there
30:12 um
30:13 to be able to help the clients right and
30:16 probably
30:17 they will also benefit from such a model
30:20 right because like it can just
30:22 consume the book like digest the book
30:25 and then you can just ask questions like
30:27 here is the case and working on like is
30:30 there anything like which book should I
30:32 consult about this case I don't can say
30:34 okay it appears that this book like page
30:37 uh I don't know 10 000 59 talks about
30:40 that
30:41 right
30:43 yeah and and then it's not only books
30:45 but the law keeps changing right there
30:47 are like new laws being added on top of
30:49 it some become extinct so you need to
30:52 keep up
30:54 um and also you have cases that are
30:56 far from obvious so it's far from just
31:00 like searching for the information in
31:02 the book and then being able to get a
31:05 perfect answer for it as a lawyer I
31:07 think uh having a having a helpful
31:10 assistant in
31:12 in
31:13 the form of a language model that you
31:15 can just ask about certain
31:18 um certain fragments of the contract or
31:20 a certain fragments of a given law
31:22 quoted
31:24 um
31:25 and then also help you reason through
31:27 the situation help you reason through
31:31 the defense uh arguments or something
31:35 like this I think it's I think it's
31:36 going to be super useful for lawyers for
31:39 for for other professions as well it's
31:42 useful for me already
31:44 um when like you you don't
31:48 you don't only use models for
31:52 getting access to a certain information
31:54 or
31:56 generating some sort of information that
31:58 you want to use further but also for as
32:02 a sparring partner basically as a as a
32:04 thought process Aid where you just want
32:07 to
32:08 get the ball rolling start thinking
32:10 about it and then kind of help
32:12 to think through it because dialogue is
32:14 a very powerful Way To Think through
32:16 things
32:17 and being able to have your own
32:19 personalized
32:20 dialogue assistant plugged into any type
32:22 of data that your needs
32:24 I mean
32:26 who don't want that
32:28 yeah so let's say I want to build a an
32:32 app using GPT or some llm
32:35 how do I go about that so I have some
32:37 idea I think we're at the beginning of
32:39 this interview we talked about that that
32:41 you know we need to talk to users to
32:44 understand their problems and figure out
32:46 like how exactly we can help so let's
32:48 say we did this so we found a problem
32:50 that many users seem to struggle with
32:52 and now we want to create a POC
32:56 um around this problem and to want to
32:58 use
32:59 an llm for that so how do we go about
33:01 that
33:03 so um
33:06 so to to get to the next stage
33:10 um
33:11 I would try to think
33:14 about the model capabilities that you
33:16 have access to and then the type the
33:19 types of tasks that are needed in order
33:21 in order to create this
33:24 solution that solves this problem right
33:26 so there are like certain steps to solve
33:28 a particular problem
33:30 is any of the capabilities of the model
33:32 good for this type of task or this type
33:36 of Step you need to try it out into
33:38 think through it
33:40 um on the more pragmatic side of things
33:42 you also need to make a major decision
33:45 about choosing your foundation for the
33:48 foundational model and
33:50 um with that
33:52 it's reasoning capabilities basically so
33:54 you you can have models that are
33:57 huge in size
33:59 huge in parameters as well
34:01 um
34:02 extremely capable very refined when it
34:05 comes to their reasoning but maybe
34:10 you know slower or maybe
34:13 um not within the domain that you want
34:16 them to be because they were trained on
34:19 a specific data that your use cases you
34:21 know not not really useful for
34:24 um
34:26 you also need to choose between model
34:29 that is an open source model and also
34:31 model that is a proprietary model and
34:34 here
34:34 your
34:36 um
34:36 your app flow will look completely
34:38 different based off of this decision
34:41 so
34:42 if you choose an open source model you
34:45 will need to
34:46 train it to yourself you will need to um
34:52 you will need to do the entire
34:53 maintenance when it comes to
34:56 um
34:57 keeping the model alive
35:00 on your own premises
35:02 making sure it's up to date making sure
35:05 nothing breaks
35:07 Etc when it comes to proprietary models
35:10 it can be as easy as an API call
35:14 to get the model capabilities but then
35:16 you need to think about things like
35:19 what is happening to my IP when I use a
35:23 proprietary model
35:27 yes yes exactly where does my data go go
35:32 to what is happening to it and how
35:36 how much can I trust this model
35:38 um these are very important questions to
35:40 ask yourself
35:41 when you're choosing a proprietary model
35:44 um
35:45 and then there's also a bunch of
35:47 compromises you need to make I already
35:49 mentioned that um
35:51 you can have a big model that's like
35:54 like the latest the greatest
35:56 the gpt4 and any other future you know
36:00 Champion
36:02 um
36:03 but it can be maybe too expensive to
36:06 call it all the time and maybe it
36:09 doesn't adapt for your business to use
36:12 gpt4
36:14 um it's also pretty slow at the moment
36:16 so maybe that will
36:18 annoy the heck out of your users and you
36:21 need to address that
36:22 um
36:23 so perhaps for your use case it's better
36:26 to go for a model that is smaller in
36:29 size that will do the task just as well
36:33 but faster cheaper
36:36 um
36:37 yeah it all depends
36:40 it all depends what kind of task it is
36:43 and and to basically need to try it it's
36:45 painful but you need to go and try
36:47 different types of models compare the
36:49 outputs compare the outcomes
36:52 um
36:53 then you also want to
36:57 optimize your prompts when you talk to
37:00 the generation models so that's another
37:02 ball game when it comes to it's it's an
37:04 art and science
37:06 there are people called
37:08 prompt Whispers a Whispers that are able
37:11 to communicate with models very Whispers
37:14 yes okay I've heard prompt Engineers but
37:18 prompt Whispers something you need
37:20 prompt engineer is this new profession
37:23 that's
37:25 um already out there
37:28 and it's basically developers that are
37:32 really skilled at uh
37:34 creating prompts and comparing prompts
37:37 and and making them useful in production
37:39 for businesses
37:41 prompt Whispers
37:43 are focused with our um
37:47 in the top of the game you know like the
37:49 the ones that really can get the most
37:51 out of the model using the smartest the
37:54 most efficient prompt
37:56 um because it it makes it makes a lot of
37:58 difference how you structure your
38:00 question task description you know what
38:04 kind of flow it's going to have whether
38:07 the model can really
38:09 quickly tune into what you're trying to
38:12 do and follow or it's going to get
38:15 confused
38:17 um
38:17 yeah like there are so many there's so
38:21 many things here that you can optimize
38:23 for
38:24 um
38:26 and then like once you
38:28 once you make a decision about your
38:29 foundational model
38:31 that's like one of the crucial things
38:34 I think it's then relatively easy to
38:36 hook it up to any system any setup that
38:40 you may have
38:41 so
38:44 yeah
38:46 it may be because I'm in the llm
38:48 industry that I care so much about the
38:50 llm side of things perhaps there's like
38:52 you know like a myriad of challenges
38:54 that you later on
38:56 need to encounter to be able to build
38:59 this app but from what I've seen
39:03 it can be pretty straightforward from
39:04 there
39:06 so the main thing we need to decide is
39:09 whether we want to host the model
39:12 ourselves train our model ourselves and
39:15 like do all this maintenance work or we
39:17 rely on external party we just make an
39:19 API call but for this case we need to be
39:22 mindful
39:24 what happens with our data like in my
39:26 case when I copy pasted the text of a
39:29 contract
39:30 um I who knows what happens with this
39:32 text right so maybe open AI uses this
39:35 for training data next time somebody
39:37 makes a prompt it will just spit out my
39:39 data right so I need to be mindful about
39:42 that and in case I build an app I need
39:44 to be especially mindful because the
39:47 data of users
39:48 might
39:49 be used by an external party and we
39:52 don't want that so we need to think
39:54 about these things
39:56 and then we need to select the right
39:59 size of the model right should it be
40:01 very powerful but slow or should be
40:03 small but maybe
40:06 um you know optimized for a specific use
40:08 case right
40:12 so these are the things we need to think
40:13 about
40:14 and then after that we invest time in
40:17 writing good promos right that's mostly
40:20 it
40:21 that's mostly then there's also a fine
40:23 tuning so
40:25 um models are trained on
40:28 large amounts of data coming primarily
40:32 from the internet but then you have some
40:34 sort of tough use case that requires
40:36 specific
40:37 lingo you know you are building a
40:41 chatbot assistant for
40:44 finance application and there is all
40:47 sorts of financial language that this
40:50 model needs to understand to be able to
40:53 successfully execute tasks
40:55 and it doesn't yet because it wasn't
40:57 part of its training data
41:01 um
41:02 then then
41:04 the fun thing is that it can quickly
41:07 catch up to that it's kind of like
41:10 when you go through a general education
41:14 and your reasoning skills are refined
41:17 enough to be able to get into any domain
41:20 and master
41:21 you know this specialized lingo and also
41:25 Concepts within that domain and being
41:27 able to like really
41:28 swiftly you know operate there so this
41:31 is the same as fine-tuning a model you
41:33 wanted to go into a specific domain you
41:35 give it a certain
41:37 um amount of data that will be
41:39 applicable to your use case and you
41:42 find units make it
41:45 better on the on the granular granular
41:47 side of things when it comes to you know
41:50 like a specific language specific
41:52 Concepts
41:54 Etc
41:55 um and and models here
41:58 differ there are models where you can
42:00 you can do that very easily there are
42:02 models where it's not as obvious
42:04 there are models that you cannot fine
42:06 tune
42:08 um so so
42:10 it it the the choice of the foundational
42:12 model will also impact the future
42:16 ability to fine tune it
42:18 um and you need to take that into
42:19 account
42:22 mm-hmm and um I recently had a
42:25 discussion about writing good prompts
42:29 and
42:30 I use GPT quite often also for title
42:34 generation so for example for this
42:35 podcast episode I tried to generate a
42:38 title with chargepd
42:40 and usually when I say okay we need to
42:44 generate a title for a podcast episode
42:47 it often come up comes up with titles
42:50 like an AI Journey with Sandra kublik
42:54 for example right so it tries to include
42:56 the name and for people who don't know
42:58 you uh it might not be clear like okay
43:00 what is it in for me there in this
43:03 episode
43:04 and then it generates you know 10 titles
43:06 like that with the name of the guest and
43:10 what I usually do to avoid that is in
43:12 the prompt I say do not include the name
43:15 of the guest in the title right
43:18 but sometimes in spite of that it still
43:21 includes the name of this of the guest
43:23 even if I say do not do this it still
43:25 does that
43:26 and I had a discussion about that
43:28 recently
43:29 and one of the suggestions there was
43:32 that
43:34 language models large language models in
43:37 particular LGBT they have problems
43:39 understanding the navigation like when
43:42 you tell it not to do something it does
43:44 not always understand that so instead
43:46 you should tell it what to do instead of
43:49 what not to do
43:51 I don't remember how exactly to fix that
43:53 prompt like maybe show
43:57 instead of to not include the name of
43:59 the guest tell it
44:02 we want
44:04 I know that the audience to understand
44:06 how it will benefit them so include the
44:09 reasoning behind not including this
44:12 I still have to try this and see how
44:15 well it works but yeah I'm wondering if
44:17 you have any other prompt tips
44:20 on any tips on creating good prompt uh
44:23 prompts perhaps you already experimented
44:26 quite a lot with that and you have a set
44:29 of tips that he usually use for creating
44:31 excellent problems
44:34 um
44:38 because the steps are not necessarily
44:40 translating very easily to other to
44:43 other models if you're optimizing for
44:46 you know
44:48 coherence command it will not perform in
44:51 the same way with anthropics Claude
44:54 um
44:56 but the the key and the the answer that
45:00 is always there is iteration you know
45:04 you're just need to try it a bunch of
45:06 times see how it performs see which
45:08 version use you believe will work better
45:12 maybe test it against
45:14 maybe a B test is with users because who
45:17 knows like maybe
45:19 um maybe the title that you think will
45:21 be great will not be that great and
45:25 maybe like there will be another one
45:26 that will get more likes or like bigger
45:28 reach and that's why the podcast will
45:30 get to more people so
45:34 um what's really useful always is giving
45:37 model
45:39 few examples so so text generation
45:42 models currently are extremely Savvy
45:45 when it comes to what what is called
45:47 zero shot
45:50 um generation so they're able to without
45:53 any kind of example actually go and
45:55 execute execute a certain task but it's
45:58 still very helpful to show it
46:02 more precisely what kind of outcome
46:04 You're Expecting so in the case of the
46:07 podcast title
46:09 maybe grab a bunch of titles
46:13 podcast titles book titles whatever blog
46:17 titles that you like
46:19 and give it as an inspiration say
46:23 try to follow you know try to make it
46:26 similar or as good as those
46:30 um so I definitely
46:32 I definitely agree with you that saying
46:35 don't do something doesn't necessarily
46:37 end up being a successful successful
46:40 command and I kind of like it because
46:42 you know
46:43 it's good that models are rebellious
46:45 they need to be able to do their own
46:48 thing no but but um
46:52 but it's really useful to
46:55 to be very clear about the type of
46:57 outcome that you want if you know that
47:00 you like a certain style that some you
47:02 find something excellent so tell it to a
47:05 model it will learn from there
47:08 um if you wanted to use certain keywords
47:10 tell it that
47:12 if you wanted to optimize for SEO tell
47:15 it that and it will it will do it yeah
47:19 so the the communication of your of your
47:21 intent is is very important and and
47:24 being able to be empathetic enough to
47:27 share as much information as possible
47:29 it's very important
47:32 empathetic to the model yes to the model
47:35 and to to what it can do because
47:37 [Music]
47:37 um
47:38 you know imagine that you're talking to
47:42 your friends and you're asking it about
47:45 something
47:47 um so okay your friend can come up with
47:50 a title for the podcast that will not
47:52 include the name but will you like it
47:54 maybe not
47:56 maybe yes
47:58 it will be like a random you know very
48:00 subjective generation that you might not
48:04 enjoy you might enjoy but if you tell
48:07 your friends
48:09 about the type of effect you want to
48:11 achieve like if you want the title to be
48:14 catchy if you want the title to be
48:17 controversial if you want the title to
48:19 be very quickly attention grabbing
48:21 because that's what we need in social
48:22 media these days to get out there
48:25 then they will be able to navigate the
48:28 situation better right
48:30 yeah so it's the same with models and
48:33 and it's all about just like trying to
48:35 empathize with it and trying to
48:37 trying to communicate as well as
48:39 possible to get the communication back
48:43 you know that that that hits hits the
48:47 spot that you're trying to achieve
48:50 and when you mentioned that we need to
48:52 make a few iterations I kind of started
48:55 thinking about like my iterations of the
48:57 prompt for this particular use case of
49:00 coming up with a title so at first I
49:02 thought okay like you don't want to like
49:04 I don't want to include names and you
49:07 still include so then I thought what if
49:09 I am polite and I had please I will help
49:13 you did not then I thought let me try in
49:17 all caps like do not include speaker
49:20 name guest name like in all caps like as
49:23 if I was shouting at it it did not help
49:25 too so like unless you know that this is
49:29 I think you need to try like instead of
49:33 like you need to give examples like I
49:36 would not necessarily come up myself
49:37 with this tip like in that moment so
49:41 sometimes yeah it just needs a practice
49:43 examples but also context so give it as
49:46 much context as possible
49:48 um maybe show it the outline of the
49:50 questions you're trying to ask for for
49:52 this podcast maybe
49:55 um show the description that you the
49:57 blurb that you've created for like
49:59 internally for the team or for social
50:01 media before
50:03 um and and based off of that let it come
50:07 up with something I usually just uh give
50:10 as much context as possible as much as
50:11 the context window allows me basically
50:13 just like throwing in everything and and
50:16 giving it as much information because
50:19 usually that's that's what works the
50:20 best
50:22 smart enough to figure out what is
50:24 important in this pile of information
50:26 yes and and if it's not then you give it
50:29 instructions you know like you
50:31 say that that wasn't
50:34 great try another way and make it
50:37 shorter longer
50:39 sounds nicer sound more prized so some
50:42 more chilled out I don't know like
50:45 whatever you need right like you can you
50:48 cannot write based off of what you
50:49 already get
50:51 um
50:52 but yeah just like examples of the ideal
50:56 outcome and as much context as possible
51:00 hmm
51:01 so we already talked about one of your
51:03 videos where you made a video about PT
51:06 without having access to GPT that was a
51:09 very interesting story and I have also
51:11 heard that you have another video
51:13 YouTube video
51:15 about
51:17 where you integrated
51:19 a lamps into your life for seven days
51:22 can you tell us more about that so what
51:25 was the experiment about
51:26 yes of course so I'm always
51:31 um extremely embarrassed and I talk
51:33 about why I started doing something that
51:35 I did but
51:37 long story short
51:39 um
51:39 I am in the llm space for
51:43 three years now and so
51:47 I think it's only decent that I use a
51:51 certain amount of large language model
51:53 based tools
51:55 and I don't do that like I I am I either
51:58 too lazy to try something out too
52:00 impatience to
52:02 tweak it and improve it so that it works
52:04 for my particular setup or I don't know
52:09 to attach to my existing process
52:11 and to my own writing so I decided to
52:15 just challenge that and and force myself
52:17 to use different types of
52:19 llm based applications
52:22 and also image based applications
52:25 um
52:26 to see whether they will help me or not
52:30 um
52:31 it was surprisingly surprisingly
52:33 difficult to stay consistent like I felt
52:35 like almost
52:38 you know it comes back to what we
52:39 discussed before that unless
52:43 a person in this case me have a very
52:45 good reason
52:46 to
52:48 change something because it's painful
52:50 currently and you want it to be smoother
52:54 um
52:55 you don't do that like you use tools for
52:58 pragmatic purposes you just want the the
53:01 effect you want to get there as fast as
53:02 possible you don't care about proving a
53:04 point so I was kind of trying to prove a
53:07 point but also trying to see whether it
53:08 will you know relieve the pain of
53:11 certain aspects of my work and
53:16 um I ended up staying with a bunch of
53:18 them so for example I tried
53:20 this um
53:22 email
53:24 assistant or actually just like
53:27 generally I would say digital
53:30 communication assistant from hyper right
53:33 and I am still using it to
53:36 help me generate my emails or generate a
53:39 draft that I then improve
53:42 um and I'm also using it for creating my
53:45 social media posts for example I did a
53:49 bunch of experiments when it comes to
53:50 creating a YouTube video itself so for
53:52 example
53:54 asking
53:56 a model to come up with a outline for a
53:59 video
54:00 then come up with a title he went
54:02 through this process yourself can be
54:04 painful and you're not necessarily happy
54:06 with the with the outcomes then coming
54:09 up with a thumbnail for a video then
54:12 coming up with a social media post about
54:13 the video there's so much content that
54:15 you can now generate with the help of
54:18 the language model but not necessarily
54:19 it will satisfy you
54:21 it will satisfy the the results it will
54:24 hit the results that you're looking for
54:27 um
54:28 and so
54:30 a bunch a bunch of things I did were
54:32 just like I would never I would never
54:35 replace it that way
54:38 um
54:39 but but then there were
54:41 actually that was just one application
54:43 that stuck with me so one application
54:46 that stuck with me and the other
54:48 well
54:49 I use chat GPT in that example now I'm
54:52 not using charge GPT I I use Coral from
54:55 coher uh but I kind of yeah use it daily
54:58 as well for for different types of
54:59 things
55:00 so it was useful it was useful to force
55:03 myself to experiment with this
55:05 and gave me some food for thought when
55:07 it comes to you know how much
55:09 how much of my process I want to
55:11 automate
55:12 how much of that is it ends up being fun
55:15 for me
55:16 or or ends up being just annoying for me
55:19 because I feel like a teacher that has
55:21 to go over this outline that is very
55:25 subpar to what I'm looking for and and
55:30 teach the model no this is not how we're
55:32 gonna do it we're gonna do it the other
55:34 way yes this these are these are the
55:37 types of things that do not give me joy
55:40 I like to create so I don't like to
55:42 automate everything but uh for social
55:45 media or I'm so helpful or emails so
55:49 helpful I hate writing emails like the
55:51 the things that annoy you the most
55:53 that's the best things to apply the
55:55 language models through I see the
55:58 highest chance of adoption there
55:59 definitely
56:00 okay
56:02 other tools that integrate into Gmail
56:05 and help write emails
56:08 yeah hyperwrite is one of them
56:12 extension that once you turn it on
56:16 you know whenever you open your Gmail
56:19 account and you start writing a draft
56:22 it just it's gonna give you an example
56:25 email to
56:28 example email response or example
56:31 initial email or you know like whatever
56:33 you need basically based off of your
56:37 existing communication or
56:39 the theme you give it to keyword that
56:41 you give it to
56:43 maybe I should try one because like I
56:45 need to answer quite a few emails
56:47 and sometimes I am procrastinating and
56:50 end up at the end of the week with like
56:52 50 emails then it answer and then
56:55 it's Sunday I need to answer this emails
56:58 so I sit and answer them and spend a lot
57:02 of time yeah and also sometimes it's
57:05 like
57:06 when you write an email you need to
57:08 think
57:08 through the particular task you're
57:11 trying to solve and like ask somebody
57:12 for something
57:14 um but sometimes you've done this
57:16 process already so writing an email is
57:18 only just like reiterating putting it in
57:20 other words and it's for me it's
57:23 frustrating because the fun part the
57:25 thinking part is done already
57:27 but I can take the thinking part give it
57:30 to the model and then it will create an
57:32 email for me that's a Time Saver
57:36 yeah I just realized that we actually
57:38 should be wrapping up and there are so
57:39 many questions I wanted to ask you but
57:42 did not have a chance to because like
57:44 one of the things you have a very
57:45 interesting uh profile like career you
57:49 did not mention but you have a degree in
57:51 Liberal Liberal Arts
57:53 but then you ended up doing uh being in
57:56 Ai and doing no alarms but maybe this is
57:59 something we can talk about in the
58:01 future but for now we should be wrapping
58:03 up
58:04 uh maybe the last thing I want to ask
58:06 you before we finish is I know you have
58:10 a book
58:11 but this book is probably like it's two
58:13 years old right so maybe some things are
58:15 a bit outdated is there any other
58:17 resource you would recommend for people
58:19 who want to learn more about the lamps
58:21 maybe something from here right yes
58:24 absolutely
58:25 um we have recently launched something
58:28 called llm University
58:30 which is basically a free course for
58:33 folks that are trying to understand
58:35 large language model foundations from
58:39 both from the theory side of things but
58:41 also from the pragmatic side of things
58:43 of building stuff with it
58:45 so you have two components there and
58:47 it's a very nice
58:49 um primer for whatever you're gonna do
58:52 it with llms in the future definitely
58:54 recommend that
58:56 um my colleague from kohir J Elmer is
58:58 working on a new uh handbook for large
59:01 language models so follow that process
59:05 we also have
59:08 a bunch of YouTube videos that are great
59:10 our our blog is also excellent when it
59:13 comes to diving deeper into Notions like
59:15 embeddings or
59:18 semantic similarity or
59:20 you know like like how to
59:23 how to build the chatbots how to connect
59:26 to Vector database like what's what kind
59:29 of Frameworks are hot out there
59:32 um really recommend our blog so
59:35 gets more tuned into
59:37 llms right now
59:39 yeah please send us a link and then
59:41 we'll include this link in the
59:42 description and maybe some like you can
59:44 if you have time maybe you can pick a
59:46 few interesting articles that you like
59:48 the most and we can also include the
59:50 link
59:51 in the description okay with that we
59:54 should be right
1:00:02 my connection is not stable
1:00:04 but yeah unfortunately I was not able to
1:00:07 I I don't know if there are questions
1:00:09 that in somebody from you asked from the
1:00:12 audience because the moment I try to
1:00:14 open YouTube my internet connection
1:00:17 freezes so I was not able to check if
1:00:19 there are any questions
1:00:21 um sorry about that I'll try to answer
1:00:24 them like if I can go there and answer
1:00:26 questions I can yeah I can check that or
1:00:30 maybe somebody wants to ask you a
1:00:32 question should they write you through
1:00:35 Linkedin or there's any other way you
1:00:38 prefer to be connected I have my YouTube
1:00:40 channel so please drop a comment there
1:00:42 all right please please drop a comment
1:00:45 on on Twitter or LinkedIn or wherever
1:00:48 I'm everywhere so
1:00:51 um
1:00:54 sorry oh yes yes
1:00:56 it's so confusing I am not following
1:01:00 anymore things are changing so fast
1:01:03 exactly okay yeah thanks Sandra for
1:01:06 joining us today and thanks everyone for
1:01:08 joining us today too and yeah I don't
1:01:12 know the next episode will probably not
1:01:15 it will not be about
1:01:18 llms but let's see maybe it actually
1:01:22 will be
1:01:24 I hope there will be more episodes
1:01:25 anyway maybe not the next one but but in
1:01:28 the future
1:01:28 um but it was really really fun to talk
1:01:30 to you thanks for having me and uh
1:01:33 have a great rest of your day evening