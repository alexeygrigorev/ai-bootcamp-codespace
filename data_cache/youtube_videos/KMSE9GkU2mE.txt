0:02 science in startup and we have a special
0:05 guest today mariana mariana is a data
0:07 scientist
0:09 hi
0:10 he's a data scientist at restrien and a
0:12 data science lead and mentor in the
0:14 local branch of a woman a woman who
0:16 caught a community in kiev before the
0:18 stream she worked at data robot and she
0:21 also led the data science team in
0:23 fintech staff welcome
0:28 before we go into our main topic let's
0:30 start with your background can you tell
0:32 us about your career journey spark
0:35 yeah i wouldn't say that it was like
0:37 super straightforward unless as it
0:40 probably happens with some of the data
0:41 scientists because you know basically
0:43 usually have like just two ways uh
0:45 you're coming from the research
0:48 background or
0:49 from software development background and
0:52 basically i used to be a java developer
0:55 so
0:56 i just got interested in the field and
0:59 uh thanks to the
1:01 code community i also met or
1:04 a real data scientist
1:06 who were doing like a work in production
1:08 and like back then uh five years ago
1:12 it wasn't that
1:14 popular maybe it wasn't that easy to
1:17 find such people and
1:19 it really helped me to find a mentor and
1:22 that's how i started to
1:24 study a lot and
1:26 then when i got my first job in a
1:28 startup i will probably be like
1:31 referencing that a bit because
1:33 this is basically the place where i had
1:34 the experience of
1:36 leading a team and
1:39 also after that i
1:41 worked in data robots which uh kind of
1:44 allowed me to compare but it's like to
1:46 work in a small startup uh
1:50 in comparison to working
1:52 more let me see closer to enterprise
1:55 kind of company
1:57 and right now in restream
1:59 also it's a startup as well and
2:02 i kind of have
2:03 all the experience that i
2:05 got like over the
2:06 years i'm trying to apply it here right
2:10 now
2:11 okay so well when did you switch
2:15 to to data science was it five years ago
2:17 yeah
2:18 so this is when you joined
2:20 the women who called
2:22 branch
2:23 yeah
2:24 okay because at the same time
2:26 yeah pretty much
2:28 and you were
2:30 the first data scientist at your first
2:32 startup
2:34 um no uh there are several data
2:37 scientists and uh it was like fintech
2:40 startup and i was lucky with that
2:42 because i had
2:44 more experience i had reviews and stuff
2:47 but
2:49 unfortunately it didn't last long
2:51 that a lot of things changed in the
2:54 company and
2:56 like it changed also in careers and
2:58 lives of my former colleagues so
3:01 i think after less than a year i was uh
3:04 the only one data scientist and that's
3:07 how i got into
3:09 uh trying to organize everything myself
3:12 and uh trying to hire a team
3:14 and which was interesting since i didn't
3:17 really had like that much experience uh
3:20 i mean technical experience
3:22 but uh i was like the only person who
3:25 knew
3:26 products that well like even if they
3:28 uh got to hire someone else or this
3:31 person didn't know that much like the
3:33 domain of the company so
3:35 it was really challenging but
3:38 it gave me quite a lot in terms of
3:41 experience
3:42 what are the pros and cons of starting
3:44 as the first data scientist at the
3:46 company
3:48 i would say it's a bit
3:50 subjective probably for me
3:52 but
3:53 maybe the best thing is having freedom
3:57 uh in terms of what you can do like you
3:59 don't have limitations
4:02 you're not limited by technologies you
4:03 use you're not limited by methodologies
4:07 and for example
4:08 uh in data robots there is like really
4:11 strict guidelines and process which i
4:14 used for the projects in comparison to
4:17 startups where you can basically
4:20 come up with some idea you can implement
4:22 it like
4:24 really fast and
4:25 control its
4:26 execution so it doesn't really take you
4:29 that much time to
4:31 go through all that as it happens in
4:33 some of the big companies when
4:35 you need to get all the immediate
4:36 approvals and stuff
4:39 um also you kind of have more influence
4:42 i guess in terms of views again like her
4:46 i mean like people listen to your
4:48 opinion more
4:50 i guess
4:51 so if you're working in a big company
4:53 there is a lot of data scientists and
4:56 you are working on some specific
4:58 projects probably but when you're the
5:00 only one you're
5:02 basically responsible for everything
5:05 related to data science in the company
5:07 so
5:08 until you hire a bigger team
5:11 um also it seems to me if a
5:14 startup has a
5:16 healthy culture uh that deadlines can be
5:18 more
5:19 realistic
5:20 because you kind of
5:23 send them yourself and uh
5:25 of course you like discuss it with your
5:27 colleagues but uh still it's not like
5:29 you have this strict
5:31 process and uh you're not pressured uh
5:34 in terms of that
5:36 although i still think that um in terms
5:39 of like disadvantages uh you kind of
5:42 have more responsibility than you have
5:44 when you work in a team
5:46 um because you are getting responsible
5:48 basically not just player model
5:51 but for everything happening in the
5:53 company
5:54 uh like in the first startup where i
5:57 worked i was basically responsible like
5:58 for everything related to analytics even
6:01 like if it was dashboards that helping
6:03 this kind of queries to
6:06 other teams and stuff so
6:09 it's quite a lot of it's a huge role i
6:11 would say
6:13 and
6:14 because of that
6:15 you have to learn a lot on the way
6:17 because
6:18 again you don't have anyone
6:20 near you where you can just ask
6:23 and uh i would say it's both
6:26 good and bad bad in a way that you have
6:29 to like you have this pressure that you
6:31 need to learn a lot and you have to
6:34 somehow validate yourself
6:36 if it's uh if you are doing the right
6:38 thing and
6:40 at the same time if you have someone to
6:41 ask sometimes
6:43 you kind of can
6:44 get unmotivated maybe to their style
6:47 at least that's where i noticed uh how
6:49 it works for for me that i kind of
6:52 developed faster the
6:54 professional and i have like less
6:57 support i would say
6:59 from
7:00 my colleagues i don't know how it works
7:01 but sometimes when you kind of feel that
7:04 you have someone to ask something you
7:06 kind of
7:07 rely more on that and on yourself on
7:10 learning stuff by yourself
7:12 so basically it forces you to
7:17 forces you to learn more than you would
7:20 otherwise uh
7:21 learn with your colleagues
7:23 yeah somehow
7:25 yeah i actually observed something
7:26 similar when i worked at the startup
7:28 even though i had data science data
7:30 scientists colleagues
7:32 who worked as data scientists
7:34 i think
7:35 the
7:37 like because this lack of
7:39 you know when there's a small team
7:40 compared to a bigger team then it kind
7:42 of forces you to really
7:44 do a lot of stuff that otherwise you
7:47 maybe wouldn't do that's that's
7:48 interesting yeah
7:49 they basically like let's focus on just
7:52 one specific project and you don't think
7:54 like okay i will learn that later and i
7:56 will just trust this person
7:58 how to do that because i need to do that
8:00 faster for like
8:02 some plans for for the team and
8:04 deadlines and stuff and
8:06 as it usually happens sometimes we just
8:08 never get to that so they're not
8:10 ourselves
8:13 yeah if somebody wants to join a company
8:16 so this company doesn't have any data
8:18 scientists um yet and you want to join a
8:20 company as a
8:21 only data scientist
8:23 you know what companies should already
8:25 have
8:26 for that
8:28 like what kind of things they should
8:30 have
8:31 for you to feel comfortable
8:33 in this uh
8:34 joining a startup
8:36 are there any prerequisites or you can
8:38 just go to any startup and start working
8:40 as a data scientist
8:42 uh i would say that
8:44 it it would be great if company has some
8:46 kind of existing pipelines and
8:49 infrastructure and people or like
8:51 supporting that
8:52 either it's data engineers uh devops
8:56 developers
8:58 just depends on on the company policies
9:01 and stuff about that
9:03 but um
9:04 like i've had experience this like in
9:07 restream there is already established uh
9:09 infrastructure and
9:11 people who do analytics and uh
9:14 and stuff
9:15 while in comparison to that or in the
9:17 first start of their work like there was
9:20 basically
9:21 nothing and
9:23 there was some data gathered but uh
9:26 sometimes it was like some box uh and
9:28 you couldn't use this data and uh
9:30 because of that it was like really
9:32 complicated
9:34 because it seemed like you had a lot of
9:36 data but you actually didn't because you
9:38 couldn't use all of that
9:40 and uh that's why i would say that's
9:42 pretty much important um also
9:46 again compared to
9:48 restream probably having some kind of
9:50 analytics department because as i
9:52 mentioned like my first uh job in the
9:55 startup there was like no one doing
9:58 analytics before me and uh when you have
10:01 like a huge scope of stuff you can do
10:03 with data science
10:05 and plus you have a lot of stuff that
10:07 you can do with analytics helping
10:09 different teams and stuff but it's like
10:12 it's too much for one person for sure
10:15 and
10:16 usually all these things are high
10:18 priority
10:20 so it can be hard to
10:23 to do all that at the same time
10:25 so basically companies should ideally
10:27 have data engineers with data pipelines
10:30 and then
10:31 analysts because otherwise if they don't
10:34 have
10:35 them
10:36 you as a data scientist might end up
10:38 doing all this work in addition to
10:41 trying to do data science but without uh
10:44 having it like without the data you
10:45 probably cannot really do data science
10:47 so you'll need first spend time a lot of
10:49 time on building all these things
10:52 right yeah
10:54 um
10:55 and how much
10:56 experience
10:58 would i need to have to start to join a
11:01 company as a
11:02 only data scientist do i need to be
11:05 very experienced like i don't know
11:06 senior person or if i'm just switching
11:09 career
11:10 um would it be a good idea
11:12 to to join
11:14 i think it should be more like middle
11:17 senior level but uh
11:19 the most important list for me is
11:22 being able to create a project from
11:25 scratch
11:26 and go through all the needed phases
11:28 like not just uh model training but
11:31 you should be able to define a problem
11:33 if you don't have enough data
11:35 to somehow translate what other people
11:37 mean when you talk with people who don't
11:40 really know data science and also
11:44 you probably should be able to deploy
11:46 and model and monitor it so basically
11:48 it's like
11:49 a huge scope i would say and
11:52 everyone has this kind of experience
11:54 because sometimes you just get to work
11:57 on some one specific stage
12:00 so
12:01 i would say
12:03 experience with that or at least the
12:05 motivation to do that and to do a lot
12:07 by yourself it's
12:09 something that
12:10 should a data scientist should have
12:14 so even though there are data engineers
12:16 even though they're analysts already in
12:18 the company you still need to do a lot
12:19 of uh you said communication
12:22 like working with others to define a
12:24 problem then actually training a model
12:26 and then after that also being able to
12:28 deploy like do the whole thing from the
12:31 beginning till end
12:33 yeah i would say it's like it always
12:35 starts from defining there is actually a
12:38 problem that needs solving because
12:40 uh
12:41 people usually don't really
12:43 they don't really exist in this context
12:45 of data science problems and they have
12:48 like very different understanding of how
12:50 the field works and
12:51 what we can do with the tools that we
12:53 have so basically it's always about
12:56 identifying whether
12:58 there is a model needed so maybe it
12:59 shouldn't be solved
13:01 or
13:02 maybe another problem needs more
13:04 attention how do you do that
13:08 i would say it takes experience but at
13:11 first
13:13 although i'm an introverted person it
13:15 was hard would be to learn not to be
13:18 like that but it takes really a lot of
13:20 communication
13:22 uh especially with people who are close
13:24 to the business side of the product
13:27 uh if it's uh for example analytics
13:30 department it's really helpful because
13:32 uh usually
13:33 analysts know quite a lot about
13:35 different parts of the product and they
13:38 already kind of help
13:41 different teams so they know more about
13:43 that than
13:44 going around those
13:46 company
13:47 but usually i try to
13:49 communicate with all the departments
13:51 because sometimes even
13:54 especially when you don't have data
13:55 scientist colleagues
13:57 all you have is like
13:59 different people with different
14:00 backgrounds and already hear their
14:02 experiences and their challenges
14:05 i kind of automatically just translate
14:08 it into the language of data science and
14:10 we try to understand how their problems
14:12 can be solved
14:14 how does it usually happen do
14:16 others come to you with their problems
14:19 or you need to practically
14:21 find problems uh that can be solved with
14:23 their science
14:25 i would say it depends on the company
14:27 because
14:28 usually when the first data scientist is
14:31 hired there is
14:32 already some understanding that
14:35 he or she is supposed to solve some
14:37 problem
14:38 or sometimes it's more like
14:40 we have a lot of data and maybe we
14:42 should do something with that but we
14:44 don't know if we should
14:45 so yeah it depends uh on the company but
14:49 when i started like in your stream for
14:51 example i had like more specific
14:53 requests and i was
14:56 i had like several ideas to explore
14:58 which is what is having like more
15:00 priority what is more feasible
15:03 and uh that's basically how i started
15:05 working and
15:07 at first it's like important to kind of
15:10 talk more about what you can do because
15:12 people can't just come to you if they
15:14 don't know what you're doing
15:16 and how it can be helpful so
15:19 at first it's more like a proactive
15:21 reaching out to other people and
15:23 um that's what basically i did like very
15:26 organized different meetings with all
15:29 the departments and
15:31 talked about their challenges and
15:33 problems and
15:35 try to explain
15:36 how i can be helpful and
15:39 now it's more like people come to me
15:41 then i'm like trying practically to do
15:43 something but
15:45 i also try always to kind of think about
15:48 some kind of a roadmap or a plan
15:50 and
15:51 discuss it as well with
15:53 other people if they
15:54 they think that would be helpful or not
15:57 i think it's
15:58 also important
16:00 because i can imagine if you talk too
16:02 many people from
16:04 different
16:05 departments from different teams
16:08 maybe all of them have problems or half
16:10 of them they have problems and then you
16:12 have a problem that you have too many
16:14 problems to
16:15 just also that's why you need a roadmap
16:17 right so you need to be able to identify
16:20 okay out of these 10 problems what is
16:22 the most uh
16:24 impactful one or what is the easiest to
16:26 solve right
16:27 yeah
16:28 i basically evaluate like visibility
16:31 priority also discuss it for
16:33 like people for my supervisors what do
16:36 they think and
16:38 that's how i basically decide what it's
16:40 more important
16:42 so
16:44 you just ask hey like on a scale from
16:46 one to ten how important it is or
16:49 like how do you understand
16:50 what is more important than what is less
16:53 uh it's more like i discuss it for
16:55 example with uh
16:58 i'm basically part of the
17:00 business analytics department and i just
17:03 asked the leader of this department what
17:05 they think is like more important right
17:07 now and he's like always in touch with
17:09 all these
17:10 people as well so
17:12 and he's like working in the company for
17:14 many years already so
17:16 i can chat with him or with some like
17:19 other
17:20 like product head of products and
17:22 people like that and hear different
17:25 opinions so that's how i decide that
17:28 something is um having more priority
17:31 right now
17:32 so for you i i'm not sure i got that
17:35 part so when you were joining the stream
17:37 uh
17:39 did you already know what kind of
17:40 problems you would be working on or you
17:43 had to figure that out on your job uh i
17:46 already kind of had a week
17:50 understanding what it could be and at
17:53 first
17:54 i thought that it could be a lot of like
17:55 one thing but then we switched a little
17:58 to another so i'm also like going for
18:01 like
18:03 work for marketing right now
18:05 and uh
18:08 also some of the problems which we
18:10 discussed in the beginning they turned
18:12 out to be not so important right now so
18:15 they moved to something else
18:17 and i would say that
18:19 [Music]
18:20 they kind of had a request but it got
18:23 more clear over time when i joined the
18:26 team
18:27 so basically a company should already
18:29 have an idea that they have some
18:30 problems that potentially can be solved
18:32 with data science right
18:34 and not like okay we have this uh
18:37 uh i don't know 10 terabytes of data or
18:39 10 bytes of data now we need to figure
18:42 out what to do with this all this
18:43 information right so there should be
18:44 something more or less not super
18:46 specific but at least some idea okay
18:48 like we have this problem uh it could be
18:51 solved with data science right
18:54 yeah i also think that even if company
18:57 doesn't really know what they want to
18:59 solve they don't have i don't know some
19:00 kind of consulting before that because
19:03 uh it's not like uh
19:06 all we all live in this context of data
19:08 analysis and i know what we can do with
19:10 that
19:11 so it's completely fine not to know but
19:14 like
19:15 both hiring and not knowing and also
19:17 expecting lots like
19:20 i
19:21 i met such
19:22 companies when they kind of
19:24 see data science as a magic field
19:27 which
19:28 will be able to solve everything that's
19:31 that's happening right now in the
19:33 company
19:34 but it's more like a part of the one big
19:38 process and changes
19:40 so it's basically an ideal situation
19:43 when a company already had consultants
19:45 who explained them what could be done
19:47 what could not be done and that
19:49 potentially for this problem data
19:50 science is a good solution
19:52 and they should hire data scientists
19:54 right and then this is probably a good
19:56 situation right because company
19:58 already has some processes
20:01 they have some ideas even though maybe
20:04 wake
20:04 ideas what could be done with data
20:06 science and then
20:08 that's probably the ideal case right and
20:09 when they already have some data
20:11 pipelines
20:12 and an analytical department it's
20:15 probably the best place
20:17 for uh
20:18 only data scientist right to start
20:21 yeah and i also think that data science
20:23 is basically it's like not the first
20:24 step and not the first thing that you
20:26 should do like
20:27 that's why i said that the analytics
20:30 department is
20:31 necessary before that because usually
20:34 for people
20:35 they think that they need some like
20:39 uh automated pipelines for
20:41 models and stuff but sometimes they just
20:44 need some dashboards and
20:46 simple more simple analytics so
20:49 it's more like
20:50 more advanced step that you get over
20:53 time so that's why it
20:55 matters
21:03 and you're muted
21:06 right now
21:07 thanks
21:09 yeah i forgot to meet myself yeah so
21:12 let's say you uh joined the company so
21:14 you had an interview with them you
21:15 really like them so they have the data
21:17 pipelines they have an analytical
21:19 department they seem to know what they
21:22 want so you think it's cool you join
21:25 this company
21:26 and what usually happens after that so
21:28 let's say on your first day
21:31 i would say the first thing that
21:33 i usually do is
21:36 i
21:36 i try to discuss as much as possible
21:39 with different people
21:40 what do they
21:42 what do they expect from me and how do
21:44 they see my work and so basically i'm
21:48 like trying to identify requirements and
21:50 the main ideas
21:52 and usually like the first week for me
21:54 is for exploring the data but
21:57 just saying that
21:58 okay let's go look at the data it's not
22:00 really productive so it's
22:03 always better to have some problem in
22:06 mind
22:07 so you could like look at the data
22:09 thinking that i can use this for that so
22:12 it was useful for me to know about these
22:14 ideas which were requested in the
22:17 beginning so i could like look at data
22:19 thinking
22:20 that uh like psc is put out and etc
22:25 so that's for the first week you said
22:27 and then let's say
22:28 um after a month um what should you do
22:32 in a month like do you already need to
22:34 have some sort of qvc or are you still
22:36 in this exploratory phase
22:39 like i guess it depends uh
22:41 on a case but uh
22:44 yeah what do you do you think happened
22:46 after a month
22:49 so i think like it kind of depends on
22:52 the face of a person i kind of tend to
22:55 do a lot of stuff quickly
22:57 i don't know
22:58 so
22:59 i try to get some kind of issue of the
23:02 first months it can be
23:04 not not necessarily a model but just
23:07 some kind of a research or
23:10 insights which already could be used
23:12 and
23:14 so basically yeah it could be even like
23:17 a draft version of the model even at the
23:20 same time because you can kind of try to
23:23 do that iteratively so you already can
23:25 test out some of the hypothesis
23:29 so basically at the end of week one you
23:32 already have some you explore the data
23:35 you already know data moral as well you
23:38 kind of try to assess
23:40 if you
23:41 can use the data that is available to
23:43 solve the problem that you were hired to
23:45 solve
23:46 and then if it's the case you kind
23:49 explore the data more
23:51 and then you get some insights and then
23:53 at the end of one uh
23:55 month number one you already have some
23:57 sort of uh maybe like insights or even
24:00 uh first model right
24:03 and then um what happens after a quarter
24:07 uh i think by that time you already kind
24:09 of um have some kind of methodology that
24:12 you use for example
24:14 i didn't just build the first model i
24:17 also built some kind of pipelines around
24:19 that so it would be easier for me later
24:22 if i needed to train it or deploy
24:25 another model so
24:27 that's why it probably took me like
24:29 it will take me longer at the beginning
24:31 than later
24:32 because i already kind of building some
24:34 preparations for
24:36 other work that is going to be done in
24:38 the future
24:40 and
24:40 probably you should already have some
24:43 kind of
24:45 analysis of what you've done like
24:47 for example you can
24:49 at least start running the model or do
24:52 some kind of a b testing you know
24:55 if it's
24:56 accurate enough or how it's working
24:58 because there's there is a lot based on
25:02 on the feedback and
25:04 on how how your model influences the
25:07 processes and the product itself so it's
25:10 at least in my stream uh we kind of
25:13 follow this lean
25:15 methodologies it's like
25:17 really important to do a lot of stuff
25:20 and
25:20 iterations and test them
25:22 at smaller scale
25:25 so basically in a quarter after three
25:28 months you can already test multiple
25:30 hypothesis multiple models and maybe
25:33 come up with
25:35 one that
25:37 really works and then try to deploy it
25:39 right
25:41 okay and have a a b test and evaluate it
25:44 that's cool and what if things don't
25:46 work out well i think it's maybe it's a
25:48 happy path that you
25:49 you do this you identify the
25:52 uh the the the problem you see that all
25:56 the data is there and you get insights
25:58 you deploy your model and then you run a
26:01 b test and you see a huge uplift
26:04 but that
26:05 doesn't always like it
26:08 it doesn't have to happen it might not
26:09 happen right do you do you know how
26:11 what's the best way of managing
26:13 expectations of a company
26:15 like may because maybe they want to see
26:18 results in three months right
26:20 yeah i was like say that data science is
26:23 not a result-oriented
26:26 field that
26:28 i personally believe that any project
26:31 in data science is
26:32 basically an answer to some question
26:34 even if if we don't like that answer
26:37 it's already some kind of information
26:40 that we can use later for example we
26:42 know that this model doesn't work but it
26:44 doesn't mean like everything is not
26:46 working completely we know that for
26:48 example we should solve this problem
26:49 differently or we should use another
26:51 data
26:52 we already can draw some kind of
26:54 conclusions that's why i can always try
26:57 to
26:58 maybe educate
26:59 everyone around that
27:01 that's how it works and
27:04 for example in your stream right now my
27:07 data analysts colleagues they are
27:09 they also agree with that because
27:12 they have kind of the same mindset when
27:14 they work in different problems
27:17 is it something like this managing
27:19 expectations is it something you should
27:21 do before starting at the company uh to
27:24 make sure that the company knows that
27:27 this process is not deterministic you're
27:29 not guaranteed to have success in three
27:31 months
27:32 or like how how would you approach that
27:35 i would say that they do that all the
27:37 time because even if you
27:39 uh kind of say that
27:41 the interviews and uh in the beginning
27:44 uh it's still kind of it can be hard if
27:47 it's a metis company which is used to
27:50 having
27:50 a developer developers team who just
27:54 implement some specific tasks and it's
27:56 like a deterministic
27:59 way of doing things so i usually just
28:02 kind of always
28:04 talk about that
28:07 okay yeah interesting
28:08 and i think we talked a bit about uh
28:12 like that sometimes maybe a dashboard is
28:14 what the company needs not
28:17 not a solution not a machine learning
28:19 model
28:20 um so how do you
28:22 um how can we understand if a problem
28:24 actually requires machine learning or it
28:26 can be just simple analytics like a
28:28 couple of queries put in the dashboard
28:30 like how do you
28:32 what's the process of figuring this out
28:34 i would say it's uh but i always start
28:37 from something easier like i always
28:39 start from some kind of exploratory data
28:42 analysis and
28:43 i see already if i need a model for that
28:46 or i can do it
28:48 differently somehow
28:50 so it's
28:51 it's more about not being like focused
28:53 specifically on just building models and
28:56 more on
28:57 solving problems and how you can do that
28:59 and
29:00 trying to kind of
29:02 explore and research in the beginning
29:05 more rather than just trying to
29:08 just get all the data again and
29:11 engineer some features and
29:13 start training models because
29:15 this is not like the main idea
29:18 and
29:19 also i think iterations kind of help a
29:22 life kind of parts in
29:25 terms of data science process but you
29:27 kind of
29:28 trying to
29:29 at least split the work in some kind of
29:32 steps and try to look every time if it
29:35 works if it works or not for example i
29:38 built like many
29:39 prototypes over time
29:41 for models
29:43 because it's kind of easier to see some
29:45 features i'm working so i wouldn't like
29:47 spend too much time
29:49 uh developing something that's not going
29:51 to be useful later i don't know if you
29:54 can talk about specific projects
29:57 but maybe you have an example where you
29:59 did something super simple that didn't
30:02 require machine learning and then
30:04 improved and did a few iterations and
30:06 then edit some machine learning on top
30:09 of that later
30:11 i would say that uh
30:13 thinking about some of the projects they
30:15 had
30:16 i don't remember the projects if i like
30:18 edit machinery and after that but like
30:21 that in the future if like more data is
30:24 added here
30:26 for example uh there is a possibility to
30:30 communicate different
30:32 customers in more effective ways so
30:35 at first
30:36 i tried to identify like we chose this
30:39 customers can charm uh like
30:43 we had each of them risky ones
30:46 in terms of charm and at first it was
30:49 just an analysis what can we
30:52 or can be related to that and they built
30:54 a model which helps to identify
30:57 probability of churning
30:59 and after that uh i've been like
31:02 collaborating with marketing department
31:04 about
31:06 trying to communicate with them and
31:09 probably later we can build a model on
31:11 top of that
31:12 to identify which what is like the most
31:14 effective way to
31:16 communicate which are like activities
31:18 can be used uh so
31:21 for retention of customers but
31:23 uh like right now it's partially machine
31:26 learning partially just analysis and i'd
31:28 say it's always kind of done that way
31:31 that you try to
31:33 um do something which is easier and
31:36 faster in the beginning so you know if
31:38 it's like even high priority if it's
31:40 even needed for this kind of problem
31:43 because sometimes
31:44 some people can say that they something
31:46 that they need or like
31:49 the solution
31:50 right now but it sometimes turns out
31:52 that it's not really that
31:54 needed
31:57 i guess when it comes to churn
31:59 you can just analyze churn rate in
32:02 different segments and you can look at
32:05 i know maybe people for specific type of
32:08 you know business or
32:11 people from specific countries and then
32:13 just by doing group by and looking at
32:16 the average churn rate you can uh
32:18 already understand what are the segments
32:20 that are more likely to to turn right or
32:23 is it does it work like that or this i'd
32:26 say that at first it was more like
32:28 trying to understand from the point of a
32:32 product like how it usually happens what
32:34 influences
32:35 this process the most
32:37 so i had like some kind of event
32:38 triggers at first and just information
32:41 about that and
32:42 then the model itself
32:44 so
32:45 yeah first it was like more of a
32:48 basic analysis what can be related to
32:51 that
32:53 okay
32:54 and uh you know like i think we already
32:57 talked about the timeline right so for
32:59 the first project uh
33:01 uh like you can see
33:03 uh like in three months you have a poc
33:06 um ideally right that's uh yeah and for
33:08 the second project like should it be
33:10 faster or like do you would you expect
33:13 to to have it in the same timeline or
33:15 how does it usually work
33:17 i would say it like it's a boring
33:20 response but it depends on the case
33:22 because sometimes it can be some project
33:25 which requires working with the data you
33:27 didn't work before or
33:29 require some additional work there with
33:32 pipelines and stuff but but if it's
33:34 something that can reuse the
33:37 previous work then it should i kind of
33:40 expected usually to be faster
33:43 so
33:44 if
33:45 it's not a very complex problem and you
33:47 already know the data set so each
33:51 each next model should be a bit faster
33:53 right
33:54 yeah especially if you kind of uh reuse
33:58 some of the pipelines because i usually
34:00 try to automate all the stuff that's
34:02 kind of like
34:04 i would say hobby but i don't know i
34:06 like i'm automating uh a lot of stuff
34:08 because it's very kind of boring to
34:10 repeat yourself all the time with like
34:13 these features and analysis so
34:15 it's uh getting closer is
34:18 different projects to get them done
34:21 yeah we have a question about
34:24 identifying the best model for a problem
34:27 and
34:28 maybe not just a model i think it's
34:30 interesting because we talked that
34:31 sometimes there is these things can be
34:34 solved with analytics
34:35 so how would you suggest identifying the
34:37 best solution to a problem
34:41 um i would say that
34:42 you can analyze the false from the
34:44 perspective of a data scientist like
34:46 using specific metrics depending on what
34:49 kind of case do you have but it's also
34:52 maybe even more important to try to
34:54 understand what you're actually
34:56 performing and how you can measure that
34:59 and something that i'm always kind of
35:02 focusing on while planning i
35:04 always like ask
35:06 people who like give me this uh kind of
35:09 requests that they need something
35:11 uh to be done i always ask them like how
35:14 are we gonna measure that and how we're
35:15 gonna know if it's working or not and
35:18 even if they don't know we can like
35:19 figure out it's together but
35:22 it's something that should be done in
35:23 the beginning because
35:25 usually when you just come up with
35:27 something on the way you never know
35:29 there is like correlation
35:31 uh user results and so
35:34 so it's better to kind of define it
35:36 earlier and then to try to compare your
35:38 solutions using
35:40 both
35:41 data science
35:42 methods and also
35:45 your knowledge of domain
35:48 and
35:49 another question is
35:51 like how do you evaluate your
35:53 performance
35:55 i think we
35:56 kind of answered that so you can uh
35:59 uh
36:00 like when you define this uh kpis when
36:02 you define this metrics you can already
36:04 see if your models are working out right
36:06 and this is a good way of evaluating
36:08 your performance right like how well
36:11 you're doing how well your models are
36:12 doing
36:14 yeah i would say it's a tricky one for
36:16 data scientists and
36:18 um in the first startup where i worked
36:21 there was like full discussion about
36:22 kpis and how it can be
36:25 calculated for example like if number of
36:28 deployed models or number of chain
36:30 models can be kpi or
36:33 what is usually
36:35 like could be helpful and i i personally
36:39 can't say that i found an answer for
36:41 myself
36:42 but
36:43 it's more like probably how you deliver
36:46 the insights but again i'm not sure it's
36:48 related to speed because
36:50 people have different
36:52 facing when they work some people
36:54 require more time some people require
36:56 less and
36:58 so it's more like uh on how you are
37:00 oriented on what you do and how you try
37:03 to provide some insights even if it's
37:06 not the answer that it was kind of
37:08 expecting like
37:10 a failed model is not a fail
37:13 yeah right
37:14 because i imagine if your kpi's number
37:16 of uh models running in production
37:19 then
37:20 like what if we know that machine
37:22 learning is not deterministic
37:24 it can happen that just by
37:27 bad luck
37:29 your projects are not successful just
37:31 because it happens right and then it's
37:33 not that like you're not working well
37:36 it's because like stuff happens
37:38 and uh so maybe a number of uh
37:41 experiments uh that you did could also
37:43 be a good uh kpi perhaps
37:48 just
37:49 maybe many of them are failing
37:51 failed but yeah that's that's part of
37:53 learning and who actually evaluates your
37:55 performance because i imagine if you're
37:57 the only data scientist in the company
38:00 other people might uh not know how well
38:03 you are doing your job so how do they
38:05 who who evaluates you and how do they do
38:08 this what do they use to
38:10 to understand if you're doing well
38:13 uh right now it's like a kind of
38:16 business analytics department department
38:18 and uh
38:20 maybe because he is also like a data
38:22 analyst that kind of helps to be on the
38:24 same way for that that
38:26 experiments are experiments
38:29 and
38:30 basically
38:31 he just has like some ideas what can be
38:33 done and how fast it's usually done so
38:36 maybe it's a bit subjective but uh
38:39 i wouldn't say that there is like a
38:41 specific system of kpis but that's how
38:44 it's
38:44 done right now so having analysts in a
38:47 company definitely helps because these
38:49 are the people who you can
38:51 uh talk to on the same language because
38:53 they probably understand something
38:56 most of analysts they think they know
38:58 that machine learning exists even maybe
39:00 they don't have hands-on experience but
39:01 they probably have some ideas for this
39:03 right
39:05 yeah basically like uh this colleague of
39:07 mine suggested to hiring data scientists
39:10 because he saw like
39:12 problems which couldn't be solved just
39:14 using data analytics so yeah some people
39:18 try stuff in machine learning or just
39:21 know how it works in general
39:25 and when you are
39:27 a lone wolf with data scientists
39:30 like uh you're alone in the company
39:33 and you get stuck like there is a
39:36 problem that you cannot solve like how
39:38 do you
39:39 who do you ask for guidance do you ask
39:41 for help in this station
39:44 i think it like it depends on kind of
39:47 what i got stacking if it's like
39:49 something business related then i can
39:52 discuss it with my colleagues
39:54 depending on how many like making this
39:56 kind of project
39:58 if it's more data science related uh
40:01 it's usually not intimidating for me i
40:04 just try to read more about stuff i
40:07 i try to communicate with people i know
40:10 in the field and like culture different
40:12 events and
40:15 also discuss it with in communities that
40:18 i know so um i don't usually feel like
40:21 it's something like a huge problem for
40:23 me like it could be it used to be when
40:26 it was like just the beginning of my
40:27 career
40:28 um but right now i don't really feel
40:30 like it's
40:32 it's necessary to have someone by your
40:34 side because
40:36 basically as a data scientist we all
40:38 work kind of separately and we don't
40:40 collaborate as much as uh maybe software
40:43 engineers do
40:45 okay yeah so basically you used your
40:47 network
40:48 you go to meetups and uh
40:51 the the community we mentioned at the
40:53 beginning women who caught
40:55 it's also
40:56 like where you can ask for help right
40:59 okay
41:00 yeah thanks uh
41:02 um yeah another question we have what
41:04 are some good ways to communicate
41:06 information that you gain through
41:08 uh
41:09 your analysis deploying your model to
41:12 the analytics team
41:14 is it better during
41:17 is better to do so during research or
41:20 by iranian things
41:23 um i think it's uh
41:26 it's more like about the format as i
41:28 understood like this question or more
41:30 about like
41:31 when they stop like when do you have
41:33 these iterations and representations
41:36 how do you do this like how do you
41:37 communicate to the analytics team like
41:40 let's say you run a model and then you
41:42 want to
41:44 tell about the results like how they do
41:45 this
41:46 i usually just create some kind of a
41:48 report with visualizations which could
41:51 be
41:52 more or less interpretable for them and
41:54 even if it's
41:55 more of my specific metrics stuff i try
41:58 to explain it as much as i can and so it
42:02 could be like so we could talk on the
42:04 same
42:05 way for and basically
42:08 it's always better for me to kind of
42:10 make a report because it kind of also
42:13 helps me to
42:14 understand when i'm creating it what i
42:17 could miss or if i paid everything what
42:20 i was thinking about so
42:22 yeah
42:23 basically it can be just a team call or
42:26 one-to-one depending like how many teams
42:28 how many people in the team you have and
42:31 in um if you're like discussing it with
42:34 other teams
42:36 it helps to kind of have some kind of
42:38 company-wide discussions or
42:41 tech talks something that i had
42:43 experienced
42:44 risk quite quite often i would say and
42:47 it's kind of helpful
42:49 to educate everyone else in the company
42:52 as well
42:54 do you have some specific format for
42:56 your reports some templates that you use
43:00 not really i think
43:02 i would like to have one probably
43:05 but it changes over time and different
43:08 companies it like depends when you kind
43:10 of present to other people because
43:13 for a time you get you
43:14 get to know them and you know what's
43:16 like
43:17 more
43:18 insightful for them
43:20 so
43:21 i don't have any like automatic
43:24 reports i just do everything and code
43:27 and try to like present it in with some
43:30 kind of visualizations
43:32 so usually it contains some
43:34 visualization right so like this is like
43:37 for example if we take a b test so these
43:40 are the results with model and these are
43:41 the without this is the metric we
43:44 uh we're measuring and this is the
43:46 uplift right or there is no uplift and
43:49 our experiment is bad this is the kind
43:51 of
43:52 language you use for communicating the
43:53 results
43:54 yeah
43:55 okay
44:00 another question is
44:02 so is your background is that you were
44:04 transitioning from software engineering
44:06 to
44:07 data science
44:08 do you have any advice for people who
44:11 want to do the same
44:13 i would say that the most
44:16 important thing for me was to
44:18 kind of get used to this
44:19 non-deterministic mindset that it's
44:22 something i got to discuss a lot with uh
44:24 other people who try to
44:27 switch
44:28 as well to data science from
44:30 software engineering and uh usually a
44:33 lot of people struggle with that most of
44:35 all as well as with probably some
44:38 mathematical background and i'd say that
44:41 i'm trying to read about that more and
44:43 understand that and try some stuff and
44:45 practice that
44:47 something that helps
44:48 but i also think that it's kind of it's
44:51 not a problem to be a software developer
44:54 and not to be a researcher
44:56 because especially if you're kind of
44:57 focused on
44:59 working on specific problems in the
45:01 company not doing some kind of
45:03 research but more of the scientific
45:05 research then
45:06 it it's going to be more of your
45:08 strengths because
45:10 a lot of stuff is not just about
45:12 training a model it's about everything
45:14 else around it like the main thing is
45:17 deployment monitoring
45:18 so i would say for me it's really
45:20 helpful that i have this background
45:22 because it helps me to do all this stuff
45:25 in a more efficient way
45:28 so basically for you is uh
45:30 like if you work as a single data only
45:33 data science in the company
45:35 then it definitely helps to have this
45:37 background
45:38 yeah for sure because you kind of get to
45:40 do a lot of stuff from scratch and
45:43 implement a lot of things in the
45:44 beginning
45:47 and when it is the right moment to start
45:50 asking for more more data scientists so
45:52 let's say
45:53 you joined
45:54 a company as a
45:56 as a
45:57 as one data scientist and then you did a
46:00 couple of proof of concepts then some of
46:02 them really worked and then
46:05 you now have many projects some of them
46:07 were successful
46:09 and how do you
46:11 how do you understand that now it's time
46:13 to ask for help
46:15 like to get one yeah yeah i personally
46:18 kind of always feel that i don't know
46:20 intimately
46:22 in terms of like the load of projects
46:25 i mean like what's expected how many
46:27 projects in the same time are having
46:30 high priority and if i can like
46:32 physically do that all myself
46:34 and uh company-wise i would say if you
46:37 deliver value it's kind of
46:40 easier to get this kind of suggestion
46:42 from the company itself that you need to
46:44 get more resources and
46:46 to expand so
46:48 it's more about kind of your own work
46:51 and trying to deliver some kind of
46:53 results and also about uh managing
46:57 expectations and managing the workings
47:00 you do and
47:01 always kind of seeing that in terms of
47:03 pressure and
47:05 plans that you have for the future
47:08 okay so when you understand that you're
47:10 filing behind that uh many projects all
47:13 of them are important and you cannot
47:15 implement them
47:16 uh maybe
47:17 even the management will come to you and
47:19 say hey how about getting some help
47:22 yeah basically that's what happened like
47:24 uh at the first start of where it worked
47:27 but at some time at some point there was
47:29 already like
47:31 two data scientists except for me i was
47:33 like the third one because there was
47:36 several like friends which were
47:38 at the time really important and they
47:40 needed work and that's why
47:42 uh it kind of uh also takes time for me
47:46 as well to
47:47 mentor these people to
47:49 do some kind of onboarding but usually
47:52 this
47:53 this time usually pays off or if you
47:56 need to have some form done
47:58 simultaneously different directions
48:01 and
48:02 what about stopping a project so let's
48:04 say you work on a project so it looks
48:07 promising at the beginning
48:08 um you did a poc and then after some
48:12 time you realize that this project is
48:14 not going anywhere so like the results
48:16 aren't great you've spent too much time
48:19 on that um how do you stop working on
48:22 this project and perhaps pick a
48:25 different one
48:27 i think that it always happens and
48:31 it helps me to
48:33 discuss it with
48:35 is my team if i have like a big analyst
48:37 in my team i always discuss with them
48:39 like priorities what do they think it's
48:41 more important so
48:43 basically when you're like always asking
48:45 yourself if i'm doing the most
48:47 important stuff right now and
48:50 with
48:51 what can be done
48:53 faster than anything else and you're
48:55 kind of ready to switch to other things
48:58 and
48:59 regardless of
49:01 how how it could be like more or less
49:03 interesting for you
49:06 because uh like i know
49:08 at least for for me when i work on a
49:10 project
49:11 i develop this attachment to this
49:13 project even though i know maybe it's
49:15 not as successful as i wanted
49:17 this project to be but still when you
49:19 put some effort in a project it's very
49:21 hard to let it go so do you have any
49:23 secret how to
49:25 uh
49:26 to overcome that
49:27 like or advice maybe i think i i just
49:31 personally
49:33 don't feel uh when i try to stop the
49:36 project that i kind of have a lot of
49:38 regrets i don't know how it works i just
49:40 uh when i'm like working on the project
49:42 i'm usually like very much focused on it
49:45 but if i see that it's
49:47 not working i'm like just always saying
49:49 to myself that i will come back to that
49:51 later if it's gonna be important because
49:53 like
49:54 the main idea for me is not to do
49:56 something like to work on the same
49:58 project all the time because they just
49:59 like it but
50:01 uh like the main purpose of my work is
50:03 to
50:05 deliver some insights and to do that
50:08 uh in
50:09 an effective way so basically that's
50:12 more about like reminding what you're
50:14 doing and what's your purpose
50:17 do you have a list of questions that
50:20 let's say if you want to join a company
50:23 that doesn't have data scientists yet do
50:25 you have a list of questions that
50:27 you
50:28 want to ask before joining the company
50:31 like are there some i know maybe 5 10
50:33 questions that you have to ask before
50:35 making this decision to join them
50:38 yeah i think the first and the most
50:40 important question for me is uh
50:42 asking how does the company sees data
50:45 scientists and what do they expect from
50:48 from me in the company how do they
50:51 imagine what i'm gonna be doing
50:53 in in the company
50:55 and basically just uh hearing the
50:57 answers says a lot about
51:00 whether the company is ready for
51:03 data science and
51:05 uh whether they don't just think that
51:07 it's kind of some kind of a magic thing
51:09 that's going to solve everything or
51:12 uh how like the mature how much were the
51:14 companies in in this
51:17 matter and
51:19 also i would say that
51:21 more
51:22 additional problems
51:23 is additional questions is like what
51:26 kind of problems do you expect me to
51:28 solve because
51:29 again that says
51:31 about
51:33 how how already the companies and do
51:36 they like hire you for a specific
51:38 problem or are they just
51:40 having the feeling and situation that
51:42 something can be done but they are not
51:44 sure yet um
51:46 also i personally like to ask
51:50 how they how do you select the deadlines
51:53 when do you expect the results to be
51:55 delivered because uh
51:58 it seems to me that
52:00 a lot of companies which are not really
52:02 familiar with data science they
52:04 think in terms of the deadlines from
52:07 software development and usually it's
52:09 kind of faster than it is
52:11 in data science and
52:12 again it says about kind of preparation
52:16 and
52:17 if the company is ready to accept how
52:20 the process is going to be running
52:22 with data science um
52:24 also i would say uh it's important to
52:28 get to know more about the collaboration
52:31 between teams and to ask about that like
52:34 if the teams are collaborating together
52:37 how often do they build something
52:38 together and
52:40 uh can one team like work on on the task
52:43 on another continue something because
52:45 basically this is uh maybe i would say
52:48 even the essence of what we do as data
52:50 scientists because like i can just
52:53 create some model but if it's
52:55 if the results of this model are not
52:56 used later on by other teams it doesn't
53:00 really matter that much and won't
53:02 provide any kind of results and
53:05 it won't be i won't be able to get some
53:08 like evaluation of what i've been doing
53:10 and it won't be visible whether it's it
53:14 was actually forced to hire data
53:16 scientists for the problem
53:19 and maybe also
53:22 i personally
53:23 ask about the future plans of the
53:26 company like if they're planning to have
53:28 a team in the future
53:30 uh to just
53:32 get to understand uh
53:34 what kind of problems they do they have
53:36 how they they perceive that and
53:39 because i personally like interested in
53:41 expanding stuff and then not just always
53:44 like coming to the companies that i will
53:46 be working as a only data scientist in
53:49 there for years because it's
53:52 obvious that problems require like more
53:54 resources so for me it's also
53:57 interesting to hear
53:59 how company perceives that and
54:02 do they actually see
54:04 this
54:05 like as
54:06 a some kind of potential field for
54:09 growth and
54:11 something to do in there for the company
54:14 yeah thank you and you mentioned at the
54:16 beginning was one of the first thing is
54:19 like whether a company is ready for data
54:20 science
54:22 and
54:23 how do you assess readiness is it
54:25 something that we talked about like
54:26 having a data pipeline having uh uh
54:29 analysts uh or maybe a department with
54:32 analysts things like that right yeah and
54:34 also like uh hearing how they kind of
54:37 describe what data scientists do because
54:40 it helps to understand whether they
54:41 already like have some expectations if
54:44 they are close to reality or not and
54:47 if if they are not whether it's going to
54:50 be a problem or not
54:53 so how do you ask that like what in your
54:55 opinion do data scientists do every day
54:58 like you just ask like that
55:00 it's more like how do you imagine like
55:02 work whatever you'll be doing or
55:05 to solve this kind of problem or what
55:07 kind of problem they expect me to solve
55:09 so it's
55:11 more like
55:12 i would say
55:13 more vague way of asking that
55:17 yeah i see that there is uh i managed to
55:19 restore my computer and they open slider
55:21 with questions and i see that there is a
55:23 question with four uploads
55:25 i know we run out of time but maybe you
55:27 have a couple of more minutes to yeah
55:29 answer that question
55:31 yes so
55:32 when would it be best to take a model
55:34 out of research environment and
55:36 integrate it into the live product and
55:37 what factors are important
55:39 to think about when doing that
55:42 i would say that it's better at first to
55:45 test it out
55:46 if it's possible outside of a product
55:49 like sometimes it's not always
55:51 implemented inside of the product like
55:53 for example
55:54 uh the churn prediction model that i
55:56 worked on in your stream which basically
55:58 helps
55:59 one specific team and it doesn't really
56:01 influence anything related to the
56:03 product so it's like not integrated into
56:05 it but sometimes like
56:06 for example uh i used to work and when i
56:10 worked in a fintech startup there was a
56:13 lot of work related to anti-fraud the
56:15 credit scoring and it was like one of
56:17 the
56:18 key components of clients evaluation
56:22 so before just integrating all that and
56:25 running all the clients for this new
56:27 way of
56:28 evaluating them uh the thing that i did
56:31 was kind of baby testing i was just
56:33 running it in the silent mode and
56:35 getting some kind of responses of the
56:36 model and trying to relate that
56:39 and instead of like just turning it all
56:42 on and seeing how it works because it's
56:44 kind of a risky thing to do i would say
56:49 and
56:49 if you like
56:51 this kind of first results you already
56:54 get to know if it's worth it to try to
56:57 run it in like fully in production in
57:01 inside your product but still even if
57:03 you like get around it i i wouldn't say
57:06 that it's good to turn it like on for
57:08 all the clients it's better to do it
57:10 kind of in an aba testing manner
57:14 okay thank you
57:16 um maybe
57:18 do you have any last words before we
57:20 finish today
57:22 i would say like
57:25 the something that is the most important
57:27 for me personally when i
57:29 start introducing data science and
57:31 companies is about
57:33 not being
57:34 intimidated by challenges and be able to
57:38 kind of learn fast and
57:40 be ready that you sometimes have to do a
57:42 lot of work yourself and also educate
57:45 people around you but hopefully
57:47 sometimes that's a fun that for me at
57:49 least it is
57:52 thanks how can people find you
57:56 uh you can find me on
57:57 i think linkedin i'm not really
57:59 accidentally here but also on facebook
58:03 as well
58:05 okay
58:06 yeah thanks a lot thanks for joining us
58:08 today thanks for sharing your experience
58:09 uh i apologize for all the technical
58:12 difficulties versus the sound
58:14 computer yeah happens in one stream
58:17 first when i go live
58:20 okay thanks everyone for joining
58:22 us today for asking questions uh
58:25 and
58:26 yeah have a great weekend good way
58:29 yeah you too bye