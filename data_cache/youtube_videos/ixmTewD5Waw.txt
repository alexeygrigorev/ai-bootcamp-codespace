0:00 let me just quickly do that so welcome
0:02 everyone
0:03 thanks for joining us today so this
0:06 event is brought to you by data talks
0:07 club which is a community of people who
0:09 love beta
0:10 we have weekly events and this is one of
0:13 such events
0:14 and you can find out more about events
0:17 if you go to our website
0:19 which is datatalks.club events
0:22 and uh yeah so you can see that for the
0:24 next week
0:25 we already plan a couple of events so
0:28 one will be about beta mesh
0:30 so you can just quickly click on this
0:32 and show you
0:34 so the one that we oops
0:40 yeah so next week we will have two
0:42 events so one will be about data mesh
0:45 which is uh anything nobody knows about
0:48 i also don't know what it is so we will
0:50 learn uh what it is next week and then
0:53 we will talk about on the podcast on
0:55 friday about data observability
0:58 and today yeah of course
1:01 if you want to stay up to date the best
1:03 way to do this is to
1:04 join our slack and subscribe our
1:06 newsletter
1:07 and you can also subscribe to our
1:09 youtube channel and then you will get a
1:10 notification about every event
1:13 and during our chat today now you can
1:15 ask any question there is a pin link
1:17 in the in the live chat on youtube just
1:20 click on this link
1:22 and ask any question you want and i will
1:24 try to ask this question during an
1:26 organization
1:28 and that's actually it for the
1:30 introduction
1:31 i think we can start are you ready
1:35 yeah okay so
1:40 this week we will talk about career
1:42 transitioning from data analytics to
1:44 data science
1:45 and we have a special guest today
1:47 andrada and radha worked for two and a
1:49 half years
1:50 as a data analyst and then she decided
1:52 to make a career switch
1:54 and she became a data scientist
1:57 and today she will share uh your
1:59 experience with us so welcome
2:01 hello everybody i'm super glad i could
2:04 join and
2:05 yeah i hope you're gonna get something
2:08 interesting from this
2:10 so before we go in uh into our main
2:13 topic
2:14 so let's start with your background can
2:16 you can you tell us a bit more about
2:18 your career journey so far
2:20 um yeah so i
2:23 was uh i did my undergrad in statistics
2:26 um during that time i wanted to get a
2:30 little bit
2:30 of domain knowledge hands-on and
2:33 i was a data analyst at avon cosmetics
2:36 in
2:37 my country in bucharest romania
2:40 afterwards i made a i did a masters in
2:44 data science analytics in the uk
2:48 during the time i found my passion about
2:50 kaggle on kaggle as well
2:52 and afterwards i came back and i started
2:56 working
2:56 working at endava as a data scientist
3:00 uh and that's about it so now you're in
3:03 bucharest nah yeah i'm in bucharest and
3:06 it's super sunny and i'm super excited
3:08 about it
3:09 does it often happen that you have some
3:12 uh yeah
3:12 but in uk it wasn't it wasn't the case
3:17 yeah okay so how did you realize
3:20 so you were studying statistics you were
3:24 working on the data
3:25 unless how did you realize that you want
3:28 to go into data science
3:32 so i guess it was i guess it was a
3:36 multitude of factors one was that i had
3:39 this
3:41 so i think the main reason i would say
3:44 now that i'm thinking about it was a
3:46 girl in my class
3:48 in my statistics class who
3:51 was talking obsessively about data
3:54 science
3:55 and i was a data analyst and i was doing
3:57 my thing and i liked it i liked it a lot
4:00 uh actually but she was talking a lot
4:04 about data science and i was
4:06 uh watching also some machine learning
4:09 the
4:10 articles and so on so i was like okay
4:11 what is this it's it's
4:13 it's so confusing to me and afterwards i
4:16 started researching
4:18 and uh during that time i also knew i
4:21 wanted to
4:22 to do a masters and because i already
4:25 was
4:26 working at avon and i was a data analyst
4:28 i was like okay i want to do a master's
4:30 a little bit deeper
4:31 not only or not on what i already know
4:34 right
4:35 so uh okay then
4:38 i will start doing data science and then
4:41 because i wanted to kind of get ahead
4:45 and not be a super noob when i went into
4:49 that masters i didn't know how hard it's
4:51 going to be
4:54 i started uh some courses on my own
4:57 on basics on data science and then i
5:00 kind of discovered how fantastic that
5:02 is and i started enjoying more and more
5:06 and because i kind of felt like
5:09 i already knew some data analytics
5:11 although it might not be the case
5:13 i went into data science full-on and
5:17 i've been doing it since then do you
5:20 remember which
5:21 courses did you take oh yeah very very
5:25 vividly um so the first
5:29 thing that introduced me to data science
5:31 the very
5:32 first thing and i highly recommend it to
5:34 anybody who
5:36 who didn't do python who doesn't know
5:39 about
5:40 machine learning i also all
5:43 only knew about regressions
5:46 because i did them in statistics linear
5:48 regressions so that's
5:49 it i highly recommend the data science
5:52 and machine learning bootcamp
5:54 on udemy it's from joseph
5:58 portillia i think portillia someone
6:01 he's he's absolutely amazing like
6:05 he did these courses so so nicely and
6:09 he teaches you okay this is anaconda and
6:11 this is how you start
6:12 notebook okay let's start with python
6:15 now i'm gonna explain
6:16 to you some pandas and some numpy okay
6:19 now what's linear regression now i know
6:21 you didn't come
6:22 only for a linear regression so take
6:24 some
6:25 i don't know random forest or decision
6:27 trees and so on so
6:29 i really at that moment i understood
6:34 what data science is and i had
6:37 my foundation and afterwards you can
6:40 build on whatever you want but that was
6:43 the foundation i really really needed
6:47 so uh was it something that you you did
6:50 this course during your
6:51 undergrad studies in statistics or
6:53 something later during your masters
6:55 i did them before my master's so i think
6:59 it was
7:00 the summer before my masters i was still
7:03 working
7:04 but i wanted to to prepare a little bit
7:07 yeah
7:07 so you so there was a girl in your class
7:11 yeah and she told you okay there is this
7:13 thing and you started to read more and
7:15 more about that
7:16 then you finally found that course on
7:19 udemy
7:20 and you did that course and you
7:22 understood okay this is a super cool
7:24 thing
7:24 and then you decided okay i want to
7:27 spend more time doing that and you
7:28 decided to go and do a masters
7:31 and i guess kegel was a big factor as
7:33 well because
7:36 it's the community and the comments and
7:39 the
7:40 medals and the fact that you can
7:42 interact with somebody like
7:44 you post on stack overflow
7:48 uh i was dragged up so actually it was
7:50 like overflow
7:51 once i posted and they downvoted my
7:55 i'm sorry because i was like oh you
7:58 didn't put the question right although i
8:00 put a disclaimer there you know i
8:02 i haven't done this before sorry and
8:05 i've never asked the question on stack
8:08 overflow again
8:10 whereas on kegel you can just you know
8:12 ask and people are so nice so
8:14 a kegel was a big factor as well
8:18 and how how did you discover kaggle so
8:20 you you were doing this uh
8:22 bootcamp course on udemy um was it uh
8:26 did you find kaggle after the course
8:28 during uh or
8:29 like during your masters or when um so
8:32 my first interaction
8:34 with kegel was uh
8:37 somebody told me during my undergrad
8:39 studies
8:40 uh and i entered i didn't understand
8:44 anything was going on
8:45 with this is a spaceship i'm out um
8:49 afterwards and this is why i'm saying
8:52 this was a big foundation such a big
8:53 foundation for me
8:54 uh during that udemy
8:58 course at some point or towards the end
9:01 i can't
9:02 remember he was like you can practice
9:05 more on kaggle i was like oh
9:08 okay i i remember that spaceship i was
9:11 so
9:11 frightened about so i naturally went
9:14 into kaggle and
9:16 i didn't even i knew it was complicated
9:18 i didn't want to do
9:19 anything with it just the courses give
9:22 me the courses i want to understand more
9:24 and more and afterwards because they
9:26 kind of tease you
9:28 from the courses into a competition
9:31 i entered really into the world and
9:34 um this is how it happened
9:37 and then what happened then yeah
9:42 then uh so
9:46 then i didn't even understand what i was
9:48 doing when i was i remember
9:50 i didn't even understand what i was
9:52 doing when i was
9:53 sharing the notebook and
9:57 i remember the only thing i wanted to do
10:00 was to improve my model it was the basic
10:05 sales high iowa house price competition
10:09 which is the natural progression from
10:12 the machine learning courses on kegel
10:14 which are by the way absolutely amazing
10:16 and are
10:18 in my opinion were best
10:22 over that course on udemy because i had
10:24 my foundation but then i
10:26 i i found out how to put some new
10:28 questions to improve my models and make
10:30 them better
10:31 yeah so
10:35 uh i started trying to improve the
10:39 models
10:40 and then because i wanted to
10:44 understand more i started okay so i
10:48 learned
10:48 visualization now i'm gonna do a
10:50 notebook on visualization
10:52 i was just my only purpose of of doing
10:56 the notebooks
10:57 was just to use the data sets on kaggle
11:00 because they were interesting and then
11:03 to practice
11:04 my skill that i wanted to to to
11:07 gain on kaggle so i wasn't posting to
11:11 gain medals or something much more later
11:15 um so i did this notebook which is
11:18 highly appreciated
11:19 although i don't understand why because
11:21 it's it's so basic
11:23 whatever maybe that's why like it's
11:26 basic and simple and people can just
11:28 open it and understand what's going on
11:30 and uh i remember that
11:32 uh on kaggle sometimes there is a good
11:36 notebook that kind of gives you a good
11:38 score but you have no idea what's going
11:40 on
11:40 yeah it's
11:44 for smart people very very smart people
11:47 and
11:47 uh yeah maybe that's why because like
11:49 it's so simple and people can understand
11:51 and relate and really follow through and
11:54 see what's going on and learn from this
11:57 and
11:57 uh yeah just to so you're uh you
12:00 you took some courses on cargo right and
12:03 then at the end they kind of teased you
12:04 to
12:05 to try competition and then the
12:07 competition was about predicting prices
12:08 for houses right
12:10 and he did not one notebook there and as
12:12 i understood it kind of become
12:14 uh became popular right so people
12:16 started to focus
12:19 that one was i think it still has 20
12:22 upvotes after one
12:24 year and a half or something no
12:27 but although in my opinion it was pretty
12:29 good like i
12:30 jumped i became obsessed on the
12:32 leaderboard
12:33 and i jumped at some point after some
12:36 hardcore
12:37 hyper parameter tuning i remember i
12:39 stayed one day nine hours straight
12:42 oh that's why i put parameter tunic but
12:45 it was so exciting because the error was
12:47 dropping and i was like
12:49 oh my god okay and i remember i
12:52 went to top five percent or three
12:54 percent or something
12:55 and so it was super addictive but what
12:58 it happened
12:59 afterwards i started to kind of try to
13:02 gain more knowledge on multiple things
13:04 and i remember i was super i didn't have
13:07 any
13:08 any knowledge on pandas and how to
13:11 manage data frames and it took me
13:15 it was taking me a lot a lot a lot of
13:17 time to do anything
13:19 visualizations everything it was taking
13:21 me a long time because
13:22 i was a beginner and i did that um
13:26 brazil fires analysis which was just
13:30 that it was the moment when there was uh
13:33 that problem in the world but also i
13:35 wanted to try to
13:38 exp experience on a data set that i was
13:40 passionate about
13:41 and that one that notebook i remember i
13:45 did
13:45 summer in september last year i didn't
13:49 i never went to kaggle until i think
13:52 late october just because i was doing my
13:54 master's and i was kind of oh what
13:56 what's
13:57 what's this you know and
14:00 when i went back to kaggle although i
14:03 already had
14:04 like two or three notebooks and no
14:05 uploads whatsoever
14:07 how do people get these i i don't
14:09 understand
14:10 um i had the silver medal or something
14:14 that was it do people see this
14:20 what and that's when actually everything
14:24 everything started so as i understood uh
14:28 so like we talked quite a lot about
14:31 kaggle and
14:32 as i understood that was one of the main
14:34 drivers for your
14:35 learning so you picked up pandas
14:39 some other data wrangling skills
14:41 visualization
14:42 doing the exploratory data analysis
14:46 and i think this is like when you learn
14:48 something especially data science but
14:50 it's not just for data science when you
14:51 learn anything
14:52 the important thing is to do projects
14:55 would you say that for you
14:56 the projects that you did to learn data
14:58 science were mostly coming from kaggle
15:00 or you also did some other projects to
15:02 learn it
15:04 100 90 of them came from kaggle
15:08 the other 10 were
15:12 my dissertation and
15:15 i think a few other projects that i had
15:18 in my masters
15:20 uh and then i kind of translated them
15:23 two of them i actually translated them
15:25 into
15:26 into kaggle so
15:29 still chiago how did you translate them
15:33 like you were writing your thesis you
15:35 said and then how did you put this to
15:37 kaggle just uploaded your notebooks
15:39 there or
15:41 not really because it was some some
15:44 of them were data sensitive for example
15:47 uh i had this amazing module in my
15:50 masters that was
15:52 hands-on and we had three projects um
15:56 two of them three projects three
15:58 projects
15:59 two of them were in teams and we would
16:02 change
16:02 team after each project which was
16:05 exhausting but they wanted us to push us
16:08 to interact with as many people as
16:11 possible
16:12 and the last one was uh solo
16:15 and what happened for example from the
16:18 first project
16:19 it was on audio files that project i use
16:23 heavily in the
16:26 birth call competition on kaggle heavily
16:30 the second one was on fraud detection
16:33 and
16:34 after i finished it what i did was i
16:37 didn't
16:37 use the oh actually the data they
16:40 used was from kaggle but they
16:43 altered it a little bit so what i did
16:46 was
16:47 i just translated what i've done uh in
16:50 that fraud detection
16:51 challenge i would say i would call it to
16:54 the
16:55 to kaggle using the data set on kaggle
16:58 so not the one they provided
16:59 and last one i can't even remember what
17:02 was the project about
17:06 oh the fraud detection was the last one
17:08 the one in between was the one with
17:10 sensitive data that i couldn't
17:11 i couldn't use but it was super like on
17:14 optimization
17:15 on it was super complicated yeah and my
17:18 dissertation for example i did sentiment
17:21 analysis
17:22 on their bike sharing scheme in
17:25 belfast i was in belfast and
17:28 i learned so many interesting things and
17:31 what i did
17:32 is after i finished i remember
17:35 the person who actually hired me who's a
17:37 grandmaster as well on kaggle gabby
17:39 preda shout out to gaby pritha he's
17:41 absolutely amazing he
17:44 texted me on linkedin and he said have
17:46 you seen
17:47 i uh there that data set on covet tweets
17:50 and i was like oh yeah
17:52 do you want to do a sentiment analysis
17:53 on it and i was like oh yeah
17:55 and then i transcribed everything i kind
17:58 of
17:59 learned from in my dissertation to a
18:02 fun interactive kaggle notebook on that
18:06 data set yeah okay so uh
18:10 i heard what you said like so you
18:14 found a job because uh uh somebody from
18:17 kaggle reached you and
18:18 i think that person i don't well what
18:21 was the the name
18:22 gabby pradam okay so so he found you
18:26 on kaggle of course right and then i
18:28 found him i think okay
18:31 i think it was more from me than from
18:33 him
18:35 um yeah so
18:40 keagle was full of opportunities from
18:43 for me
18:44 and when i started i never realized and
18:46 this is why i encourage
18:48 every time and i think people are
18:50 getting bored so if you
18:52 if you listen to two talks from me i'm
18:55 of
18:55 cargo make but just because it brought
18:58 me so many opportunities
19:00 and my job was one of them
19:04 and what happened is at first
19:07 when i started doing google i wasn't
19:10 used to any romanian name
19:13 so when i found the rankings it took me
19:16 like
19:17 half a year into kegel is super complex
19:20 i
19:20 i guess i wasn't curious enough
19:23 so when i went into rankings
19:28 with the idea of i wanted to take
19:31 a lot of people especially from the top
19:34 and
19:35 follow them and i recommend this to
19:37 everybody follow
19:39 people on kaggle on linkedin on twitter
19:41 or
19:42 on anything they usually have the handle
19:45 if they are in top 50 it means they are
19:48 very top 100 top 200 i i think i took
19:52 two
19:52 top 200 people it means that they are
19:54 super passionate and it might be that
19:56 you you have something to learn from
19:58 them
19:59 anyways and when i saw in top five or
20:02 six or something
20:03 a romanian name i was shocked i was like
20:06 oh
20:07 we can do this too what
20:10 and i followed him um
20:15 and i was like i was super chill i
20:17 didn't i didn't text him or anything i
20:18 was like
20:19 well me i think a contributor
20:22 at that time or something like that i
20:24 i'm not gonna do this
20:25 and afterwards i think i i don't know
20:28 how he
20:29 remarked me but i at some point he
20:32 followed me back
20:33 and he left me like a super sweet
20:37 comment
20:38 super genuine comment on
20:41 one of my notebooks it was a sentiment
20:43 analysis or rick and morty tweets
20:45 which it's one of my favorites
20:49 but he left a comment there and i
20:52 remember i was so excited like i was
20:54 super happy about it and afterwards when
20:58 i realized i wanted to come back to
21:00 to to bucharest when i started
21:04 searching job uh jobs i
21:08 texted him as well and i
21:11 would also recommend this to anybody
21:14 because finding a job you need to apply
21:16 to 100 to get
21:19 five back responses back and maybe one
21:21 is gonna
21:22 gonna say yes so i would recommend
21:25 to text to anybody and i knew
21:28 he was elite in dava i knew he was
21:33 i wanted him gabby i hope you're not
21:36 listening to me
21:42 i really i really really wanted a mentor
21:45 and uh he
21:51 the data science field is changing
21:54 a lot fast and
21:58 you can't be a person that isn't open to
22:01 change to be a good data scientist
22:03 because if you're using words today in
22:06 two years
22:08 i it's gonna be absolute
22:11 maybe not worth is a good example but
22:13 look at i don't know
22:15 just simple vanilla neural networks they
22:18 aren't used anymore
22:19 you use more complex algorithms or you
22:22 aren't using the
22:24 regression you are using an xj boost for
22:27 example or random forest or whatever
22:29 so you need a person who's open who
22:32 likes it
22:32 who reads who is passionate about data
22:36 science
22:36 and he is and i knew he was just because
22:39 he was so active or keggle and he liked
22:41 it and i i saw him
22:42 he had an interest in it so i was
22:45 thinking that i really wanted
22:47 to find a job not really it wasn't the
22:50 job i was looking for it was kind of
22:52 a person that would
22:55 teach me things
22:58 uh and i had a lot of interviews with
23:00 people that i didn't
23:05 i could have went further but i just
23:07 stopped them just because i knew
23:09 if i get this job i'm not i don't i
23:11 won't like this person
23:12 and i won't be able to work with him
23:14 yeah so i found gabby on kegel and i'm
23:17 super lucky that he he saw opportunity
23:21 in me and i'm super grateful
23:23 uh for that now maybe we can talk a bit
23:26 about
23:27 this process for looking for a job so
23:30 you said that you need to apply for 100
23:32 positions to get
23:33 just one job offer so for you how many
23:36 did you apply to
23:39 it wasn't 100 just because
23:42 but it took me a long time
23:46 but it depends it depends a lot and
23:50 you don't need to go into looking for a
23:53 job
23:54 thinking that it's gonna take me a long
23:56 time because it might not
23:58 but usually and in my case i remember i
24:01 started
24:02 so to give you uh a comparison
24:06 i am the struggling one usually
24:10 and i had another calling in my master's
24:13 who
24:13 she's super smart and she
24:17 found the job much quicker
24:20 so it took me for example i started
24:22 looking for a job
24:23 in june and it took me until
24:27 october to get the proposition she
24:32 on the other hand started looking in
24:36 august at
24:39 late august summer
24:42 beginning of august and in late august
24:44 she already told me she was having an
24:46 offer kind of so
24:51 it depends and it's hard and you're
24:53 looking at other people
24:54 and maybe they are more lucky but you
24:57 need to be resilient i didn't
24:59 apply to 100 jobs just because i
25:02 remember i was having a habit
25:04 every friday i would stay for two or
25:06 three hours to apply
25:08 just because i couldn't find 100 jobs to
25:11 apply to
25:12 because it was coveted so
25:16 i i was trying in bucharest which is
25:20 a metro kind of it's a metropolitan area
25:23 it's the capital of romania
25:26 but i was also trying uh to other
25:30 countries to be remote there weren't
25:33 many positions for a
25:36 junior data scientist you know that
25:41 so everybody looks for a
25:46 trainee data scientist with the senior
25:49 knowledge
25:49 and the no a junior data scientist with
25:53 a senior knowledge but
25:55 the salary of a traineeship or something
25:58 i wasn't i didn't fit so it took me a
26:01 while
26:01 and i had many rejections as well which
26:04 hurt
26:06 sorry what were the main difficulties
26:09 for you so you said it was
26:11 so you started in june and you found in
26:13 october so i think it's like
26:15 i know five months it took five months
26:17 yeah
26:19 so what were the main difficulties for
26:21 you in this process
26:27 the main difficulty and it
26:30 still is a big difficulty for me
26:34 is the coding part
26:39 so is it like a lot of competition or
26:41 just people don't want to hire
26:43 juniors to work remotely or no
26:46 it's that um
26:50 so in all the interviews i had
26:54 besides the one for endava so with gabi
26:58 so all the other interviews i had
27:02 were testing me on coding
27:05 but on algorithmic
27:09 coding style
27:13 it was um i remember i had
27:17 so i had an interview for this company
27:19 i'm not gonna name names
27:20 just because it doesn't matter and my
27:23 partner was having
27:24 an interview exactly for the same
27:26 company i was having it
27:28 for romania but he was having it for i
27:30 think london
27:31 it doesn't matter but it was the same
27:33 company and we had
27:35 a part of one day he had a coding
27:39 uh interview and i also had a technical
27:42 interview not really a coding he
27:45 had an easier so he's in cyber security
27:50 he had an easier algorithm
27:55 than i had which i was applying for a
27:58 data scientist
27:59 and i was like what's happening and when
28:02 they tell you
28:03 okay try to solve this and they watch
28:06 you
28:08 and i'm like i have no idea what you're
28:10 telling me please
28:11 can we please talk about data sets can
28:13 we please talk about
28:15 projects can what and i remember
28:18 i was struggling a lot just because i
28:21 was doing a lot of
28:22 um algorithmic coding online with
28:26 exercises which i
28:27 i hate i genuinely hate
28:30 because these are the interviews whereas
28:33 for example for endava
28:34 what happened is i just had
28:38 a normal conversation because i already
28:44 they already kind of knew that i knew
28:47 data science and i know at least roughly
28:50 how to code because of my projects on
28:52 kaggle
28:53 so the only thing was talking about
28:56 okay how would you solve this problem
28:59 okay what about this
29:00 okay so we have this project or what
29:02 projects have you been working on
29:04 how did you solve it so it was more
29:07 about how would you say
29:12 uh how you think a problem not
29:16 i'm gonna see if you know this algorithm
29:19 that you need to know by heart and uh
29:21 i don't i'm not gonna hire you so most
29:24 of the interviews were of this sort
29:26 of uh asking like okay like uh
29:30 i don't know uh one famous uh
29:34 example i often got in the past was
29:37 you know you have like a string with the
29:39 brackets
29:40 you know opening brackets and closing
29:42 and you need to find out if it's a
29:44 balanced or not balanced
29:45 okay and this kind of stuff that you
29:48 don't
29:48 need at work at all it's like more like
29:51 a brain teaser
29:52 so i guess uh most of the
29:55 uh the interviews they were asking for
29:57 these kind of things right
29:59 they put me to create a class
30:02 that would receive a
30:05 i i'm trying to remember the problem
30:08 correctly it's a
30:09 a popular one and if you try to find it
30:12 on google
30:13 you you'll find but i can't remember the
30:16 name
30:17 it's the thing that you have a tree
30:21 and on any node you give
30:24 you want to get the
30:28 other nodes that have the same neighbors
30:31 it was something like that and i don't
30:34 even work with classes
30:36 like i usually don't uh
30:39 just with pytorch and it's usually
30:42 pretty
30:42 if you know a few examples you can make
30:45 them but i was like i i have no idea how
30:47 to
30:48 you can you so it was very difficult
30:52 for me and usually you finish these
30:54 interviews kind of
30:56 negatively impacted being like oh i'm
30:59 super stupid
31:00 like i shouldn't be doing this i
31:02 shouldn't be doing this but it's not
31:04 true
31:05 it's and the other interview for example
31:07 that i had it was
31:08 for pandas but they didn't let me google
31:14 which i think it's something
31:18 stupid as well just because you google a
31:21 lot at work
31:23 um and they put me also it was on pandas
31:27 but they
31:27 put me to do this weird long
31:33 kind of not really function but
31:36 when you call multiple pandas function
31:39 to get
31:40 something a filtering of some sorts from
31:43 this
31:43 from from a table and i managed to get
31:47 almost to the end uh and i remember the
31:50 guy being
31:51 like oh you know you should know this
31:54 this is super simple
31:56 and when they tell you it's super simple
31:58 you're you're feeling
31:59 more stupid you know uh
32:02 yeah so in my opinion they are not
32:05 realistic
32:06 okay that is that must be a very
32:08 frustrating experience
32:10 but uh yeah we all go through this yes
32:14 but what i heard is like your visibility
32:17 on kaggle and your passion because i
32:19 hear from you that you're super
32:21 passionate about uh
32:22 kaggle and community there so you had uh
32:26 like you had some visibility you have
32:28 visibility there people know you people
32:30 see your notebooks people
32:32 i see what you do there and for people
32:34 in the community
32:36 uh they recognize you right and then uh
32:40 this also helps having some visibility
32:42 in a community to
32:44 get a job and i guess this was one of
32:46 the factors how you managed to
32:48 uh eventually get that one offer attend
32:51 right
32:51 from from this company it's better
32:55 than only to have a cv to be like i know
32:58 python
32:58 to also be like i know python look my
33:01 kegel profile i use python
33:04 uh i am
33:07 familiar with pytorch it's just the cv
33:10 where's this other guy who's like i know
33:12 pot pie torch
33:14 look these are three projects on keggle
33:16 that i did using pytorch
33:17 because you can see and
33:22 i don't know how familiar are companies
33:25 with uh kaggle
33:26 but i think they are starting to and
33:29 having a portfolio
33:30 is super important rather than only
33:32 having pcb
33:34 uh cv's resume sorry resume yes
33:37 doesn't matter i think it's the same
33:39 thing okay
33:41 yeah and uh it can be kaggle it can be
33:43 maybe just a github profile or
33:46 i don't know home page with projects or
33:49 blog posts
33:50 but i think the good thing about kaggle
33:52 is you have a community element there
33:55 if you just write blog posts maybe
33:57 nobody sees this blog post but on cargo
33:59 you have this community
34:01 you also have this social uh element
34:04 where people can follow each other
34:06 so every time you create a notebook i
34:08 don't know how many
34:09 followers you have on google but all
34:11 these people see your notebook and then
34:13 they rush
34:14 and avoid the notebook and i don't think
34:17 the followers see no because i have many
34:20 people's
34:21 people that i follow and i usually i
34:24 don't know how the algorithm works
34:26 but on the feeds i don't
34:29 you i don't see them usually okay
34:33 but yes it's it's a big interactivity
34:37 and if you're doing some amazing work
34:40 people
34:40 eventually are going to follow but it
34:42 doesn't
34:43 so i have many notebooks that i'm not
34:46 that proud of
34:48 that are super super uh upvoted
34:51 and i have other notebooks that are my
34:54 pride and
34:54 joy truly and have
34:59 very little or almost no uploads
35:03 at all so it's the thing that you want
35:05 to create it's not really
35:07 the upvotes matter and i would be
35:12 it wouldn't be true if i would say they
35:13 are
35:15 don't matter at all they matter but it's
35:18 not good to start working on kegel with
35:21 that goal in mind because you aren't
35:24 gonna get
35:25 far by looking at the numbers
35:29 yeah we have a related question so why
35:32 do you prefer
35:33 kaggle over github for show ques is
35:36 showcasing your project's work and
35:38 code i guess just because i'm more
35:42 familiar with it
35:46 i
35:49 link github with coding
35:52 and with libraries whereas i link
35:56 kaggle with projects
36:00 and with community and showcasing
36:05 some sort of algorithm or result or
36:08 whatever
36:10 and this is why i i thought at some
36:12 point to move my notebooks or to github
36:15 as well
36:15 but i don't think it's gonna do me
36:19 any any good or any more justice so
36:24 but there are people that have quite
36:26 amazing githubs so if you are
36:30 the person that makes life easier
36:33 doing functions and creating libraries
36:36 or amazing
36:36 amazing stuff go ahead and do github
36:41 okay and so as i understood for you when
36:44 you were
36:45 making the switch from analytics to data
36:47 science the biggest problem for you was
36:49 uh coding right so like especially in
36:52 interviews like how do you pass all
36:54 these uh korean interviews uh
36:56 that are difficult and stressful
37:00 and also sometimes they say oh it's easy
37:02 but uh for you it's not
37:03 and it's demotivating but yeah there
37:06 were also
37:08 things a that you did as a data analyst
37:12 on an elite unless that were helpful for
37:14 you
37:15 right uh i don't know some data
37:18 wrangling skills uh
37:19 so what were the the things that were
37:22 useful for you
37:23 as a data scientist now
37:28 i guess
37:33 the most important thing i guess
37:36 it was the process of solving a problem
37:41 because so i did statistics and at work
37:45 i was doing data analytics which aren't
37:48 quite hand in hand but these two as a
37:52 mix
37:54 gave me i remember
37:57 the most important thing i learned from
37:59 avon was
38:01 triple quadruple check
38:04 whatever you did you did a group by
38:09 check the data to see if everything is
38:12 fine
38:12 because i sent some reports that were
38:15 quite messed up to 60 people and then 60
38:19 people
38:19 came back to me being like no you're
38:22 wrong
38:23 and then i sent them back being like
38:25 look now they are good
38:27 and then 60 people came back to me being
38:30 like no
38:30 you're wrong again so triple
38:34 check the data which is also super
38:36 important machine learning because
38:38 can have data leakage you have missing
38:41 data that needs to be
38:43 needs to be tackled you have variables
38:46 that
38:47 you need to understand them you need to
38:49 have business knowledge and domain
38:52 knowledge
38:52 which also is super helpful um
38:55 from statistics i remember i
38:59 the distributions understanding the data
39:03 understanding what's uh
39:06 a tabular data set not really a data
39:09 frame but
39:09 tabular data set understanding kpis
39:13 these all
39:14 are super important within the
39:20 data pre-processing and analyzing part
39:24 and now that i'm talking i realize maybe
39:27 this is why
39:28 i like it so much rather than
39:31 hardcore modeling i like that part as
39:34 well
39:35 but again that part needs a little bit
39:38 more
39:40 coding expertise that i am
39:43 struggling to gain as i move forward
39:46 i want to gain more but it's just an
39:49 area that for me
39:50 doesn't come as easily as exploring
39:54 and losing yourself into the data and
39:56 understanding things that are super
39:58 super interesting so correlations as
40:00 well
40:01 these particularities and subtleties
40:05 now there are many people that come to
40:07 me and ask
40:09 but isn't this the harder part and the
40:12 coding is the easy part
40:13 i actually i'm participating in some
40:17 courses now
40:19 where the class is talking to the
40:22 teacher and they are like
40:24 can you please teach us more coding and
40:26 less slides
40:28 and he comes back and says well
40:31 you'll see the slides are more important
40:34 than the coding
40:35 now i disagree
40:41 because this is my opinion and this is
40:44 my background talking maybe a software
40:47 engineer is going to be
40:49 disagreeing with me as well we can agree
40:51 to disagree but in my opinion
40:54 it's easier to understand the concept
40:57 and it's easier to
41:00 you don't really need to go
41:03 so deep into the mathematics only if you
41:06 want to do research then you'll need to
41:09 but just to use the algorithms you don't
41:12 need to go so deep into mathematics
41:14 whereas the coding part
41:18 you need to know how to do stuff it
41:20 doesn't matter if you know
41:22 the idea you need to understand how to
41:24 do them and it work
41:26 now as well i am
41:29 the most struggling part is when i know
41:32 what to do it happened to me these two
41:35 days
41:36 i know what to do i understand the
41:38 problem how do i do this
41:42 and it takes me a little bit longer
41:44 which is annoying
41:45 but i'm gonna get there
41:49 yeah so i understand that
41:52 i also see that in other data analysts
41:54 so who
41:55 are pretty good at understanding data
41:58 getting insights
41:59 from the data querying data do
42:02 data manipulation and calculating some
42:04 statistics doing exploratory data
42:06 analysis
42:07 but when it comes to coding it becomes
42:10 difficult
42:11 i i know you're still going through and
42:14 learning
42:14 uh that maybe you can
42:18 share some plans like how you how you
42:21 want to do this like how you want to
42:22 approach that
42:23 are you taking some courses to to to
42:27 improve that site
42:28 or
42:33 at the moment i stopped
42:36 completely kind of doing courses because
42:39 i found
42:40 out through experience that the best way
42:43 to learn something is to projects like
42:45 exactly like you said so
42:48 what is so and what usually
42:52 is the plan and has been for the past
42:55 one year and a half
42:56 um is find a competition
43:00 maybe i can't wait for an nlp
43:03 competition actually kegel can you
43:05 please give us an lp
43:06 i remember last year when i was like no
43:08 no i'm not doing nlp computer vision
43:10 they had a bunch of natural language
43:12 processing competitions
43:14 and now they don't have any and they
43:16 have a lot of computer vision
43:18 but what i usually do is
43:21 i focus on a subject or something that
43:24 sounds interesting
43:26 and then i think
43:29 uh 80 of the times i join a competition
43:33 without
43:34 having having no idea how to solve the
43:36 problem like
43:37 no clue whatsoever but then the plan
43:40 is to study very very well a few
43:44 notebooks
43:45 because and i say this a lot in my
43:47 notebooks
43:49 the baseline many times the baseline is
43:52 from
43:52 other people like it's not mine and
43:57 i feel like some times people are
44:00 ashamed that they aren't original
44:04 you can't invent the will and if you're
44:06 learning
44:08 you'll need to practice and you can
44:11 practice from these people that are
44:13 super knowledgeable so take their code
44:16 is fine twist it
44:19 and do something and then build upon it
44:23 and say okay this is the baseline from
44:25 this person
44:26 amazing thank you so much so give them
44:28 credits
44:29 but i usually and this is the plan i
44:32 take the code from somebody i
44:35 tried to explain it very very deeply
44:40 because knowledgeable people on kegel
44:42 although they explain a lot
44:44 they don't explain enough
44:47 and i need to get even deeper and to
44:50 start
44:50 coding myself and rename the variables
44:54 like in
44:55 i'm gonna understand them i'm gonna and
44:58 so on
44:59 and afterwards after i understood
45:02 everything
45:02 i can start trying to build upon it and
45:06 research and look at many other more
45:09 kaggle notebooks and so on
45:12 this is the plan and it has been working
45:14 pretty well
45:16 so basically you take a notebook that
45:18 somebody shared you try to decompose it
45:20 understand
45:20 what every line is doing you try to
45:22 rearrange the code you try to
45:24 change the variables until you
45:27 understand
45:27 every bit of uh every
45:30 line of code every every letter there in
45:33 the
45:34 in the code and then you start to
45:36 improve that code
45:37 start to try to upload to i don't know
45:40 try a new model maybe do something else
45:44 there okay
45:44 because we have a question from earth um
45:47 what do you think about learning with
45:49 imitating
45:51 if we try to imitate and then just copy
45:53 other notebooks
45:54 and understand do you think it's a good
45:57 way and i think
45:58 you just answered that because this is
46:00 what you are doing maybe not imitating
46:02 but
46:03 you know taking what others did and
46:05 trying to really decompose it into
46:08 simplest pieces and then understand each
46:11 piece
46:12 separately right and then kind of have
46:14 this big picture
46:16 and the best way is um
46:19 and i recommend this a lot but this
46:22 helps and i've
46:23 i did this even from the beginning from
46:26 there
46:32 udemy course don't
46:37 fork the notebooks because you already
46:40 have the code start a new notebook
46:44 and then have the other one that you are
46:47 imitating like you said
46:49 on the other uh on the left side or
46:52 somewhere else
46:52 to look at it and then take each line of
46:56 code one by one and write them yourself
46:59 because this is practice it's not just
47:02 reading
47:03 you are actually writing them and it's
47:05 gonna imprint in your memory and i
47:08 i if you're doing this
47:12 five times you're gonna know every
47:15 single letter
47:16 in that notebook and this way you can
47:18 start
47:19 printing you can start adding or
47:21 subtracting
47:22 without already having a bunch of code
47:25 and then
47:25 trying to add or remove or change
47:28 something because you want to really
47:31 understand as much that
47:33 you want to take it with you
47:37 to dirty your hands this is what i'm
47:39 trying to say
47:40 and how much time do you spend on this
47:42 decomposition because i imagine that's
47:44 uh not five minutes right it's a few
47:47 days
47:48 a few days so that's a few evenings
47:51 right or
47:52 yeah oh well to say oh we depends
47:56 but it can take from six
48:00 seven eight hours to i had one that
48:04 i had an error it took me a while to
48:08 debug
48:09 uh that took i think five
48:13 almost full days
48:14 [Music]
48:17 but i ended up with a pretty nice
48:19 notebook afterwards
48:21 yeah i remember with this approach i
48:24 also
48:25 try to follow something similar i'm not
48:28 active on kaggle anymore but i
48:30 was at some point i was trying to do
48:32 something similar
48:33 and then uh i was trying to decompose a
48:36 notebook
48:37 and then i thought okay now i understand
48:39 what's going on and then i rerun and my
48:41 model is two times worse than the
48:43 original one
48:44 right and then okay what did they change
48:46 when it stopped working like because the
48:48 code in my head it's the same
48:50 right it just happens
48:53 so and then i would spend i don't know
48:55 like many many hours trying to
48:57 understand what
48:58 uh what did they break and then what i
49:00 ended up doing is just
49:02 okay i'm throwing away this notebook i'm
49:04 starting from scratch
49:06 and then executing every cell and then
49:08 changing uh like a tiny bit and then
49:10 making sure the results stay the same
49:12 and that takes a lot of time it's like
49:15 uh i don't know
49:16 many days i can feel your opinion and i
49:19 can relate i know
49:21 but this is how you learn the best it's
49:23 like
49:26 if we go a bit uh back to your masters
49:30 that we have a question from
49:32 zach did you find your masters in data
49:35 science
49:37 like do you think it was helpful for
49:38 your career or
49:40 maybe not significantly
49:47 i'd never like this question just
49:49 because i feel
49:50 it's so you don't have to answer that
49:56 um everybody
49:59 has their uh have their own experience
50:03 um for me my master's
50:07 was a great time to
50:10 have also a lot of time to kegel
50:15 which i am very grateful
50:18 my masters put some sort
50:22 of arrangement because when you start
50:25 data science
50:26 you're like oh machine learning okay
50:28 deep learning
50:29 computer vision natural language xjpost
50:33 what pca what's everything
50:36 it's it's extremely wide and broadened
50:40 you don't know what to start with so my
50:42 master's really helped me
50:44 decompose that knowledge and start
50:48 indeed step by step and i remember when
50:51 i was doing
50:52 my statistics module i was just
50:56 finishing and understanding a little bit
50:59 of
50:59 how to process the data and then i went
51:02 into
51:02 understanding python and then i started
51:05 doing more and more
51:06 uh pre-processing of google and then the
51:10 data mining module was about machine
51:13 learning and i was doing more machine
51:15 learning on google so i was
51:16 pairing whatever i was learning however
51:19 unfortunately for me
51:21 and this was a bummer really
51:24 that was that because i was doing so
51:27 much keggle and because i was learning
51:28 so much on my own
51:31 i didn't quite
51:35 gets more from my masters
51:38 besides learning r i need to give them
51:42 that
51:44 but besides that unfortunately even deep
51:47 learning
51:48 which they were they were calling it
51:50 machine learning but
51:52 the deep learning part i learned from
51:55 youtube and it took me two months
51:58 on youtube and again printing everything
52:02 and so on
52:05 but unfortunately they didn't manage to
52:09 give me
52:11 more yeah okay
52:15 let's say so i i followed the similar
52:18 path to you even though my background
52:20 was
52:20 in software engineering i also decided
52:22 to do a masters
52:24 but eventually what helped was online
52:27 courses
52:28 and kaggle to actually to really
52:30 understand uh
52:32 machine learning but yeah probably
52:35 masters was still useful like you said
52:37 uh they uh explained
52:41 where each piece of the puzzle belongs
52:43 uh so
52:44 probably yes but i would repeat it
52:48 if i'd be again in the same place i
52:50 would repeat it
52:51 100 percent okay
52:55 yeah but what i was what i'm trying to
52:58 ask
52:58 is often people who go from analytics to
53:02 data science
53:05 they don't always it's not always
53:07 possible for them to go and do a masters
53:09 to spend one year
53:11 doing that was it one year for you
53:13 because i think in the uk it's one year
53:15 right
53:16 in europe in continental europe or at
53:18 least in germany and i think in most of
53:20 the other countries is two years
53:21 so not everyone has this luxury to stop
53:25 working
53:25 for two two years and
53:29 you know completely immersed into that
53:31 maybe you have some recommendations for
53:33 them like
53:34 what would you do if you couldn't do
53:36 masters and say you had a full-time job
53:38 as a data analyst like would it also be
53:43 follow the same path like do this course
53:45 on udemy do courses on kaggle
53:48 then try to you know get into notebooks
53:52 and
53:53 all these things we discussed or would
53:54 you suggest something else on top of
53:56 that
53:57 yes
53:58 [Laughter]
54:00 so exactly what you said
54:04 i wouldn't suggest anything else just
54:05 because i don't have
54:08 i am afraid to
54:12 suggest some things that i didn't do
54:15 just because it wouldn't be appropriate
54:18 however
54:22 if you start as i said from scratch
54:27 if you do that course or if not
54:30 you can safely go on to kaggle and start
54:33 from there you don't really need that
54:36 course you can start from kaggle
54:39 straight up and for six months
54:43 maybe to one year every evening
54:47 three days a week let's say you emerge
54:51 a few hours into the data science part
54:54 at the end of that year you'll have
54:57 knowledge you'll have to show something
55:01 which is super important you'll have
55:04 community
55:05 if you are engaging with people
55:08 on linkedin on twitter or i don't know
55:11 anywhere
55:12 you can you can find on youtube
55:15 also ken kenji who's one of the
55:17 ambassadors
55:19 for zebra hp and nvidia he's awesome by
55:21 the way and he's doing
55:23 uh the 66 days data science challenge
55:27 you can go and follow him you don't need
55:30 a teacher
55:31 to to tell you what to do and there are
55:34 lots of resources out there
55:37 um you can
55:40 pivot from data analysis to data science
55:44 in maximum one year if you're like
55:47 relaxing
55:48 and taking your time and enjoying the
55:50 process maybe one year
55:52 yeah and then the this aspect of uh
55:56 uh going through uh coding exercise exa
55:59 like coding uh
56:02 interviews that's probably uh uh
56:05 stressful part but you have to go
56:06 through this right so there is
56:08 no way around that unfortunately no or
56:12 maybe become a kaggle grandmaster
56:15 it doesn't help for me it doesn't help
56:20 they still want to to stress you
56:24 and put you under pressure you need to
56:27 find also right people
56:28 so i guess the this is where the
56:30 networking aspect comes
56:32 in into play that and you have that
56:35 aspect
56:36 networking on cargo and probably other
56:38 social platforms like
56:39 linkedin and twitter like you get you
56:42 connect to people
56:43 and then probably it helps for them to
56:45 see you
56:46 to see what you do and then they already
56:49 know you they already know what
56:51 what you're capable of because they can
56:53 see your notebooks and that probably
56:54 helps with
56:56 to at least start the conversation right
56:58 yeah exactly
57:00 okay and one thing we didn't talk about
57:03 um
57:03 so we talked at your kaggle grandmaster
57:06 in notebooks
57:06 and i think we also maybe you can spend
57:08 a couple of minutes talking about that
57:11 because for many people when they hear
57:13 kaggle what they imagine is
57:15 i think you mentioned that once like a
57:17 spice ship of models
57:19 uh and yeah like all these
57:23 models put on top of models put on top
57:25 of models
57:27 buttons yes but
57:30 kaggle is not just about that right and
57:34 you don't need to focus just on
57:36 competitions to get uh
57:38 to learn a lot from kakal and uh
57:41 so what you did you followed the the
57:43 notebook
57:44 kind of tier i don't know if you you can
57:46 call that but
57:48 that is the notebook path and uh
57:51 yeah so what i wanted to say is uh
57:54 like you don't have to focus on
57:55 competitions because it's uh
57:58 it's difficult right it's difficult to
58:00 get this gold model in competition
58:02 it's uh you need to spend so much time
58:05 there
58:05 like but you don't have to do this right
58:08 to um you know to learn things
58:14 besides this discussion which i think
58:18 they started putting medals and
58:20 discussions just because there were
58:21 indeed so
58:22 some people that were very helpful in
58:25 their comments
58:26 and i and completely understand that
58:28 tear
58:29 you can learn from any of the three
58:34 tiers as you i think they are called
58:37 yeah
58:38 competitions of course just because you
58:39 are training you are
58:41 you're looking at other people and the
58:43 leaderboard and
58:44 they are absolutely fruitful and amazing
58:48 uh notebooks again because i
58:53 not all my notebooks are on competitions
58:57 but you can do notebooks on competitions
59:00 to again
59:01 understand the process better
59:04 you can also do them on different topics
59:07 that you like
59:08 or something maybe you're passionate
59:10 like i was about sentiment analysis
59:12 do a number on sentiment analysis see
59:14 how you can gather the data and so on
59:16 and talking about the data the data sets
59:19 i feel like
59:20 they are a little bit under appreciated
59:23 but they are super important because if
59:26 you
59:27 uh because i told you about gabby so
59:30 gabby
59:31 he just became a dataset's grandmaster
59:35 he is three times grandmaster now on
59:38 carol
59:39 and he scrapes the
59:42 information and he updates it
59:45 which is an effort on its own but the
59:48 idea
59:49 of scraping the data and making little
59:51 scripts
59:52 or big scripts i don't know what he's
59:54 doing or how
59:56 how advanced he is but just
59:59 gathering the data and putting it in a
1:00:02 clean format
1:00:04 and it's a skill on its own and
1:00:08 data sets i feel like they are the
1:00:11 hardest to gain a medal in
1:00:15 just because it's very hard to put
1:00:18 out a data that's super super important
1:00:22 and very valuable to the people so data
1:00:25 sets again it's
1:00:27 super easy especially if you want to do
1:00:29 a be a data engineer
1:00:31 in my opinion i know a guy who wants to
1:00:34 be
1:00:34 that and he wants to start keggle only
1:00:38 for data sets
1:00:39 because he's he likes to take clutter
1:00:43 and make it neat i guess he's a clutter
1:00:46 like a clean freak or whatever yeah
1:00:50 so you can learn in any tier
1:00:53 thank you anything else we didn't cover
1:00:56 what you wanted to share
1:00:58 i don't think so any last tips yeah
1:01:04 use social media okay each one twitter
1:01:08 linkedin or
1:01:09 doesn't matter both heavily yeah
1:01:13 how how should we use this like let's
1:01:15 say somebody's looking for a job what
1:01:17 should they do
1:01:19 um try to build and this takes time
1:01:25 this this takes time a lot of time
1:01:30 but try to
1:01:34 make your social media especially
1:01:37 linkedin
1:01:38 and twitter as focused on data science
1:01:41 as possible
1:01:42 and try to showcase their your work
1:01:47 share data science things related
1:01:52 and everything that gathers a community
1:01:55 and builds a community
1:01:56 because there comes the opportunities as
1:02:00 well
1:02:00 and there comes the
1:02:05 more knowledge because you meet more
1:02:08 people and
1:02:10 having a community is extremely
1:02:12 important this may be more important
1:02:14 than
1:02:15 being very good at something if you you
1:02:18 need to have the community in my opinion
1:02:21 and it is super important and people
1:02:22 don't talk enough about this
1:02:24 so use social media to showcase your
1:02:27 work
1:02:27 to show that you're passionate be kind
1:02:31 be
1:02:31 gentle thank to people
1:02:34 that helped you super important
1:02:37 and try to add
1:02:40 more to this community try to be a
1:02:43 bonus not something that i don't know
1:02:46 uses all that information
1:02:48 but it's just trying to keep it to its
1:02:50 own or something like that
1:02:52 so give and share and
1:02:55 the world will be a better place
1:03:00 yeah that's a great way to finish
1:03:02 today's uh
1:03:03 conversation i think so i
1:03:06 so people where can people find you so
1:03:09 linkedin twitter cargo
1:03:12 i'll share all the links after the chat
1:03:15 i'll put them in description
1:03:17 yeah um yeah i guess uh
1:03:21 that's all uh for today
1:03:24 yeah thanks a lot for joining us today
1:03:26 and sharing all this experience and also
1:03:28 being open about all the struggles
1:03:30 you've had and i think many people
1:03:32 who are going through a similar
1:03:33 transition now will appreciate that uh
1:03:35 especially
1:03:36 uh this interview part uh because i know
1:03:38 it's
1:03:39 not easy so thanks a lot and uh
1:03:43 yeah and uh thanks everyone who is
1:03:45 listening
1:03:46 and uh yeah drop by next week when we
1:03:48 have events
1:03:50 yeah and subscribe yeah of course
1:03:53 i always wanted to say that on youtube
1:03:58 so subscribe and press the like button
1:04:01 yeah exactly
1:04:02 [Laughter]
1:04:04 likes comments subscribe
1:04:08 it was nice talking to you so
1:04:11 have a great weekend