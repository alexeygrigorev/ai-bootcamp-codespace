0:00 hi everyone Welcome to our event this
0:02 event is brought to you by data do club
0:04 which is a community of people who love
0:06 data we have weekly events and today is
0:09 one of such events if you want to find
0:10 out more about the events we have there
0:12 is a link in the description right now
0:15 there is only this event that we have
0:17 right now but we will be adding more we
0:19 will have quite a few podcast interviews
0:22 scheduled so be sure to check this page
0:25 and of course we will also announce
0:27 these events like in social media and
0:31 newsletter anyways do not forget to also
0:34 subscribe to our YouTube channel if you
0:35 haven't this way you'll get notified
0:38 about future streams like the one we
0:39 have today and we have an amazing slack
0:42 Community where you can hang out with
0:43 other
0:45 datings during today's interview you can
0:47 ask any question you want there is a
0:50 pined link in the live chat click on
0:52 that link ask your questions and we will
0:54 be covering these questions during the
0:56 interview and this is the intro
1:00 and now I will the document that you
1:06 prepared and if you're ready we can
1:09 start okay so this is the time when
1:12 actually okay great so this week we'll
1:15 talk about the practical application of
1:17 generative AI in industry and we have a
1:20 special guest today Maria Maria is a
1:22 principal key expert in artificial
1:24 intelligence at Simmons she has over 15
1:27 years of experience in Ai and a cat that
1:30 we just so uh Maria is known for
1:33 transforming Advanced AI Research into
1:35 practical impactful tools and your work
1:38 focuses on ethical scalable solutions
1:40 that enhance decision making and
1:42 streamline processes and the cat is
1:44 really cute for those who are watching
1:46 this only in audio maybe check out the
1:49 video because there was a cat anyways
1:52 welcome to uh uh Welcome to our
1:58 event and um yeah the questions for
2:01 today interviews interview are prepared
2:03 by Johanna Bayer thanks Johanna as
2:05 always for your help and before we go
2:07 into our main topic let's start with
2:10 your background can you tell us about
2:11 your career Journey so far yeah thank
2:14 you for your
2:15 introduction so actually I started as a
2:20 trained linguist so I studied
2:22 Linguistics many many years ago I
2:24 started over 20 years ago with a
2:27 traditional Linguistics and translation
2:29 studies
2:30 uh and then I realized that I actually
2:33 like programming and computer science
2:36 but I already had a degree in
2:38 linguistics so what I did I applied for
2:41 the scholarship and got a scholarship to
2:46 do computational Linguistics Master
2:48 studies in
2:50 zarand afterwards I was a researcher in
2:53 Frankfurt um then I was also a
2:55 researcher in damad in the ukp group
2:59 over in gich for two years and then I
3:02 decided to switch to Industry and
3:06 started working in BMW in a MLP group as
3:10 data scientist uh then um I moved to
3:14 Simmons where I'm currently
3:16 working and if I'm at this point I
3:20 remember that my legal department makes
3:22 me say one thing I'm a seen employee but
3:26 all my op all the opinions that I'll
3:28 Express in this point are Solly my own
3:32 so and yeah and since then I've been
3:35 working in Simon as um an expert in AI
3:39 so first a senior now as a principal key
3:42 expert in artificial intelligence and
3:45 that's where I am at
3:47 now and um so I also work or used to
3:51 work uh in
3:53 industry and usually we have positions
3:57 like I don't know Junior data scientist
3:59 senior data science and so
4:01 on so what does key expert mean like
4:06 what do you do at your job this this is
4:11 a great question because uh nowadays AI
4:16 expert um started getting a bit of a
4:19 negative connotation because really why
4:22 recently I have a feeling that nowadays
4:24 there are so many eye experts
4:27 like exactly like I can go on the street
4:30 close my eyes throw a stone and I
4:32 probably hit an AI expert so this is
4:35 probably throw stones exactly don't
4:40 don't hurt anyi experts but in theory uh
4:45 what an expert does as a we say like
4:48 managers manage people uh experts manage
4:52 technology so uh the task of an AI
4:55 expert is to be up to date with the
4:57 state-ofthe-art to
5:00 understand technology also I believe
5:01 that an expert should should have a
5:04 critical view at the technology not give
5:07 into the hype to understand the
5:11 limitations and then be able to advise
5:16 uh management and the company which
5:18 technology they should take uh which
5:20 they shouldn't what's to expect from
5:22 this technology and what risks can be
5:24 connected to
5:27 that and why do you think there are many
5:30 a so-called AI experts these
5:32 days I assume because we have ch GPT and
5:36 it became so popular that everyone knows
5:39 now that AI is a
5:41 thing right I think it's from side it
5:45 got very accessible so before to be an
5:49 AI expert you at least need to know how
5:52 to code so there's at least some kind of
5:54 a mode now you need to be able to talk
5:58 or to to spell and then you can become a
6:02 prompt engineer and prompt engineer is
6:06 already for many people halfway the AI
6:08 expert don't necessarily have to spell
6:11 words correctly because AI will no no
6:14 I'm not saying gtic I I just like that
6:17 you somehow use a keyboard yeah and then
6:20 you prompt something then you create a
6:22 prompt library and voila you can call
6:26 yourself a fot leader and AI expert but
6:31 of course that's uh going to be not for
6:34 a long time like this there a lot of
6:36 people will um filter out the demand for
6:40 these drops but currently yes and the
6:44 other point is of course currently a lot
6:46 of people lots of Industry want to do
6:49 something with AI it's almost like a the
6:53 sign that you're an Innovative mod
6:55 company if you necessarily build an AI
6:59 product and it doesn't matter if AI is
7:01 actually applicable there but as I read
7:05 in one of the Articles if the only thing
7:07 that you have is a generative AI Hammer
7:10 everything looks like an generative AI
7:12 nail so everyone's trying to build
7:15 something to show to others to investors
7:18 to management that they have this and
7:20 therefore there is a demand for AI
7:22 experts and the more of them growing
7:25 like mushrooms nowadays MH around yeah I
7:29 just came back from a forest and because
7:33 the weather is uh it's very humid like
7:36 there's uh it's like it's not raining
7:39 all the time but like when you go to the
7:41 forest there are so many mushrooms so
7:44 I'm a very uh enthusiastic mushroom
7:48 picker I have around 10 kilograms of
7:51 Frozen
7:53 mushrooms in my fridge
7:56 so yeah yes this year was very good like
7:59 not for AI experts but also for
8:01 mushrooms yeah right exactly this is
8:03 what I wanted to say uh and yeah because
8:06 of this hype but uh maybe it's also a
8:08 good thing CU like some people who do
8:10 not necessarily have the programming
8:11 background now can
8:14 be how to say can make impact so we will
8:17 see of course in a couple of years if
8:19 this will still be in demand but while
8:21 there is demand um perhaps it's not such
8:24 a bad thing right I I think that's a
8:25 normal evolution of any area that gets
8:30 people who are successful will stay no
8:32 matter what their technical background
8:35 people who are not successful will go
8:37 away uh we have this um amaras law like
8:41 gner hype cycle that we know that where
8:44 you have ai at the top everyone has very
8:46 high expectations but then it steadily
8:49 goes down and it becomes part of our
8:52 daily routine uh and I think the same
8:55 here but I actually happy lots of people
8:58 trying on out learning about it and
9:03 there is nothing wrong even with
9:05 thinking you are an AI expert calling
9:08 yourself an a expert may maybe you are
9:10 like it's a or will be so absolutely
9:14 like no no gatekeeping here for who
9:17 should call themselves an expert and so
9:20 how do you you said you help a lot of
9:22 people who try to get into your AI and
9:24 how do you do this like through courses
9:27 or well currently I mostly work uh with
9:30 this and cimons so uh for example one um
9:35 of the things I do a lot uh is uh
9:38 different trainings I do also a lot of
9:41 um key notes and uh another thing that I
9:47 did um is uh you probably know a gandal
9:51 game uh gandal where yes you should the
9:55 wizard from lot of drinks right yes and
9:59 uh uh there's a game it's um kind of
10:02 organized by a startup that works on the
10:05 safety of chatbot and the large language
10:07 models so what they did they asked uh
10:11 people to hack into their bot so for
10:14 example they prohibit the model say a
10:16 certain word and people have to prompt
10:18 it so the model prints out the the
10:21 prohibit word so there is a similar
10:24 challenge I've done for S and we had a
10:28 1500 people participating in this and
10:31 you really it was really fascinating to
10:34 watch after the logs of what people are
10:36 typing in because even at 3:00 a.m.
10:39 there were people trying to hack this
10:40 bot like to show that they're smarter
10:42 than this super what does it mean to
10:43 hack a bot like for example if I use CH
10:47 GPT so the the thing like I used to
10:50 entertain Myself by going to chpt
10:54 copying an artic taking an article about
10:56 astronomy and asking chpt to rephrase
11:00 this uh article about astronomy as if
11:03 Donald Trump trump was saying it right I
11:05 it was super hilarious right super
11:07 entertaining until they stopped doing
11:10 that until they recognized that hey
11:12 Donald Trump is a person we don't want
11:14 to do that so we They just added some
11:18 filters um saying hey we do not want to
11:22 entertain you this way anymore right so
11:26 does it mean that
11:29 I still can hack the filters of chat GPD
11:33 to make it do what I want and this would
11:35 be like this sort of hacking here
11:37 talking about yes and even more uh
11:40 dangerous it can be when you publish a
11:43 both as a company for the external use
11:46 you probably have heard about Air Canada
11:49 that uh a b created an non-existing
11:52 discount and they had to give the
11:54 discount I think there was a bot of a
11:57 car company that sold the car for1 and
12:00 they had to sell it uh for this and this
12:04 is exactly what you want to prevent you
12:06 build the bo you don't want your Bo to
12:08 hallucinate some services that you don't
12:10 have because it might be legally
12:12 obliging for you to provide them or give
12:14 the discounts and so on but in theory
12:17 you can always find a way to almost
12:21 always to prompt this model that it
12:23 tells you exactly what you want so you
12:26 can force it to give you a non-existing
12:27 discount sell you a car or the other
12:31 thing what one of the challenges that we
12:32 had um we hid in the database like
12:36 confidential information that was the
12:38 name of my kusco and people had to make
12:43 the boat tell the confidential
12:45 information and the bo was prohibited to
12:46 say it and uh that was not even a
12:50 challenge to be honest like uh I mean it
12:52 was a challenge but around 30 people
12:54 managed to make the board sh tell them
12:58 the name of the cat so this is something
13:00 that um a lot of people or a lot of
13:03 companies might not think about it that
13:05 everything that goes into the board can
13:07 potentially come out of with the right
13:10 prompting can you tell more about this
13:12 so how did exactly how did they
13:16 exactly hide the name of the C and how
13:18 it was
13:19 retrieved oh so so exactly so the name
13:22 was uh basically hidden in the uh
13:26 knowledge database that it was some sort
13:28 of R application right so there was a
13:31 yeah exactly it was rag uhhuh okay yeah
13:34 and uh the protections were so first of
13:37 all system prompt do not tell any cat's
13:40 name so then there was a a filtering
13:44 langage model another one that was
13:46 checking if in the output there's a
13:48 cat's name and how the people hacked
13:52 there were still many ways so for
13:54 example some people chin some people use
13:56 Chinese language because Chinese
13:58 language um has um heroglyph and
14:01 heroglyph they have higher um
14:02 information density so they tend to
14:05 override the uh the system prompt very
14:09 well uh the other ones uh wrote some
14:13 kind of emoy request uh some wrote
14:17 python code that would like a function
14:20 that would retrieve the but in theory
14:23 what you need to do is to give lots of
14:25 pointless instructions and because all
14:28 the those language models they have an
14:30 attention mechanism behind so they pay
14:33 attention to something and what you want
14:34 to do is that it started painting
14:37 attention to something completely random
14:38 and irrelevant and forget your important
14:40 instruction you gave before and and then
14:43 it will tell you everything and I don't
14:46 encourage it by any means but honestly
14:49 there are lots of boats from Airlines
14:51 and you can try to get discounts they
14:56 they give very eagly discounts not that
14:59 I tried
15:01 but okay you you you can see it for
15:03 yourself yeah just make it write a poem
15:07 or like uh write a code just trct it
15:09 with something and it will tell you what
15:11 you want so the idea is we have a rack
15:14 application and in the r application we
15:16 typically have a prompt like here is the
15:17 context and based on the context answer
15:19 the following questions plus we have
15:21 some instructions like if there is any
15:23 confidential information do not like
15:26 edit this do not expose it to the user
15:28 right and then there is
15:30 another step in
15:32 this process uh which takes the out with
15:36 a FR and also says Hey like if there's
15:39 any extra information there remove it
15:43 like any confidential information right
15:46 so two steps people needed to just using
15:50 the interface of a
15:52 bot to hack it to give it uh to um to
15:56 force it to give the information right
15:58 and they did this one of the examples
16:00 you mentioned was to just put so much
16:03 information in the prompt not in the
16:06 prompt in the in the in the window in
16:08 the
16:09 request it just forgets like the
16:11 original instructions of not giving away
16:13 the name of the C right yeah ex exactly
16:17 you just what what you want that it gets
16:19 distracted from what you originally told
16:22 and focuses on your instruction and it's
16:25 um I mean there are many ways to protect
16:28 um uh the llm or like the board for
16:31 example you can check if there is
16:33 something in the query of the user that
16:36 uh tries to extract something it
16:38 shouldn't then you have it in the system
16:40 prom then you can check the output then
16:43 you can also use nonm classifiers that
16:47 check if there is any so so there you
16:50 might build many levels of um safety
16:54 before you can for sure say that this
16:57 this bot is safe for you
16:59 mhm yeah this is an interesting thing of
17:02 adding an non llm classifier because you
17:04 cannot really trick it
17:05 right yeah exactly exactly it it can be
17:09 wrong but you cannot trick it it's more
17:12 difficult to trick it I would say it
17:14 this way because like different level
17:15 yeah yeah it's a simpler model so you
17:18 cannot like
17:19 [Music]
17:20 really uh how to say trick cheat it
17:23 right convince it to to do something Ah
17:25 that's really interesting so you said
17:27 one of the things you do one of your um
17:32 responsibilities as a principal key
17:34 expert in artificial intelligence is
17:38 advising Management on which technology
17:41 to use and what kind of risks it can
17:43 bring right so one of the risks we
17:45 talked about so um like this uh if you
17:49 use salm as a chatboard it
17:53 canate come up or people can hack it
17:55 right so then uh the company will have
17:58 to sell a plane ticket for $1 right yeah
18:02 I think this is not even the main
18:04 problem because what is like a plane
18:06 ticket for uh it's it's not the problem
18:09 the problem here that it's the
18:10 reputational damage that this uh B will
18:13 cause to your company because it will
18:16 show that you basically put out a
18:19 product that wasn't secure and safe and
18:22 this is what you mostly want to prevent
18:24 when you release such Bots another thing
18:26 with these Bots is of course the
18:29 question of hallucination so imagine if
18:32 you uh have a friend who lies to you
18:36 once uh will you ever want to talk to
18:39 this friend again will you ever trust
18:41 this friend again probably not right you
18:44 will be like well he lied to me so why
18:45 should I talk to him and um it has been
18:50 uh shown many times that there is no way
18:52 to get rid of hallucinations so there
18:56 it's it's a machine learning um approach
18:58 it's a statistical approach it will
19:00 always be something will always be wrong
19:03 there so the here's the problem with the
19:07 user acceptance people uh perceive those
19:09 Bots as a a friend as an advisor as some
19:13 kind of
19:15 anthropomorphic entity so people who do
19:17 not necessarily have experience prior
19:19 experience with machine learning and
19:20 things like that because for
19:23 example yeah we talked about mushroom
19:25 picking right and sometimes um to my son
19:28 and I when we were in the forest we
19:30 would ask chbt about mushrooms and then
19:34 it would invent mushrooms and it's kind
19:35 of fun right so I know that it has this
19:38 problem and then we would Google some of
19:40 the mushrooms and like Google doesn't
19:42 know about them and to me it's clear
19:43 that it just made this mushrooms up but
19:47 for people who do not necessarily have
19:49 this prior background like this prior
19:52 experience they would like okay yeah it
19:56 came up with a mushroom that does not
19:57 exist like how can I trust everything
19:59 else it says right yes and actually this
20:02 is fair this is even a more dangerous
20:05 example because I do try this is CH BT
20:08 and once I put a death cap uh if you
20:11 don't know what a death cap is it's a
20:13 mushroom that can kill up to seven
20:16 people if you eat it it's a it's 95% of
20:20 the poisoning with a mushroom they are
20:22 caused by the death cap and it's a
20:24 mushroom that um if you start getting
20:26 symptoms basically there is no way to
20:30 well survive unless you get the LI
20:31 transfer so this this is a very deadly
20:34 mushroom and we have in Germany yeah I
20:36 think we see them quite often yeah
20:38 plenty and they look very similar to
20:40 Champions like that's why people get
20:43 poisoning with them because they think
20:44 it's a champion and I did try a couple
20:47 of times the CH and indeed this thing
20:49 gives me a recipe how to cook this how
20:52 to the champion and so on and uh well I
20:57 believe that people need to be be
20:58 educated by about AI that you shouldn't
21:01 of course trust when this thing tells
21:03 you that the death cup is champing on
21:04 that you immediately take a bite from it
21:07 but uh yeah this this is uh something
21:11 that um can also be a problem and
21:14 certain applications of AI you might
21:17 want to consider that you probably
21:19 shouldn't have them in general for the
21:23 public use particular there are certain
21:25 demographics uh probably to whom it will
21:28 be very difficult to explain that you
21:30 shouldn't trust this um we can do all
21:32 education but there are certain people
21:34 in certain age who might just like
21:36 blindly trust it and um act on it so
21:41 this is the problem and another problem
21:43 the risk for the company when you build
21:46 those chatbot you invest a lot of money
21:48 invest a lot of resources and then users
21:51 just don't want to adopt it because uh
21:55 every second answer is uh either
21:57 hallucinated or is too long or is not on
22:01 point and so on and this is something
22:03 that I think we frequently hear about
22:06 the chat boards you know like nowadays
22:08 everyone wants to build a chatboard but
22:11 nobody wants to use a chatboard so this
22:14 is something we could um at least I have
22:18 never heard of a person who calls
22:21 WaterOne has the chatbot answering to
22:24 them and says like yes I directly got to
22:27 a chatbot
22:28 so yeah we still do not have this Joy of
22:32 using the chatbots and I think this is
22:35 something that one needs to consider
22:37 when you build the use case with that
22:39 what happens if the chatbot lies will
22:41 users still want to use it uh will it
22:44 make them anoid uh can it create serious
22:47 damage like can they eat a death cap
22:49 because of this and um uh is there a
22:53 better way to adopt this technology than
22:55 build a chat so it's two risks first
22:58 reputation damage if a companyes a
23:00 product that is not properly is not
23:03 secure enough then it's reputational
23:05 damage and then it's also not clear if
23:09 the return on investment will be
23:11 positive maybe users will not want to
23:13 use it is there anything else like what
23:16 like other common risk
23:18 factors I would say this might be the
23:22 major one was regarding the chart
23:25 because um as I said this is fairly
23:27 expensive to build a good
23:30 one
23:32 um so that's that that's probably what
23:35 what what I usually uh focus in of
23:38 course there's like for the developer
23:40 you can
23:42 also risk to uh stacking in an um
23:47 endless loop of prompt engineering
23:49 trying to figure out the perect prompt
23:52 that will have the list of the uh of the
23:56 errors and so on so um
24:00 so yeah I would probably first yeah ask
24:05 so it's more like so the the third one
24:06 was development time so it might be
24:09 might get expensive especially if
24:10 developers get really into like nitty
24:13 grees uh like do this prompt engineering
24:16 which is also kind of dangerous
24:19 cuz uh open AI releases a new version of
24:23 the model and then like all your prompts
24:25 kind of can exactly that's that's the
24:28 exact risk too because you prepare all
24:32 those nice prompts and then they might
24:34 just not uh work the same way as you did
24:38 in the model plus we also have seen that
24:41 even the same model they non
24:44 deterministic which means that the same
24:47 question always get the different
24:50 answer okay knowing this
24:53 risks um okay maybe like with prompt
24:55 engineering this is something we can
24:57 also talk about but like
24:59 when it comes to hallucination yes it's
25:00 a non
25:01 problem and what do we do with this like
25:04 apart of apart from telling people hey
25:07 like beat the suggestions with caution
25:10 like what else can we do in Char GPT it
25:12 says what does it say like
25:16 AI I'm an AI I something like this don't
25:19 can make mistakes check important this
25:22 is what they say but this is not
25:23 something you will put into uh let's say
25:26 I right to vone or my bank and then
25:30 actually we do I I I would think we
25:32 should do it
25:33 everywhere like I came there with a
25:36 concrete problem and
25:38 then the answer I get yeah you can do
25:41 this this and that and then there is
25:43 like disclaimer our bot sometimes can
25:45 make mistakes check important
25:47 information
25:49 like exactly and the this is exactly
25:52 where you have the user story that
25:54 doesn't fit exactly uh the integration
25:58 of the the way you do so an alternative
26:01 for this for example if you want to make
26:03 sure that your um user always get the
26:06 right answer and they don't get the
26:08 annoy for example you can use this in a
26:09 system for uh human support so instead
26:13 of having a human constantly generating
26:15 the answer
26:18 or writing out the answer uh there can
26:21 be a human who looks through the answer
26:23 if it's good it's sent further to the
26:26 human uh for example through a C or
26:28 through a ticket uh if it's not then the
26:31 human corrects it and it has been shown
26:34 that this is actually a very good
26:35 application because it does save a lot
26:37 of time and I think it brings us to the
26:39 point where many people uh misunderstand
26:42 the AI as a substitution of humans of
26:46 human labor instead as a tool and
26:49 assistant uh for the current jobs
26:53 so and this is a mistake of many chat
26:56 Bots they assume they can replace the uh
26:58 support instead of being an assistant
27:01 for the people who work in the support
27:03 so yeah the better way would probably be
27:06 to see how you can make life of your
27:08 support simpler with it instead of
27:10 trying to eliminate them as as a
27:13 whole yeah I think this is something so
27:16 I worked in my previous company I worked
27:18 in
27:19 moderation and the company was doing it
27:22 was a Online Marketplace so you want to
27:24 sell something like I don't know this
27:26 computer mouse and then um you put a
27:30 description you put like a few pictures
27:33 and then the the think the item does not
27:36 immediately go live there are a few
27:38 checks right whether um like it's not
27:42 fraud and so on right for example for
27:44 computer mouse it's okay but like what
27:45 if it's a phone and this phone is
27:48 suspiciously cheap right so it could be
27:51 not a real phone and then you order this
27:53 phone and instead of getting a phone you
27:54 get a potato right then like it's a
27:57 problem um so we had some
27:59 models um that would check if this
28:02 transaction or this uh item this listing
28:06 is fraudulent or not and the worry from
28:09 people from moderators was that we are
28:11 building this system to actually replace
28:13 them right because uh it was like long
28:17 before all the LMS um but yeah so what
28:21 we had to explain is like hey we don't
28:23 want to actually fire any of you we want
28:27 won't want to replace you we actually
28:29 want to help you
28:32 like um I remember this example one of
28:35 our product managers used is um
28:39 autopilot right so when a pilot is
28:41 flying a plane they do not necessarily
28:43 need to kind of steer the the plane all
28:46 the way right most of the work is done
28:48 by the autopilot they're just observing
28:51 and if something happens they interfere
28:53 so that was the metaphor we used for the
28:55 bators and they liked it right so I
28:59 think something like that the work like
29:01 that needs to happen with people too
29:02 right because like they worry that hey
29:04 now ai will replace
29:07 like everyone and yeah we need to tell
29:11 them it's not a substitution it's more
29:13 like assistance
29:16 right exactly and uh we have seen this
29:19 over the years for decades right like
29:22 machine translation in 50s was supposed
29:25 to be completely eliminate translators
29:28 and uh look where we at now and machine
29:31 translation is also a very good example
29:34 uh of where we still see AI being an
29:37 assistant because everyone now um kind
29:40 of think that trans like human
29:43 translators they are in danger let's
29:44 look how good chpt translates the yeah
29:48 it's awesome text okay so why
29:50 translators are not in danger if
29:53 change because uh um a lot of this
29:56 translation for example when you do
29:57 technical translation there are two
29:59 things that I needed for example so
30:01 first of all uh you need that the text
30:04 is actually 100% correct then you need
30:08 to make sure that it adheres to the
30:10 company standards for example it uses
30:12 the terminology that company has it
30:15 doesn't like rename you know some
30:16 buttons like it doesn't translate St
30:18 button into like so you need an editor
30:20 not a translator you need you need you
30:22 need an editor you need who like can
30:25 validate the sanity of this and um uh
30:30 what happens now if we look at the
30:32 statistics of the translators uh
30:34 translators make more translation uh
30:36 translation percentage gets cheaper but
30:39 the amount of translators involved in
30:42 the uh job they are not going down it
30:45 just simply you can create more
30:47 translate and another tendency there is
30:51 uh translators that are bad like
30:53 non-rain translators not technical
30:55 translation like basically poor translat
30:58 can be probably
31:00 eliminated so you can produce bad
31:03 translation
31:04 automatically but uh translation that
31:07 needs a technical XT understanding of
31:09 the vocabularies and the company
31:13 specifics you need a human translator
31:15 there to review it uh again to make sure
31:18 that you do not distribute any risks
31:20 because you know like all this manuals
31:22 like car manuals product manuals like
31:25 you don't want the person like sticking
31:26 two fingers in the socket
31:28 because uh you mistranslated something
31:32 automatically so uh even this ones they
31:35 don't seem to be as endangered as we
31:38 expect based on the recent
31:41 statistics okay so when I said you need
31:43 an editor what I did not think about was
31:46 that like actually the person needs to
31:48 understand the source language too not
31:50 just the
31:51 target you need to make sure that the
31:53 translation is
31:55 actually correct right yeah so so the
31:59 translation uh uh human translation just
32:02 becomes uh different from how it used to
32:05 be it heavily relies on automatic tools
32:09 it gets more
32:10 productive uh but it's uh not going away
32:15 as a as as a job except you're B
32:18 translator then yeah you can be replace
32:20 BP and by the way I stopped using Google
32:23 translate so now I just use chpt for
32:26 translation especially
32:29 yeah you can give it instructions so in
32:32 Google Translate I cannot tell it like
32:35 hey like use
32:37 the informal plural here instead of like
32:40 formal one and then translate easier so
32:45 yeah like it's a super handy thing and
32:48 um yeah you actually started your career
32:52 with uh computational Linguistics and
32:55 also with machine translation right
32:58 yeah um so I was working a lot on low
33:02 resource languages so that's something
33:05 that also probably currently is somewhat
33:09 of a challenge for large language models
33:12 because whenever we start a use case uh
33:15 we always start I always say do you have
33:18 data in English why because it's our
33:20 high resource language it's the language
33:23 that the model mostly trained on they
33:25 anate they this what I used to work on
33:28 was low resour languages and one worse
33:30 that's historical languages so for
33:32 example Gothic middle low German Middle
33:35 High German Middle English um you know
33:39 like um Middle English in the sense of a
33:43 choser that sounds very very different
33:46 from Modern English uh maybe even like a
33:50 bit more like German I
33:53 mean in orinal no I think Shakespeare in
33:55 Reginal is still still resembles it's
33:58 it's new English like Middle English I
33:59 can quote a bit of Cher so it will be
34:02 something
34:06 like from the team I first began to read
34:11 he truth
34:15 and there was a night there was and
34:18 that's worthy man you know so this is
34:21 how different they so it's like for me
34:25 so I had to um
34:28 things in my mind so first I thought
34:30 it's like from The Lord of drinks like
34:32 language from El or whatever and then
34:36 the the second was like um maybe it's
34:38 something
34:39 Scandinavian but English is kind of
34:41 Scandinavian right I mean it's it comes
34:43 from like the same family as
34:46 Scandinavian languages German language
34:48 right it's a v Germanic family languages
34:53 Scandinavian the north
34:55 Germanic uh languages so uh the closest
34:59 languages to English German um Dutch so
35:03 they are very uh similar English used to
35:06 have lots of cases if you know like
35:09 dative accusative like the whole
35:11 morphological Paradigm like all I wish
35:14 Germans would drop these things too yeah
35:17 yeah yeah German is dropping it it's if
35:20 you look at the dialect it's dropping
35:22 there so this the north German dialect
35:25 right plat dut or how it's called like
35:27 they all have only one right uh PL D
35:30 yeah has uh um I think it dropped
35:33 the uh the genders but I'm I'm not sure
35:37 like yeah so I don't think I'll live
35:41 long enough to benefit from from this
35:44 yeah but yes so this is how I started
35:48 and of course you can see for example if
35:51 I I also try for fun to ask CH to
35:53 generate some something in Middle
35:55 English or go like complete
35:58 so I want to ask you about
36:00 this think you quoted so first of all
36:04 what was that and second
36:06 like it's a language that does not exist
36:09 anymore how can you actually pronounce
36:13 it like there are there are no
36:15 recordings of people saying that right
36:18 you can just only assume how exactly the
36:20 sounds like how you should make the
36:24 sounds that's um so why we approximately
36:28 know how it's pronounced it's a it's
36:31 comparative linguistics We compare it
36:34 with how the languages are spell
36:37 in
36:39 imagine so like this is how we imagine
36:41 how dinosaurs could look like right we
36:43 have no idea we only have bones and the
36:47 rest is our imagination so it's similar
36:51 with like research I I think for example
36:55 like let's take a uh word a like a and
37:00 night right so you have um a like a
37:04 letter in almost all Germanic and Latin
37:07 languages it was pronounced as ah so you
37:10 can already assume that it's not a and
37:13 then you have
37:16 a or I think so you have in German you
37:20 have right so you know that c was not
37:23 silent and I mean it's there like why
37:25 would someone write it if it's uh not
37:27 there there and you go comparing it with
37:30 the other languages how these sounds are
37:32 pronounced there and then what you start
37:34 noticing uh that there was no spelling
37:37 reform for a long time in English and
37:40 there were certain systematic um phatic
37:43 changes that have happened over the year
37:45 for
37:46 example uh where you have um like uh
37:49 words like fine or time team yeah uh um
37:54 uh uh Team time if was when it was
37:58 written with e it was long e so it was
38:01 team back then and there was something
38:03 called great consonant shift so basic
38:06 Great Vowel Shift so when uh
38:09 articulation of all the vowels kind of
38:11 went up and E became a diff Tong like I
38:15 but in other language is still stay e so
38:18 you can like the development of phonetic
38:21 is very logical and very and you can
38:25 derive certain rules depending on the
38:28 regions how how how the language changes
38:31 and based on this uh linguist can assume
38:33 how it was pronounced back then and why
38:36 it's spelled like this now so I I just
38:39 recall that there there's this poem
38:41 called bolf is it in that language yeah
38:44 no be wolf is a um old Jackson it's even
38:48 yeah I I used to be able to quote that
38:50 one too but I it's it's it's it's it's
38:54 uh even older and it's almost just
38:57 impossible to understand it without uh
39:01 actually learning this back then all the
39:04 um all the English was like so so so far
39:07 away from like what what it is now
39:09 English was greatly influenced by French
39:11 and by the uh you know the occupation of
39:15 England uh so that's uh it's a it was
39:19 even before I studied that
39:21 [Music]
39:23 um like when I was learning English I
39:25 studied that so that's why because of
39:27 the occupation um of England uh it was
39:31 the language of um like peasants more or
39:33 less like not high society but like just
39:37 usual people and they were illiterate
39:40 that's why they started dropping all
39:41 these articles and
39:43 stuff yeah like for
39:45 them to I
39:47 mean for a lot of languages for a lot of
39:50 dramatic Germanic languages those
39:52 languages were uh languages like
39:56 dialects there were um languages of um
39:59 peasants and what actually builted the
40:01 languages is the spread of Protestants
40:03 so when they realized that you need a
40:06 Bible in a vernacular language so that
40:09 people can understand it they starting
40:11 writing Bibles in a um in the languages
40:16 in the local languages and this is
40:18 basically what brought us some kind of U
40:21 spelling and orphography and
40:23 systemization of those uh languages so
40:27 uh um when I was working in research
40:29 like all my texts were Bibles like uh
40:32 basically I would say I read Bible every
40:35 day because uh that's
40:38 literally uh the only text I I I had
40:42 back then and it's also a great text
40:44 because it's basically a parallel
40:46 translation because you have Bibles in
40:48 all the languages so you can very well
40:51 Trace how those things were said back
40:54 then and you can figure out like what
40:56 which word me
40:58 there and what did you actually say like
41:00 this this quote so the word KN which is
41:03 night I understand but the
41:06 rest there was a night and thought a
41:09 wory man and that a worthy man thought
41:13 from the team that he he first first
41:17 began that from the time when he first
41:19 started to read to write out he loved
41:24 chivalry he loved chivalry Tru
41:28 and truth and honor
41:32 fre and cour freedom and courtesy okay
41:36 so now when you say like that I can see
41:39 like the resemblance right I can see
41:42 that some words are actually very
41:43 similar but when you said this for the
41:46 first time it was just for me like I
41:48 couldn't pick anything yeah it's
41:51 interesting and we also make transcripts
41:53 for our podcasts and I'm really
41:55 wondering how
41:58 actually I I could send you uh the
42:01 Middle English text to it and it's very
42:04 it's it's like when you read it you can
42:06 understand everything it's written like
42:08 English it's just the pronunciation and
42:10 there you see how like English didn't
42:12 have a spelling reform for a long time
42:15 and how it was supposed to be uh read
42:18 and where we are at
42:20 now okay um I see that there's a
42:23 question from enina enen the old
42:26 housemate I don't if it means anything
42:28 but like do you use an AI app to
42:30 identify the mushrooms you pick
42:33 Maria oh if I use an AI app to identify
42:36 yes I used to use one uh there was a
42:40 simple H classifier so before CH GPT and
42:44 how I used to uh use it I know that uh
42:48 um you cannot rely on top one guesses so
42:53 I would uh usually rely on top 10
42:55 guesses so I would look through the top
42:58 10 what the mushrooms are then I would
43:00 look if there are any poisonous um twins
43:04 of the or anything poisonous among the
43:06 gases and then I would just compare but
43:09 honestly I would still not eat it
43:11 because if there's something poisonous
43:14 like you need to be wrong just once yeah
43:18 exactly I mean I also by default assume
43:20 that all mushrooms are
43:23 poisonous no some very good ones yeah
43:26 but like CU I don't
43:28 not know for sure if this is a good one
43:31 or not so for me it's better to assume
43:35 it's poisonous
43:38 yeah that's how my husband is he doesn't
43:40 eat my
43:41 mushrooms I canot make him try
43:45 them and then you also published an
43:48 article so coming back to
43:51 you like our translations because we
43:53 don't have any other questions from
43:55 Arena maybe Arena will come up with more
43:57 questions I don't know um so yeah I just
44:01 decided to check if we have any
44:02 questions and then I saw it and then I
44:03 thought yeah we should cover it because
44:05 Arena has been waiting for the answer um
44:08 but coming back to machine translation
44:10 and languages and low resource
44:13 languages so we talked about like Old
44:16 English old German and we have a Bible
44:19 but what about like languages when we
44:22 don't even have that like you worked on
44:24 suan Tex right
44:28 I I looked at pictures and it just a
44:33 plate not a plate but like
44:36 a how you call it like a plate I don't
44:39 know like just a thing made
44:42 of yeah and then you have like
44:46 some you
44:47 have triangles rotated in different
44:50 directions six and it's probably not a
44:53 Bible it's just a plate with like four
44:56 rows of
44:58 different um how symbols right so how do
45:03 you
45:03 even attempt to understand what is
45:06 happening there this was actually quite
45:09 an interesting project that was a
45:11 project with Mr mamian languages like
45:14 with a uniform
45:16 languages Sumerian
45:18 HTE and it's it's been a while it was
45:22 way before um large language models and
45:26 back then
45:27 uh and honestly large language models
45:29 are not going to work particularly good
45:31 on this because of the word large we
45:35 don't have large data for those
45:37 languages so what happens there first so
45:41 there um
45:43 uniform uh uh expert linguist who
45:47 process like who literally like go on
45:50 the Expeditions take pictures of those
45:52 uh plates then they transcribe them in a
45:57 a script uh in a in a Latin basically
46:00 like they for every character they have
46:02 some kind of a um fonetic representation
46:07 of it sometimes it's not is it like in
46:10 Chinese we have a character that can
46:13 represent a word right yeah and I think
46:15 in ancient Egyptian language it was also
46:19 the case right so it's not letter so how
46:23 like it's Samarian like
46:25 that as far far as I remember there was
46:28 actually kind of a mix of different
46:31 styles to write sometimes it's not even
46:34 like solo like um one language there
46:37 could be like a mix of different uh um
46:41 uh heroglyph in there and uh they did
46:45 have um morphology uh in that uniform
46:49 but I'm not going to like now uh kind of
46:52 100% saying this because that's a bit um
46:56 the expert of the linguists who work a
46:59 lot with what we did back then we tried
47:02 to build a machine translation system uh
47:06 that translates between um Sumerian and
47:10 English to a certain degree like more
47:13 like an assistance for the linguist and
47:16 uh it was not a neural machine
47:19 translation because again we don't even
47:22 have the data for this so it was a old
47:25 approach like statistical machine
47:27 translation know with the translation
47:28 model and the language model we do the
47:31 alignment between words and it
47:35 surprisingly worked okay but um of
47:38 course was not particularly spectacular
47:41 in this and the other thing that we
47:43 tried to do is to help uh linguists
47:46 annotate those text as parts of speech
47:49 like what is noun what is adjective and
47:51 then option was if we can align words uh
47:54 from English translation to the um
47:57 sumarian we can just say if like a
47:59 certain noun aligns the noun then it's a
48:01 noun so a fairly simple approach so the
48:04 whole project was basically to uh help
48:08 again to linguist to analyze grammatical
48:12 properties of the of the language I
48:15 eventually left to work in the industry
48:18 when this project started so I I hope it
48:21 kept going but I'm not sure like what's
48:24 status of this
48:27 and while
48:28 um like in the meantime I was also
48:31 Googling Samarian language and I found
48:35 um like let me share it in chat I'll put
48:38 it in YouTube um here so there is
48:43 a kind of a table that says for this
48:48 character this is ltin D this character
48:51 is lighting e is lighting f um so
48:55 actually um what we have on these
48:57 tablets is one symbol is one character
49:02 right and then you go from there trying
49:04 I think there was a mix I think there
49:05 was like this and like that if I if I
49:08 remember correctly so there were
49:10 characters but there were also things
49:12 that would determine a word and were
49:15 like non-compositional but maybe if
49:17 someone speaks uniform in the like
49:19 Samaran in the CH they can tell us
49:22 because I honestly don't don't know
49:24 anymore I know that was fortite case is
49:27 a younger language than Sumerian and
49:30 they had characters from Acadian from
49:32 Sumerian they were a mix of different
49:35 languages from suarin is old language so
49:38 I'm not sure like how much interference
49:40 there was with other
49:41 languages at work uh you speak German
49:44 don't you or uh yeah I speak German and
49:47 English uh so I mean that's that's
49:50 mostly I that and for you like when you
49:54 came to Germany did you already speak
49:56 German
49:57 yeah uhhuh okay so it was a part of your
50:01 um training right yeah it was a part of
50:04 my translation studies that I like the
50:06 Linguistics so I studied Linguistics
50:08 before I came to Germany so that was not
50:12 too hard to uh learn German to be I
50:16 learned at some point Korean and this
50:19 this is a whole different level
50:21 obviously uh in terms um how we need to
50:25 learn uh every single word but uh like
50:29 uh German is so similar to English as
50:31 they said it's from the same group it
50:33 has the same like basically you already
50:35 know half of the word um from English so
50:38 it was the grammar is a intuitive uh
50:43 like we yeah yeah of
50:45 course
50:47 maybe I mean if if you compare with
50:51 grammar from like other languages like
50:53 for example what Korean does there like
50:56 we and we have all the main Concepts
50:58 like we know what the case is we know
51:01 what the the only one is for us probably
51:03 is the article is the one that
51:09 new okay yeah I remember 10 years ago so
51:14 like around 12 years ago I lived in
51:16 Poland and polish is very close to
51:18 Russian so Russian so polish for me was
51:21 relatively easy uh so it took like maybe
51:24 half a year of just living in here
51:26 actually I have this book here because I
51:29 was also learning Polish Polish it's a
51:32 practical course of Polish if you can
51:34 see so I was also learning it at some
51:37 point it's not it wasn't that difficult
51:39 just hearing people trying to understand
51:42 what they say and reply back and then if
51:43 something is not clear asking what it
51:45 means so polish was relatively okay for
51:49 me not that difficult but the machine
51:51 translation back then was terrible
51:53 because what was happening I think under
51:55 the hood is there was no direct
51:57 translation between polish and Russian
51:58 so it would first translate Polish to
52:00 English and English to Russian and then
52:02 the result was terrible um I think the
52:05 same was happening with the Ukrainian to
52:07 Russian at some point Ukrainian to
52:09 Russian translation became like super
52:11 good in Google Translate but I also
52:13 remember times when it was like totally
52:15 butchered like the translation MH but
52:18 these days it
52:19 seems much better like at least when it
52:22 comes to polish to Russian Ukrainian to
52:24 Russian is like when I translate ukra to
52:26 Russian it treats I can read it feels
52:30 like it was written in Russian already
52:31 like there are no weird phrases usually
52:35 uh only maybe when I try to translate a
52:37 poem then sometimes it can be so like it
52:40 feels to me that the level is kind of
52:43 quite good already like is it the case
52:46 like for example like I'm just curious
52:48 to know what is the current stat of
52:50 state of machine translation when it
52:52 comes to like let's say big
52:53 languages for example Korean like if we
52:56 from Korean to Russian is it still okay
52:59 or
53:01 like so what it's always trained on like
53:04 and I think what goes into chpt as well
53:08 as what goes into maim translation are
53:10 so called paral corpora right parel text
53:13 so you have a translation sentence in
53:15 Russian you have a sentence in Ukrainian
53:17 I think to acquire such parl text is not
53:21 very difficult because we have lots of
53:23 text on the internet that both Ukrainian
53:25 and Russian those those like were or I
53:28 don't know if they still are official
53:30 languages of Ukraine so you have you can
53:33 easily uh acquire this uh Russian is
53:37 also quite good for this because it's
53:39 it's one of the scks I think un
53:41 languages so all the text that you have
53:44 in the UN there's un Corpus is
53:46 translated in Russia into Russian from
53:49 English to uh like Chinese and I think
53:52 like what's so H and uh this this is the
53:56 reason reason why uh translation is good
53:58 for such language like for example
54:00 European languages very good because
54:02 European Parliament translates
54:04 everything into the uh that's why
54:07 translation from polish to Bulgarian is
54:09 easy but like from polish to Chinese
54:12 maybe not so polish Chinese could be I
54:16 mean machine translation used to work
54:19 like this pivoting through the languages
54:21 for pretty much maybe even I wouldn't be
54:25 shocked if Google Translate still do
54:27 this that they're pivoting through
54:29 English for they're just making it
54:31 better than before yeah so oh I mean
54:35 there there's like an approach now with
54:37 multilingual models right where you
54:39 basically train everything
54:42 together and then you hope that the
54:45 model will be able to generalize to a
54:48 new language pair so even if for example
54:51 it never seen a corpus uh between like
54:54 of I don't know Korean to Ukrainian
54:56 but it's in the Corpus of Korean to
54:59 Russian it can kind kind of kind of can
55:02 figure out how uh it will generalize to
55:06 Ukrainian and I think that's that's
55:07 what's happening for example with chpt
55:09 because I doubt they had lots of Corpus
55:11 of Korean Ukrainian right um so I would
55:16 think this is probably now the the state
55:19 of the art so multilingual models that
55:22 basically trained all together and uh
55:27 uh we are moving away from the pivoting
55:30 through English or some other uh similar
55:34 language for example Russian probably
55:36 would be a good pivoting language for
55:38 Slavic Lang languages because it's a
55:40 fairly High
55:41 resource um so yeah and of course the
55:44 further the languages are from each
55:46 other it's uh frequently the harder it
55:49 is to translate between them the other
55:51 thing is um the availability of the
55:55 digital resources so for example
55:58 translating in African languages like
56:00 where you do not have um much um text on
56:03 the internet where uh spelling is not
56:06 standardized uh uh is for example I try
56:09 to translate between middle low German
56:11 and German two very similar
56:15 languages but it was very hard because
56:19 middle low
56:20 German even on a small Corpus even
56:23 statistical machine translation doesn't
56:25 have a standard spelling for example you
56:27 had 16 ways to spell cross in in a
56:30 German so the machine translation would
56:33 translate nicely into German but from
56:35 German into
56:37 middle uh low German was almost
56:40 impossible because it simply didn't know
56:42 which which cross to choose and uh out
56:45 of I assume there were 16 people who
56:48 would do the translation and everyone
56:50 had a different way of of course they
56:53 it's every village had a different way
56:55 to write back
56:57 then they they there was no concept of
57:01 you know of grammar of standard TI ofy
57:04 there was no punctuation there was no
57:06 prescriptive grammar as we have like the
57:08 institutions that prescribe orphography
57:10 they appeared just uh in the 19th
57:15 century uh that start standardizing
57:18 languages and then I see that there's
57:20 another question from
57:21 Arena and uh this question will probably
57:25 require another
57:27 hour oh
57:30 my well do you have like a couple more
57:32 minutes maybe you can can like try to
57:35 condense your answer so the question is
57:38 what was the biggest challenge uh
57:39 leaving the academy and moving to work
57:42 for such a big name in
57:44 Germany right I think the biggest
57:46 challenge was indeed to understand that
57:51 uh the most Innovative approach the most
57:54 state of the-art approach is really not
57:58 what industry frequently wants they want
58:01 a quick approach that works uh they do
58:05 not care that much about the best
58:07 possible accuracy sometimes like or
58:10 horror from the researcher perspective
58:13 you can sacrifice 10% of f score for a
58:17 faster
58:18 implementation you do not um you need to
58:21 deliver and deliver quickly and you
58:24 always need to think about how you're
58:26 going to operate it so you can build a
58:31 very complex model but if it's a heavy
58:33 weighted model you cannot put it into
58:36 production you need to think about
58:38 return on investment you need to think
58:40 about a lot of things research doesn't
58:43 really care that is basically uh a lot
58:46 of questions that come with applied AI
58:49 so apply it means can you actually apply
58:52 it something so that's a that was quite
58:56 quite quite a
58:57 change um for me and um I I think I did
59:03 it fairly well but sometimes I'm still
59:06 struggling with this
59:08 stuff uh but I think after so many years
59:12 it's it's getting better and better yeah
59:14 thank you and by the way Arena here uh
59:18 is already so she has been a guest uh in
59:22 our podcast and soon she will have a
59:26 will appear again so we'll host here
59:28 again in a webinar so thanks Serena for
59:32 joining us today and I'm really looking
59:35 forward to seeing your webinar soon so
59:38 and Maria thanks a lot for uh also being
59:41 here today for being our guest for
59:43 sharing all your experience with us your
59:45 stories uh I really enjoyed our
59:47 discussion today so thanks a lot thank
59:50 you very much for inviting me it was a
59:52 great experience yeah and uh yeah well
59:56 have a great day and uh thanks everyone
59:58 uh have a great