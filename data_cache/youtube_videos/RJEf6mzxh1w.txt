0:00 hi everyone welcome to our event this
0:02 event is brought to you by data talks
0:04 club which is a community of people who
0:05 love data we have weekly events this
0:08 event is one of such events although it
0:10 doesn't happen on our usual weekly times
0:12 because we had to reschedule it from
0:14 last friday so usually we have events
0:16 like that today we will have live
0:18 interviews events like that usually
0:20 happens happen on friday
0:22 and then we have webinars that happen on
0:24 tuesday
0:26 so you can check our events we have a
0:28 link in the description just go there
0:30 and check it
0:31 subscribe to our youtube channel if you
0:33 haven't done this yet for whatever
0:35 reasons i don't know what
0:37 can be a good excuse i cannot think of
0:39 any so if you haven't done this go and
0:41 subscribe
0:42 and actually i learned this i am
0:44 sometimes watching youtube videos
0:46 and they like every five minutes they
0:48 say hey go and subscribe
0:50 and i'm wondering like is it annoying it
0:52 actually works so i'm not sure
0:55 but yeah i hope it's not annoying and
0:57 yeah please do that
0:58 and we have an amazing slack community
1:00 it's the link is also in description go
1:03 there um check the link and join we talk
1:06 about all data related things so it's a
1:08 very cool community i do recommend
1:10 checking it out
1:12 and finally during today's conversation
1:15 if you have any question you can ask
1:18 them in the link so there is a pin
1:20 linked in the live chat click on this
1:21 link ask your question and i will be
1:24 covering these questions as we as we go
1:26 during the interview
1:28 so that's all from me
1:32 i think
1:33 so at least i don't have any more slides
1:36 so now let me get the questions
1:41 do you like the questions
1:44 yeah yeah pretty interesting let's go
1:46 through them
1:48 okay so are you ready to start
1:50 yeah go ahead
1:53 okay so this week we'll talk about nlp
1:56 teams and we have special a special
1:57 guest today ivan so we already have had
2:00 ivan a few weeks ago where he talked
2:02 also about nlp introduction to nlp
2:06 and one of the things he talked about
2:08 was
2:09 um nlp teams and then who we have on the
2:12 team the roles and uh then later
2:14 everyone posted uh
2:16 these pictures of members of nlp teams
2:19 uh on linkedin and it got a lot of
2:21 engagement a lot of attention so we
2:23 thought it would be cool to
2:25 spend some time talking more about this
2:28 how we can uh
2:30 like me in general about leading nlp
2:32 teams who are on the teams and so on
2:35 so ivan is uh he works in is engineering
2:38 manager at personnel and do i understand
2:40 correctly that you do not manage an nlp
2:43 team right now right no no it's right
2:44 now yeah but i used to tell you more
2:46 about that yes yes
2:48 so but what you do now what you are
2:50 currently working on is identity as and
2:53 access management this this is what
2:54 persona is doing right um yeah so okay
2:58 uh persona is a hr platform right so
3:01 um my team specifically is responsible
3:05 for
3:06 basically everything related to login
3:08 login experience of the users and then
3:10 also access rights because as a sort of
3:12 hr platform
3:14 you um there's a lot of personal data we
3:18 are handling and
3:19 we have to make sure everything is as
3:22 secure as possible and
3:24 adhering to all the standards and
3:26 what we are kind of we are in internal
3:29 product team so we are providing
3:32 tools for other teams at the company so
3:34 we we have like
3:36 our own tooling around
3:39 access rights that other teams can use
3:41 that can help them basically in their
3:43 features and and their parts of the
3:45 application
3:46 to check whether a specific user or um
3:49 you know has er is supposed to have
3:51 access to a document of some sort or
3:55 supposed to see i don't know a salary of
3:57 someone so you know it's a manager is
3:59 supposed to see salaries of his
4:00 subordinates but not the other way
4:02 around and things like that
4:04 yeah that's that must be quite a complex
4:06 problem um so
4:09 the main technical and thanks for
4:11 telling us by the way so the main
4:12 technical interests
4:14 of one include building microservices
4:16 for data intensive applications
4:18 envelopes for nlp and deep learning
4:20 research just we will talk about some of
4:23 these things today so welcome to our
4:25 event
4:27 thanks thanks for having me i'm
4:29 yeah looking forward to answering the
4:31 questions
4:32 um so before we go into our main topic
4:35 of um nlp teams let's start with your
4:37 background can you tell us about your
4:39 career journey so far
4:40 yeah sure um right i uh
4:44 i've studied uh actually initially i
4:47 come from ukraine and i studied uh their
4:49 sort of general linguistics um
4:52 for a while when i moved to munich
4:54 unique
4:56 about it's about 10 years ago already
4:59 i decided to
5:00 to to pick up actually computational
5:02 linguistics so it was like a
5:04 continuation of what i was doing before
5:06 and the computational linguistics as a
5:09 field was relatively new back then as
5:11 well it was you know sort of centered a
5:14 lot around machine learning and how that
5:17 can be applied to text understanding and
5:20 text analysis in general
5:21 uh you know back then it was still uh
5:24 done with peril and then eventually
5:27 moved into python as it's now sort of an
5:29 interesting industry standard
5:31 and so i um over time i worked actually
5:35 on different
5:36 projects and in different teams i did
5:38 not
5:39 only work on nlp and ai so i my like
5:42 first jobs were in building uh
5:45 interfaces for desktop apps and so i
5:48 worked a lot with csharp signals plus
5:50 eventually i worked on web scraping for
5:54 quite a while then i moved into data
5:56 engineering so i was working on
5:58 etl pipelines with spark and hadoop
6:02 and then for a while i worked also as a
6:05 data scientist so that was a company
6:07 called trust you where we
6:09 were working on aspect-based sentiment
6:11 analysis on text summarization and a few
6:14 other nlp tasks and
6:17 there is where sort of the core of my
6:20 nlp
6:21 knowledge also comes from because that
6:23 was
6:24 super challenging as we had to support
6:27 our solutions
6:29 for 23 different languages so basically
6:32 um
6:33 and uh some of those languages were
6:35 super complex so we uh i think we
6:38 um the most
6:41 complex languages i worked with would
6:42 probably be japanese and thai these are
6:44 like asian languages that are very very
6:47 different to like regular uh english nlp
6:51 that you would do uh so yeah that was
6:53 quite interesting uh eventually then i i
6:56 went into management so i've
6:59 i i
7:00 actually got another degree in
7:02 technology management here in munich at
7:04 the cdtm
7:05 and
7:07 i've been managing teams for a bit over
7:09 two years so i managed data engineering
7:12 teams
7:14 nlp teams and now it's more sort of
7:17 web product based team at persona
7:22 interesting we still
7:23 use perl
7:25 no not really
7:27 it's uh
7:28 yeah
7:29 it's a language that's hard to read and
7:32 it
7:33 you know it also depends on who writes
7:34 the code because the the formatting
7:36 there is not very strict
7:38 uh yeah
7:40 i remember uh the day when i needed to
7:43 figure out how apparel program works
7:46 because there was a scraper web scraper
7:48 written in perl that the company where i
7:50 worked used and it saved
7:52 data it dumped data in a specific format
7:55 that was only possible to read from perl
7:57 so i had to hack a pro pro program that
8:00 reads this and converts it to json and
8:02 then just uh it really messed up with my
8:05 brain so i'm not the same person as
8:07 before
8:08 after doing that
8:09 yeah yeah no i mean apparel is actually
8:12 a very powerful language you know and
8:14 especially if you do
8:16 no i know it's still used in in cyber
8:18 security to some extent it's like really
8:20 good for
8:21 uh
8:22 you know salting passwords and stuff
8:24 like that but i i actually i haven't
8:27 worked with it for quite a few years so
8:28 it has probably changed a lot uh yeah
8:32 yeah so you mentioned you also got a
8:35 degree in technical management yeah
8:38 exactly that was uh masters
8:41 uh this uh
8:43 sort of um
8:44 honors degree it's like an additional
8:46 program to masters that you can take
8:48 here at uh um it's a cdtm center for
8:51 digital technology management here in
8:53 munich it's it's part of both lmu and tu
8:56 um so if you study uh you know at lmu
8:59 atu you can
9:01 get an additional degree there
9:03 and that was that was very interesting
9:04 because uh it was very hands-on so
9:07 it included like a couple of internships
9:09 i worked
9:11 at
9:11 like i had an internship at a company
9:13 that was selling satellite images so i
9:15 actually worked on
9:17 spectral analysis of satellite images
9:19 which was quite interesting then i also
9:21 worked at a cyber security company
9:23 called montego
9:25 which is also quite fascinating
9:27 and yeah it was this was very hands-on
9:29 you learn a lot from it how to manage
9:32 projects and
9:34 yeah and uh you also get a really good
9:37 sort of network built out of that
9:39 most of uh like a lot of startups and
9:42 startup founders are founded actually by
9:45 by people who come out of cetm here in
9:48 munich and in berlin
9:50 that's cool so you you started product
9:52 or project management there what else
9:54 did you study there like team management
9:56 like people yeah yeah organizational
9:58 management so yeah all of those topics
10:00 right
10:01 so are these things that people can
10:03 actually learn at university or it's
10:05 like uh
10:06 learning swimming by reading books about
10:09 this
10:10 it's uh as i said like it was super
10:12 hands-on and that was cool because all
10:14 of the uh presentations and sort of
10:17 courses that we had were then led by uh
10:20 some ceos or founders of of different
10:23 companies and they would just bring
10:24 their own perspective on you know how
10:27 they approach organizational management
10:29 or how they build up a startup that is
10:32 now like worse a few billions
10:35 so so that was very very very
10:36 fascinating to do so there i don't think
10:39 i i had to read any books while there i
10:41 was mostly really learning from
10:43 experience of others
10:46 yeah i remember before i became a
10:48 manager i was reading books about this
10:50 books or articles and they didn't make
10:52 much sense to me
10:53 like
10:54 to me it read like okay
10:56 do
10:57 things well and
10:59 things will work out something like this
11:02 but now like when i already have this
11:04 experience and i go back and read this
11:05 now it all of a sudden makes much more
11:08 sense so i guess this is one of the
11:10 things like yeah that's cool that things
11:11 like that happen and you can just go
11:13 there did you
11:15 need to take a break between works works
11:17 like your work there or
11:20 no i try to do everything at once so i
11:23 was working part-time
11:25 and then also studying both
11:27 computational linguistics and technology
11:29 management
11:30 yeah that's really cool
11:32 so i'm i'm also really curious about
11:34 your transitions your career path so you
11:36 did quite a few different things so then
11:39 you managed to so you worked as a data
11:41 scientist and you managed nlp teams and
11:43 now you manage uh like general usual
11:47 like i'd say air quotes usual software
11:49 engineering team
11:50 i'm wondering what led to this uh
11:53 decision
11:55 mainly you know um it's kind of driven
11:58 by by my uh career goals right i i want
12:01 to
12:02 eventually
12:04 like
12:05 work on a on a higher level as a as a
12:07 manager right either director level or
12:10 or cto and i think it's uh you know very
12:14 important to have a very good grasp on
12:16 different parts of software engineering
12:17 right i already had a lot of experience
12:19 with ai
12:20 um and
12:22 now i sort of relearning things or like
12:24 reminding myself how it is to manage
12:27 a team that works on a web application
12:30 you know um and i i there are still like
12:33 many things that are still the same
12:34 right i'm still doing more or less the
12:36 same tasks right i'm
12:38 managing productivity of the team i'm
12:42 talking a lot about ci cd which is
12:44 important not just for source
12:45 engineering but for ai as well
12:47 right and
12:49 talking about um
12:52 sort of
12:54 yeah
12:55 availability of
12:57 the web apps that we are working now and
12:59 it's the same topic of availability of
13:02 models ai models and how well uh you
13:05 know or how fast the users actually get
13:08 the input from from ai models or from
13:10 web apps it's basically more or less the
13:12 same and then
13:14 our arching topic is observability and
13:16 observability is important for any team
13:19 i think not just ai and or just software
13:21 engineering like we used to to have a
13:24 lot of dashboards we looked at when we
13:26 worked in lp models we do the same now
13:28 we use we just look at different metrics
13:31 but we still have you know observability
13:33 is a big part of what we are doing
13:36 that's interesting yeah thanks for for
13:38 sharing so coming back to our topic of
13:40 uh
13:41 nlp teams so how would you define an mlp
13:44 team and like is it even different from
13:47 because you just said that many things
13:49 that you are doing right now even though
13:51 the team you manage is not
13:53 specifically an nfp team it's not a data
13:55 science team it's not a data team at all
13:56 it's just
13:57 software a team of software engineers
14:00 like
14:01 how is it different from
14:04 what you have and what is nlp team
14:07 yeah yeah good question i mean um it's a
14:10 it's more of like an
14:11 industry question do we even have like
14:13 separate designation for nlp teams i
14:15 think uh maybe a few years ago this
14:18 wasn't the case like you would just have
14:19 a data science team and like everything
14:21 data science is done there right you
14:24 either its vision and lp or just regular
14:27 data analysis i think now in recent
14:29 years we're like more and more branching
14:31 off
14:31 because nlp has also became more and
14:34 more popular uh in the last few years
14:37 and so you now see
14:38 companies uh you know having like a
14:40 really dedicated nlp team that works on
14:44 nlp tasks so um
14:47 i am a big proponent actually of like
14:50 cross disciplinary teams so i would
14:53 prefer you know to have a team that
14:56 incorporates you know data scientists
14:59 uh nlp engineer uh ideally a data
15:02 engineer and maybe even infrastructure
15:04 engineer this is something i had a lot
15:06 of success with is in my previous teams
15:08 where we really had like
15:10 all the talent gathered in one team and
15:13 we had all the knowledge that we needed
15:15 to to succeed there
15:16 um
15:17 so
15:18 right but still as i said like some
15:21 companies still do it like they have a
15:22 completely separate nlp team that works
15:25 on on delivering a
15:27 nlp pipeline right um
15:31 it's good when that team is like fully
15:34 owns it like they also are responsible
15:36 for
15:37 deploying into production and then
15:39 monitoring and everything else this is
15:41 great but it's all not always the case i
15:43 know also of cases where nlp teams just
15:45 build a prototype in jupiter notebook
15:48 and then just give it away to the data
15:50 engineering team and they or like ml
15:52 engineers and they put it on production
15:55 um so you know what differentiates nlp
15:58 teams from other teams i think it's
16:00 mainly the
16:01 the like the core task is working with
16:04 text data
16:05 and then sort of delivering
16:08 a system around it that that produces
16:11 some insights for the user right so be
16:13 it uh classification or chatbot or some
16:17 text generation something like that
16:19 okay so
16:20 an lp team doesn't need to have an nlp
16:22 engineer as long as a team works on some
16:25 nlp related tasks let's say chatbot or
16:28 customer service but then it becomes an
16:30 nlp team right
16:32 yeah i mean that's another question like
16:34 what is an nlp engineer and is that
16:37 you know i've been asking myself and the
16:39 industry is that an established role
16:42 right because it's still asked about
16:44 that as well yeah like it still i i
16:46 don't think it is still fully
16:47 established right i still see you know
16:50 job ads that just say data
16:53 analyst or data scientist but the
16:55 description is you know everything
16:57 related to nlp and and so i
17:00 i hope
17:02 there is more sort of
17:04 um the industry takes a step into
17:06 defining these roles a bit more and
17:07 that's something i was trying to do with
17:09 with you know i showed in the previous
17:11 presentation and i as you mentioned i
17:13 shared on linkedin trying to sort of
17:15 define those roles what are their
17:17 responsibilities and what are the skills
17:19 that they need to have and so for nlp
17:21 teams themselves
17:23 right
17:25 i think an lp engineer is very important
17:27 an nlp engineer is someone who has
17:30 the experience and knowledge of working
17:32 specifically with
17:34 um nlp
17:36 tasks and like data science
17:39 parts that specifically work with with
17:41 text
17:43 and ideally this is not always the case
17:45 but ideally someone who also you know
17:47 has some linguistic knowledge right at
17:49 least some some applied linguistics or
17:52 at least basics of general linguistics
17:54 because that's super
17:56 useful to have it's not a must these
17:59 days but it is you know very useful
18:02 um
18:03 now thinking back to my career when
18:07 i worked as a you know data scientist
18:09 you know data scientist was my title but
18:11 i was sort of an nlp engineer um and
18:16 looking back at the time i think
18:17 linguistics really helped like i was
18:19 working on
18:20 very hard problems of parsing
18:23 text and like especially in different
18:25 languages
18:26 and without knowing those like building
18:28 blocks of how to do uh proper dependency
18:31 parsing for example or um you know how
18:34 to uh do tokenization in languages that
18:37 don't have
18:38 uh any full stops or spaces like thai
18:41 it's just a wall of text and that really
18:44 helped like i think without linguistic
18:46 knowledge
18:48 me and my team wouldn't be able to solve
18:50 those issues so easily
18:52 so if let's say a data team that do not
18:55 have the nlp engineers people with who
18:58 specialize in nlp tasks so if this team
19:02 doesn't have
19:03 such people so how should they go about
19:06 picking up the skills
19:09 should it be a data scientist who goes
19:11 and learns about uh
19:13 linguistics or how should they do that
19:16 ah yeah that's a that's a really hard
19:18 question actually uh because the
19:20 question itself is to be
19:22 at the current stage do we
19:23 [Music]
19:25 need those linguistics now like there
19:28 are so many things now that
19:30 you could really get by without
19:32 understanding linguistics right there's
19:34 you know just think about gpt3 where
19:38 anyone can do it right you don't even
19:40 need to know
19:41 how to do
19:43 data science itself right you just
19:46 use the gt3 prompt and then you have
19:48 something built out of it
19:50 it depends on what tasks you're working
19:52 right if you are working on
19:55 like more regular nlp tasks that
19:58 everyone else is working like i don't
20:00 know let's say just basic sentiment
20:02 analysis or summarization things like
20:05 that this
20:06 you know most of the time you probably
20:08 can get by without any linguistic
20:10 knowledge but if you're going more into
20:14 um specific tasks like you know you
20:16 don't say donation extraction or
20:18 information extraction and especially if
20:20 you're starting to work with
20:22 languages that are not not so like
20:25 widely covered by
20:27 you know research these days then it
20:30 really helps to to to have linguistic
20:32 knowledge and how do you get that is
20:35 a good question so um there are quite a
20:37 few resources online of course you can
20:40 learn that
20:41 by yourself
20:43 i wouldn't recommend to like go and
20:45 learn general linguistics um that is
20:48 probably not not going to be super
20:50 helpful there are courses and resources
20:53 that are
20:54 more specific to nlp itself and i think
20:56 there are quite a few things for example
20:59 around spacey i think they have a lot of
21:01 tutorials around that hacking phase
21:03 and you can just really go and
21:05 specifically learn
21:07 nlp related linguistic knowledge right
21:10 okay so you focus more on nlp and
21:13 computational linguistics rather than
21:15 you know generic linguistics
21:17 here okay and then um i guess what you
21:20 also mentioned is you pick up a library
21:23 like a space your hugging face and you
21:25 learn that and then
21:27 along with learning this library you
21:30 also pick up some necessary nlp
21:32 knowledge right
21:33 yeah yeah i mean there's a
21:35 right
21:37 what i'm saying can be also like heresy
21:40 to some people
21:41 right i know there's like a you know
21:43 there are two camps of uh nlp
21:46 researchers one one camp says we can do
21:49 everything with ai and we don't need
21:50 linguistics and then there's another
21:52 camp that
21:53 specifically advocates for
21:55 us first learning linguistics properly
22:00 and then applying it to ai right and so
22:02 it's like it really depends on what
22:05 you're doing if you're in if you're
22:06 doing research actually at the
22:07 universities i think
22:09 knowing linguistics will definitely
22:11 benefit you because that's probably
22:13 one of the avenues that will help
22:16 um improve current ai right if someone
22:19 who knows both linguistics very well and
22:22 ai very well they're going to build a
22:24 better language model than someone who
22:27 only knows ai for example
22:29 yeah it's also
22:31 um
22:32 like maybe if you compare in computer
22:34 vision you have like old school computer
22:36 vision which is about extracting
22:38 features with all this um
22:40 you know i like i think it's called back
22:43 official words and all this uh
22:46 like uh swift and i don't remember i
22:48 don't know much about these things but
22:51 like uh i know that this thing exists
22:53 like old school of computer vision and
22:55 then there is a new school is just we
22:57 don't care about this just throw
22:58 everything in neural network it will
23:00 figure this out and work
23:02 and interestingly it does work right
23:05 yeah it does work
23:06 yeah
23:07 you know that's another kind of worms
23:09 that i i don't think we want to open
23:12 what is more complicated vision or text
23:15 analysis right
23:17 and
23:18 you know maybe it works because vision
23:20 is a bit more definitive in some way
23:24 than text because text you know text is
23:26 a
23:27 you know there's a there are endless
23:29 amount of of sentences you can generate
23:31 in english and that's only in english
23:33 right you have so many languages there
23:35 you know whatever 5000 languages we have
23:37 or something like that it's uh
23:39 yeah i don't want to open this kind of
23:41 worm i i'm not saying that text is
23:43 easier than vision
23:45 version is very hard as well
23:47 but i think for in order for us to
23:49 succeed with text analysis i think we
23:52 still need uh uh linguistics for sure
23:55 okay so what do you say that a data
23:57 scientist an nlp engineer is somebody
24:00 who has data science uh background um
24:02 like with a data scientist with
24:05 some knowledge of nlp
24:07 and computational linguistics wouldn't
24:09 we correct the description yeah yeah
24:12 so that was basically
24:14 so you said you were hired as a data
24:16 scientist but your task was working on
24:18 nlp things yeah mostly and what's the
24:21 difference then between uh
24:24 nlp engineer and machine learning
24:25 engineer so he's an engineer an engineer
24:28 in the same sense as you know
24:29 engineering engineer like do they care
24:31 more about the engineering aspect or
24:33 more like training models aspect
24:36 that's very good
24:38 i hope in the future they will be more
24:40 or less the same because i think those
24:41 parts are important
24:43 how i've seen it so far nlp engineers
24:46 are
24:47 um
24:48 like at least in in the case of the team
24:50 i worked at uh we were doing a lot of
24:53 engineering like it was really a lot of
24:55 pure engineering where we are optimizing
24:57 everything and not just
25:00 optimizing training but also optimizing
25:01 inference
25:03 what we were doing less of was
25:05 the
25:06 like productionizing of the model itself
25:08 like the deployment itself and that was
25:11 mostly done with the help of ml engineer
25:14 or data engineer in this case and i
25:16 think this is kind of um you know i also
25:19 had a lot of interviews
25:21 uh when when hiring nlp engineers data
25:23 engineers and managers this is sort of a
25:26 division i see where ml engineers
25:28 themselves think of of themselves as
25:31 devops for ai right they are responsible
25:34 for
25:35 um you know deploying the models
25:38 uh figuring out how to do um i don't
25:40 know blue-green deployment of ai model
25:42 right because that's the challenge that
25:44 i think um nlp engineers
25:47 not always prepared to solve
25:50 yeah interesting
25:52 and um
25:54 so we talked about linguistics and that
25:56 uh somebody who is an op engineer they
25:59 need to know these linguistics
26:01 but do we need
26:03 people who are who specialize only in
26:05 linguistics who have this not just nlp
26:08 knowledge and know how to um
26:10 call methods from spicy but who actually
26:15 had education as linguists do we need
26:17 people like that in the team
26:19 yeah for sure there are some specific
26:21 tasks that would really benefit from
26:23 that and i think
26:25 um
26:26 in the i think about the last two years
26:28 there was like a new
26:29 role forming in the world of data
26:31 science and it's called conversational
26:33 designer and it's basically a person who
26:37 is responsible for
26:39 making the
26:40 user experience and the flow of how the
26:43 chatbot interacts with the user
26:45 feel sort of more realistic right
26:48 and conversational designers from what i
26:50 see
26:51 mostly people who come from like more
26:53 pure either linguistic background or
26:56 some like more societal studies
27:00 because
27:01 that knowledge is really important then
27:04 to how do you properly form uh and
27:06 utterance that that the chatbot can use
27:08 or how does a chatbot react to some
27:11 specific questions things like that and
27:13 that's what conversational designers
27:14 these days work and they usually um
27:17 from from what i've seen right i have a
27:20 like a small uh
27:22 uh subset of people i know who are
27:25 actually conversational designers but
27:26 from from those i know they mostly work
27:28 on on
27:30 um on defining that slow without having
27:33 to code that much right they are less of
27:36 a recorder less of an engineer they like
27:40 really
27:41 specifically look into
27:43 how
27:45 you can build out a really nice
27:47 experience around talking to a child
27:50 so i guess it's similar to what we have
27:52 in general software engineering like
27:54 product designers and ux designers
27:57 only here that they don't focus on
27:59 general ux user experience they focus on
28:03 the conversational part yeah the
28:05 interaction with chatbot yeah yeah
28:07 that's still really good
28:10 comparison yeah
28:12 okay interesting and what about areas
28:15 when let's say some teams not all nlp
28:18 teams work on chatbots there are teams
28:19 who work on other things
28:21 like you mentioned like this information
28:23 extraction
28:24 and
28:26 i don't remember what else but there are
28:28 areas where like maybe we need to
28:31 do something with text understand it or
28:33 whatever um do we need linguists there
28:37 in those teams
28:38 as well
28:40 good question uh it really depends on on
28:42 like what area of research you're
28:46 working in or like what the specific
28:48 tasks you work on
28:49 um
28:51 i think it wouldn't hurt right if you
28:53 have someone who knows linguistics well
28:55 um
28:56 and if you have
28:57 problems as i mentioned before like
28:59 problems where you really need to think
29:01 about how do you
29:02 parse a sentence or how do you
29:04 um you know um
29:06 get something out of of of of text
29:10 um
29:11 yeah that that's where a linguist really
29:13 helped uh ideally right i think i
29:16 ideally is uh
29:18 to have this nlp engineer role that has
29:21 pulse incorporated right it's someone
29:22 who knows linguistics enough to uh to be
29:25 able to apply it but then the other side
29:27 also knows the engineering part behind
29:30 it
29:31 and to to effectively apply it to the
29:34 problem they're working on
29:36 yeah and
29:37 as you mentioned when a team starts
29:40 working on an nlp task
29:42 they don't necessarily need to
29:44 immediately get this nlp with
29:47 linguistics knowledge because you can
29:48 get quite far just by using this library
29:52 so let's say yeah team starts working on
29:54 the some nlp tasks so they do get by
29:57 they just go get hug interface spacey
30:00 start using this and then at which point
30:03 do they need to hire a linguist or nlp
30:06 engineer so how do you decide that how
30:08 do you see that that they need somebody
30:13 that's a good question it also i guess
30:15 depends on
30:17 um
30:18 on what approach they choose right if
30:20 they
30:21 if the problem that you have can
30:24 be solved by pure ai
30:26 then i think there
30:28 probably is no need for specific like
30:31 linguistic knowledge in the team
30:33 um but not all problems can be solved
30:36 with ai and that's why
30:38 um you know
30:40 still in the industry a lot of problems
30:42 are solved with still like rule-based
30:44 systems or like uh see some statistical
30:47 approaches
30:48 and and that's or especially if you need
30:51 to build still build like uh features uh
30:54 to do a feature engineering i think
30:56 there it would
30:57 be very helpful to have a linguist or
30:59 like at least an lp engineer who knows
31:02 what to look for how to build features
31:04 and and so on
31:06 um
31:07 yeah so it really depends on the problem
31:09 right we are sort of moving into a
31:11 direction where more and more problems
31:13 can be solved with just you know
31:14 starting a neural network with a problem
31:18 and
31:19 it's a question of where we are going to
31:22 go in the next few years right
31:24 there's
31:25 i think jpg3 showed one thing is that
31:28 you can just throw raw power
31:30 and a bit of beta into the neural
31:33 network and then
31:34 you have something amazing working but
31:36 the question is where does it end right
31:39 how far can we go how many more learning
31:42 parameters we can fit into the language
31:44 model um yeah
31:47 yeah that's fine that he mentioned that
31:48 we have a question uh what is the future
31:51 of nlp um
31:53 do you think that if we have libraries
31:55 like hugging face or spacey or spacey
31:59 like because they simplify it a lot
32:01 right so they just take it and then i've
32:03 like the api of these
32:06 libraries is quite good so you can just
32:08 take and use it
32:11 do you think
32:12 having access to libraries like this
32:14 will remove
32:16 the need or to write nlp pipelines from
32:18 scratch or not
32:21 yeah i think
32:24 i mean
32:26 yes for for many tasks
32:29 like you
32:30 you can get by with those things and
32:33 um i mean what those uh like tools that
32:37 you mentioned what they are doing is
32:38 they are democratizing yeah
32:40 they are
32:41 there
32:43 they are open sourcing everything and
32:44 this is great
32:45 this is enabling like smaller teams or
32:48 smaller startups to work more easily on
32:51 ai
32:52 um
32:53 and whether that will like fully remove
32:56 the need of writing you know deepak
32:57 plans
32:58 i don't think it will it's actually very
33:00 funny i had a very similar conversation
33:03 uh five years ago and back then everyone
33:05 was talking about automl
33:07 all right automl is going to replace
33:09 data scientist automl
33:12 we're not going to need build nlp models
33:15 and that is still not the case right
33:16 five years have passed we're still
33:18 building
33:18 uh nlp pipelines um so i think this will
33:21 probably stay the same we will still
33:24 have to build led pipelines
33:26 because the
33:27 complexity will just grow and grow and
33:30 as complexity grows
33:32 you probably won't be able to catch up
33:34 with
33:35 having high level tools that uh sort of
33:38 always incorporate the latest thing
33:40 right you will still need to use lp
33:43 pipelines for building on people like
33:44 pipelines to be able to have like a
33:47 advantage or an edge
33:49 um
33:50 right papers come out you know nlp
33:53 papers high papers come out every week
33:56 and and
33:57 like new things
33:59 um
34:01 will come out very fast and the faster
34:02 you react to them the better right so
34:05 having an lp engineering team that can
34:07 easily take some some new paper and then
34:10 incorporate ideas like not the whole
34:12 thing but at least some ideas into their
34:14 current solution will be super helpful
34:16 and that's probably not always possible
34:18 with these open sources
34:21 but i guess also like in spacey there is
34:23 a method that just you know just
34:27 make things good and then it just works
34:29 but internally somewhere it uh still has
34:32 an mlp pipeline right right and then
34:35 potentially you can go deeper and then
34:37 try to uncover that and
34:39 also adjust it to whatever you need and
34:42 by the way speaking of nlp pipelines i
34:44 don't think we
34:46 mentioned what an mlp pipeline is maybe
34:48 can you tell us what what it actually is
34:50 and why uh
34:52 hugging face and spacey remove the
34:54 needle
34:55 doing that
34:57 yeah good question so i mean it
35:00 depends on how you define it my
35:02 definition would be you know if you are
35:04 an lp team building an nlp pipeline that
35:07 already starts with data right that
35:09 starts with data annotation that starts
35:11 with generating good quality data and
35:13 then refining it and the next step is
35:16 depending you know if you use ai
35:19 you build up uh basically
35:22 let's say you take something like d5 or
35:25 some other language model
35:27 and then you have to make it work for
35:29 your specific task right so you do some
35:31 task engineering basically around it and
35:34 you make it work with your specific data
35:37 input and then you also have to define
35:40 what's the outcome of that and then
35:42 you know depending on how much you want
35:44 to play around with with the
35:46 language model itself you can also in
35:48 between
35:49 work on
35:50 neural network improvements for your
35:52 specific task
35:54 then when you have that
35:56 the last bit is basically okay there's
35:59 also testing right
36:01 testing for nlp models is very important
36:03 after that comes productionizing so how
36:06 do you deliver some kind of you know a
36:09 binary model that can be used for
36:11 inference
36:12 and how do you deploy it and then in the
36:15 end how how do you
36:17 do observability around it so for me
36:19 that is the nlp pipeline that starts
36:21 with data and
36:23 ends with how do you observe how your
36:26 model performs on production
36:29 yeah okay and
36:31 so what it describes so the data
36:32 annotation data quality then task
36:34 engineering and testing the model then
36:36 productionizing model so spacey and
36:39 hugging phase don't seem to remove the
36:40 need for that you still have to do all
36:42 this task it's not like you just press a
36:44 button and all of a sudden have high
36:46 quality annotated data right you still
36:48 need yeah what they remove is this task
36:49 engineering for the most part right you
36:51 don't have to
36:52 you know uh tinker around with the
36:56 behind the scenes implementation of a
36:58 specific language model you just use it
37:01 from there
37:03 what i had in mind when i heard nlp
37:05 pipeline is um i remember using this uh
37:08 core the stanford core and rnd library
37:11 it's in java
37:12 it's a pretty old library and then
37:14 there's a class called
37:16 pipeline or nlp pipeline i don't
37:18 remember
37:19 and this pipeline so it's first it's
37:21 about
37:22 splitting the sentences so you could say
37:25 you have a paragraph and then in
37:26 paragraph you have different sentences
37:28 you want to split it and to have
37:30 separate sentences
37:31 then
37:32 you then turkey nice like you
37:35 take the sentence and break it into
37:37 multiple tokens then perhaps you want to
37:41 do i don't know remove punctuation or
37:42 not remove comprehension
37:44 and then you also want to do some
37:46 limitations stemming all these
37:48 things so this is what i thought uh when
37:52 i heard no b pipeline that is that is
37:54 what's referred to as pre-processing
37:56 right that's uh yeah i guess i i just
37:59 forgot to mention that so like
38:01 you have the data and then
38:03 how do you um make the language model or
38:07 like whatever are you using role-based
38:09 system understand the data that's where
38:11 where the step of pre-processing comes
38:12 in right this tokenization limitation it
38:15 really depends on you don't always need
38:17 all of those steps and for
38:19 uh you know
38:20 for current language models you don't
38:22 need almost any of those steps anymore
38:25 um
38:26 and like it really depends on the task
38:28 right and you're right like these
38:30 problems are mostly solved and they are
38:32 mostly solved in tools like spacey and
38:35 and hugging phase where you don't really
38:36 have to think anymore how do i tokenize
38:39 a sentence it's
38:41 done like almost fully automatically
38:43 there
38:44 and what about uh this tools like gpt3
38:47 that uh
38:48 like i guess they also remove some of
38:51 the steps uh from this pipeline as well
38:53 they make it easier right
38:56 yeah like g3 is like a whole on a whole
38:58 different level
39:00 you don't need to do anything really the
39:02 the
39:03 idea of gt3 is that it it
39:06 it's like a it's a big it's a smart
39:08 lookup table right it has seen
39:10 uh i think like 10 of the whole internet
39:13 right that's what the data set that was
39:14 used to train it and if they've seen so
39:16 much data that it has also seen
39:19 uh you know what it kind of you could
39:22 say it knows what mlp is right it knows
39:24 how to solve some tasks it knows what
39:26 the organization is it just somehow has
39:29 learned it and it's like internal
39:31 in that black box
39:33 we don't know how that actually works so
39:35 all you need to do for gt3 is just write
39:37 a prompt like you give it one example
39:40 for example you write
39:41 if you want to do sentiment analysis you
39:43 just write
39:44 a day is nice and then you write tag
39:47 positive and then you write another
39:48 sentence and say i'm sad and then
39:51 you write tag but you don't don't write
39:53 whether it's positive negative but then
39:54 the model will just auto-complete it for
39:56 you it just knows somehow that you are
39:59 asking it to do
40:00 sentiment analysis which is which is
40:02 insane and there's even like even super
40:05 ridiculous things as gp3 where
40:08 there was a paper recently where they
40:10 were exploring how well does gp3 does
40:13 translations
40:14 and basically
40:15 they uh like in the original i think gp3
40:18 paper
40:19 they just had a prompt like please
40:22 translate this sentence from english to
40:24 french and then give the sentence
40:26 and then what the what the researchers
40:28 did they they said they changed the
40:30 prompt to please translate this english
40:33 sentence as if you are a very
40:36 good french translator and then it gives
40:38 you a much better quality of translation
40:41 which is you know it blows your mind
40:43 that this is possible to state i think
40:46 you showed
40:47 in your presentation that it's possible
40:49 to translate a usual sentence into
40:53 like uh
40:54 rewrite it as if it was written by a
40:56 lawyer right right that's also in sense
40:59 it's like translating from usual uh
41:01 english to
41:03 uh
41:04 uh yeah yeah i mean this is the
41:08 you know
41:10 it's a miracle of this like gt3 like
41:13 massive language models that they
41:15 somehow have internalized all of those
41:17 things without
41:19 you know we didn't have to teach them
41:21 what is tokenization or what is even
41:22 what is translation they just somehow
41:24 learned it
41:25 and
41:26 that's you know the question now is you
41:28 know how far can we get with this right
41:30 can we just get away with throwing more
41:33 compute power bigger gpus and more data
41:36 and
41:36 expect it to work better and better
41:39 and when does it become creepy
41:41 yeah kill it is already kind of like i
41:44 have goosebumps sometimes when i
41:46 watch some of these demos like they
41:48 basically like as you said it's a big
41:50 lookup table and probably it already
41:52 knows everything what is there on the
41:54 internet about you about me about
41:55 everyone who is watching that right if
41:57 you ever left a footprint somewhere on
42:00 the internet it saw it and it knows that
42:03 yeah it was probably
42:05 i remember like it was uh
42:07 seeing a demo that it's possible to get
42:09 like emails of people yeah right this
42:12 was even possible with like gpt2
42:14 like you could just start writing an
42:17 address and then it would auto complete
42:18 it was with the actual name of someone
42:20 who lives at that address which is it's
42:22 crazy
42:24 that's creepy but i guess like if you
42:26 use gpd3 then you still have this
42:28 component of task engineering just
42:31 it's on the basis now it's a very
42:34 simplified number
42:35 like you don't need to do that much
42:37 right you just need to figure out what
42:39 is the best way to tell the model to do
42:42 your task
42:43 and how much data you actually how to
42:45 give it and you even you know you could
42:48 even get by with like just a few
42:49 examples for some tasks for more
42:51 complicated tasks i can imagine you can
42:53 still need like a very well annotated
42:55 data set
42:57 but it's not cheap right it's expensive
42:59 you cannot just uh you know just use it
43:02 and rely on this completely and gpd3
43:05 yeah i mean uh i don't know like they
43:07 are trying to open sources now or
43:09 something i don't know but i think you
43:11 still have to pay like for for tokens to
43:13 be able to use it for each request you
43:15 you need to pay
43:17 yeah so it is definitely expensive but
43:19 it's you know um
43:21 it's not just a problem with that you
43:23 have to pay for it but it's a problem
43:24 that you have zero control of what it's
43:27 doing and why it's doing it like if
43:29 there's let's say if someone
43:32 uh
43:33 finds a way to buy us gt3 very easily
43:37 then they can easily reproduce that on
43:41 your solution that you build based on
43:42 your history so you you have like zero
43:44 control of that
43:47 that's why
43:48 you know
43:49 that's why not not everyone jumps on on
43:52 this like not everyone's using gt3 i
43:54 think it it's
43:55 super good to build an mvp of some sort
43:59 right you can very quickly
44:01 you know
44:02 use gp3 to build out
44:05 some kind of demo
44:07 and then sort of validate it and then
44:09 i've seen a lot of uh companies do that
44:12 basically
44:13 after they validated their demo with
44:14 something easy like gpg whatever gt2
44:17 even and they just say okay now we build
44:20 something that we are in control of we
44:23 build our own lte pipeline and we know
44:25 how it works we have control over it to
44:27 some extent
44:29 and i guess you can use it for updating
44:31 your data as well right
44:33 so for collecting your initial version
44:35 of the data set yeah i guess i i
44:38 actually haven't seen
44:40 anyone using gp3
44:42 for data annotation
44:43 i don't know how well that actually
44:45 works that's again i think we have a
44:46 pilot project on that i think it worked
44:48 well i wasn't involved in that project i
44:51 just heard that uh we tried this and it
44:54 worked uh well and then basically
44:55 trained a simpler model on the output of
44:58 gpt3 yeah so something like logistic
45:01 regression or something like that so
45:02 something super simple it was a
45:04 classification problem
45:06 nice yeah yeah i didn't even think about
45:08 that
45:10 so because like writing all these rules
45:12 for extracting data for information
45:14 extraction so
45:15 uh
45:17 like oh elix is a place where people can
45:20 exchange like it's basically online
45:22 marketplace so you have listings and
45:24 listings have descriptions and you want
45:27 to extract some information from there
45:29 and you mentioned that information
45:31 extraction is a complex task
45:33 right and we tried to use gpg3 i think
45:36 for
45:38 making this for extracting this and then
45:40 using these things as labels and then
45:41 fitting simple model
45:43 yeah
45:44 but i only saw demos so i wasn't taking
45:46 part of that but that's a cool
45:48 interesting question
45:50 but i think we talked about this already
45:52 and we kind of
45:54 mentioned that so the question we have
45:56 is now we have this gpt3
45:59 does it mean that we no longer need
46:00 things like hacking face
46:02 spacey
46:04 and so on or we still need to so would
46:06 you still use hugging face if you had
46:08 access to gpd3 now
46:13 yeah i
46:14 i would say yes because chip juicer is
46:16 still is not able to solve everything it
46:18 is kind of able to solve
46:20 most of the tasks
46:22 to a good extent but the question is
46:26 can it actually solve everything
46:28 you need to be able to
46:30 for it to be used in production right
46:32 for you to be actually given to the
46:34 clients and i had to think that's the
46:36 case right now um and
46:39 you know and even if you do that there
46:42 is a lot of danger
46:45 that
46:46 you know it will just go wrong when you
46:48 and you have no idea how to control it
46:50 right it
46:51 becomes biased
46:52 to some specific user group or something
46:56 yeah i'm wondering what would
46:58 then would happen like let's say if uh
47:00 open ai finds out that
47:03 it's broken because somebody you know
47:05 messed up with this and they decided
47:07 okay now it's bad let's shut it down and
47:10 then everyone who relies on this uh
47:12 yeah they can seem sorry
47:15 yeah that's why um you know that there's
47:18 a group uh
47:20 like a
47:22 open source engineering group called uh
47:26 euler ai although ai and basically they
47:29 are working on
47:31 rebuilding gt3 from scratch and so we
47:33 have now things like gpg j and gp neo
47:36 it's like smaller version of gt3 but
47:39 they are fully open source and anyone
47:40 can use them
47:42 and you also can look up sort of how
47:44 they build it right
47:46 so so that's a good that's a step in the
47:48 right direction and that's
47:50 um you know
47:51 i think this will always be the case
47:53 even if openai comes out with gpg4 and
47:56 it's again proprietary there will again
47:58 be someone who will be able eventually
48:00 to crack the code and sort of open
48:02 source it forever
48:04 yeah interesting and so another question
48:06 we have is uh
48:09 do what do you think nlp is more is it
48:11 more about like writing better pipelines
48:13 and uh improving these pipelines and
48:15 then implementing some research papers
48:17 or it's more like theoretical linguistic
48:20 knowledge in a planet i think you at the
48:22 beginning you mentioned that that you
48:24 know you can get
48:26 quite far
48:27 without
48:29 much linguistics knowledge so what do
48:31 you think nlp actually is is it about
48:33 applying these libraries or is it buying
48:35 is it about about using linguistics uh
48:38 knowledge and appliances that's a good
48:40 question i think uh
48:42 it depends if you're talking about
48:43 industry or like
48:45 academia right so if we're talking about
48:47 industry
48:48 and like let's say smaller companies or
48:50 small startups
48:52 you know
48:53 for them there's no sort of financial in
48:55 incentive to
48:57 innovate in terms of linguistic
48:59 application of nlp right they are more
49:01 interested in building this nlp
49:03 pipelines and building a product out of
49:05 them and that's where tools like hacking
49:07 fashions basically come in that help
49:09 them a lot where we are talking maybe a
49:11 bigger companies like let's say google i
49:13 know google has
49:14 you know at google brain for example
49:16 there are people who are working on that
49:18 they're working on
49:20 linguistics applications or nlp and a
49:23 lot of academia also works on that right
49:25 because
49:26 um
49:27 you know they will not you know we will
49:30 probably from academic perspective we
49:32 will not advance nlp
49:34 if we only work on
49:36 building bigger uh
49:39 sort of ai models we really need to to
49:42 see how else we can incorporate the
49:44 linguistic knowledge into ai research
49:46 and that's where academia is actually
49:48 doing a lot of that there are a lot of
49:49 universities who are working
49:51 on that specific part
49:53 so basically are saying the future of
49:54 nlp is not just throwing more hardware
49:57 yeah at
49:58 gpt3 whatever gpt4 or i don't know if
50:01 something if it's a thing but more like
50:05 okay now we learned how to throw
50:07 hardware at
50:09 all the internet and then make it learn
50:11 it how can we now simplify it right so
50:13 how can we now uh achieve similar thing
50:16 but without having to
50:19 burn
50:20 like a lot of
50:22 gps
50:23 yeah yeah i mean this
50:25 probably i mean you could say there's
50:27 like a race going on now right
50:29 organizations like open ai are trying to
50:32 push the limits of just you know
50:33 building bigger and bigger language
50:35 models whereas you know some
50:36 universities are
50:38 trying to to
50:40 rely more on linguistics right and it
50:43 it we i i don't know what will come out
50:46 of that right who will win and if there
50:48 will be a winner or always will be like
50:51 that now ideally uh i've uh there's a ln
50:55 lp research institute and i know they
50:59 are exploring a lot of this
51:02 how do you merge
51:04 linguistics with ai to build better ai
51:08 model and better language models and
51:09 this is i think this is the
51:12 right direction to go into because
51:14 this will definitely help advance the
51:16 field
51:18 yeah they this allen ai they do quite a
51:20 lot of work in the nlp right
51:23 right yeah yeah they they yeah right so
51:25 the institute is called ellen ai i think
51:27 and they have also like a
51:30 open source toolkit called lnop
51:32 yeah because i remember
51:35 seeing competitions on kaggle from them
51:37 it was about uh
51:39 like it was actually my first kaggle
51:40 competition i ever took part in it was
51:43 about
51:44 so you have uh
51:46 in
51:47 school you have these multiple choice
51:48 questions so you have a question and
51:50 then you have four answers
51:52 and
51:53 the task that they had is built a model
51:56 that would select the right answer so
51:58 you have a model you have a question you
52:00 have four answers
52:02 and the task was to
52:04 rank them basically to give the correct
52:06 answer
52:07 and then yeah it was
52:09 it was some unusual not a usual
52:12 sharing problem let's say
52:14 so it was a lot about indexing wikipedia
52:17 and then using this knowledge base to
52:19 rank all these answers
52:21 so yeah that was a quite fun one
52:24 yeah i mean you know
52:26 ai and lt also incorporates many other
52:28 things like
52:30 um you know net like graph they build a
52:34 knowledge graph and things like that
52:35 that's also all part of nlp
52:38 yeah
52:39 so i'm
52:40 so that competition was um you know six
52:44 years ago
52:46 do you think now with all these gpt3 um
52:50 things uh is it a solve problem now can
52:52 we just uh
52:54 you know answer multiple choice
52:55 questions or it's still not a solved
52:57 problem
52:59 i i don't think so i don't think there
53:01 is a
53:02 any problem we have fully solved right
53:05 you know some
53:06 you know there are papers that state
53:09 some ai models are as good as humans or
53:11 better as humans but this is all
53:13 evaluated on a very small subset of some
53:16 kind of data right it's really hard to
53:17 say whether it's actually true or not so
53:20 it's i wouldn't say we solved all of
53:23 those problems
53:24 yeah and even if we did we probably
53:26 would have solved it only for english
53:28 but there are so many other languages we
53:30 need to solve it
53:31 yeah what do you think about language
53:33 translations because there is a question
53:35 uh that it seems to be one of the
53:38 toughest nlp tasks so do you think we
53:41 will be able to achieve human level
53:42 results there in in language translation
53:47 yeah good question um
53:50 yeah you know
53:52 language translation itself i i knew
53:55 someone who worked at darpa in the u.s
53:58 and basically language toleration
54:01 mostly come or came to us from
54:04 solving these problems for
54:06 you know military purposes and this is
54:08 where it mostly started i think
54:11 now you actually have like more um you
54:13 know
54:14 product based solution right so you have
54:17 you know google translate of course you
54:18 also have a depot or dpl
54:21 which is
54:23 trying to solve this problem and
54:25 i think the path to solve it is to
54:29 try to make it an actual product that
54:31 can make you money and that will
54:33 get you more funds to
54:36 put it back into research and then
54:38 improve it even more and more this is uh
54:40 i think this is the way we are going
54:42 right now right google is investing a
54:44 lot into translation there are other
54:46 companies investing a lot of that but we
54:48 will be able to solve it fully
54:50 i don't know it's hard to say but i
54:52 there are more and more like
54:54 products coming out of that
54:57 um
54:58 but
54:59 right now i think
55:02 if you look at that
55:03 translation task we are kind of good for
55:06 maybe like
55:08 eight to ten languages and that's it
55:09 like it's mostly european languages
55:11 maybe chinese and you know of course
55:13 english it's kind of okay it can be used
55:15 but
55:16 you know if you go beyond that we're far
55:18 far away from being able to solve that
55:21 issue and that mainly comes from the
55:22 fact that we don't have enough data for
55:24 its writers
55:26 it's not enough
55:27 textual data to train ai on
55:30 but also i'm quite impressed now with
55:33 the results i get from google translate
55:35 as a user yeah because
55:37 like i live in germany in germany people
55:39 use german my german is not that good so
55:41 what i usually do is i
55:44 write something in google translate
55:45 usually i use english because
55:47 translating from english to german works
55:50 much better than translating from
55:51 russian to german even though now last
55:54 year
55:55 it really works it works really well
55:58 also from russian to german
56:00 even though i think english and german
56:02 are a lot closer
56:04 to each other than russian and german it
56:06 works really well
56:08 and
56:10 eight years ago when i lived in poland i
56:12 needed to translate from polish to
56:14 russia and these are very similar
56:16 languages right they are very close but
56:18 i think what happened internally is they
56:20 translated first from polish to english
56:22 and from english to russian and then a
56:24 lot of things would be lost in
56:26 translation here right but now if i need
56:29 to translate something from polish to
56:30 russian it's very good and uh
56:32 translation from ukrainian to russian
56:34 works like as if a person translated
56:38 it works really well so
56:40 like i sometimes delete websites uh in
56:44 ukrainian so there is a lot of content
56:46 in russian and some articles in
56:47 ukrainian and then i would understand
56:50 ukrainian but sometimes it's just
56:51 simpler to translate
56:52 and it works really well like as if it
56:55 was written in russian so that's that's
56:57 really impressive so yeah i i think
57:00 google translate actually switched to
57:02 using these like language models that
57:04 they trained uh i don't know how many
57:05 years ago but it is like four or five
57:07 years ago and that's where the quality
57:09 was like really visibly much better
57:12 right and you know google can do it
57:14 because they have so much data right
57:16 they index the whole internet and it's
57:18 easier for them to train just a language
57:21 model for it and uh i think what
57:23 translations now like the top solutions
57:26 are all
57:26 pure ai and i don't think there's much
57:28 linguistics in that
57:31 yeah but i guess if i try to translate
57:33 from russian to
57:35 uh you know some
57:36 indian language like uh then
57:39 maybe it's not a very common uh
57:41 yeah that translation player okay i
57:44 wanted to ask you about uh so i just
57:46 noticed that we don't have a lot of time
57:48 left and okay there was something i
57:49 really wanted to ask you so i wanted to
57:51 ask you about your project so you have a
57:53 project on your github called nlp pandec
57:56 right did they pronounce it correctly
57:58 and it will be pandect uh i guess yeah i
58:00 don't know how to pronounce it because
58:02 it's also old greek
58:03 i i think it's pandecto
58:06 can you tell us more about this project
58:08 yeah sure sure this is uh something i
58:10 started last year like during lockdown
58:13 because i was bored
58:15 and so uh the idea was uh
58:18 right we all know there are like these
58:20 awesome lists right this is like a very
58:22 typical thing on github where people
58:25 create like a list of things and
58:27 nice links so um i wanted to do
58:29 something like that for for nlp there
58:31 were already some like awesome list
58:33 final key but i just thought they are
58:36 like a bit bland there's just a list of
58:38 urls so i tried to
58:41 to make it more like user-friendly so i
58:44 came up with this idea to to have like a
58:46 different name for it right pandect
58:48 means encyclopedia you know on all the
58:50 greek
58:51 and uh
58:52 i also created some like visuals around
58:55 it so if you go to the nld bandicon
58:57 github all the sections are done uh
59:00 with nice fonts and there are all the
59:03 uh sort of symbols of gods and and
59:06 things like that uh so kind of giving it
59:09 a a a theme and then what i did was that
59:12 is also try to really uh
59:15 like fine grained classification of
59:18 things to put there like for if you go
59:20 to the nlp pendant you can just
59:23 easily search for a specific nlp task
59:25 and then you have a list of
59:27 uh of i don't know tutorials you have a
59:29 separate list of books you can read on
59:31 that or a separate list of github
59:33 repositories you can look at and then in
59:36 that i also did like
59:38 an analysis of all nlp tools of all ml
59:41 tools so all of that you can find there
59:43 and it doesn't end with nlp pandect so
59:46 as i work also with many other things i
59:48 have two more projects related to this
59:50 so there's a microservices pandect so
59:53 there's a lot of information there about
59:56 how to build and maintain microservices
59:59 how to do devops around them and there's
1:00:01 a one i started more recently is for
1:00:04 engineering managers so there's
1:00:05 engineering manager
1:00:07 uh pandex which is
1:00:09 incorporates a lot of resources for
1:00:11 leadership how do you lead technical
1:00:14 teams
1:00:15 how do you you know solve people issues
1:00:18 and things like that
1:00:20 okay thanks i just realized there was so
1:00:22 much i wanted to ask you i think we
1:00:24 covered only like half of that but we
1:00:27 talked about other things so
1:00:29 yeah that was that was fun thanks a lot
1:00:31 for joining us today thanks a lot for
1:00:33 sharing all everything with us yeah
1:00:35 thank you for inviting me by the way so
1:00:37 if somebody wants to reach out to you
1:00:39 how can they do that yeah so the best
1:00:41 way is to find me on linkedin that's
1:00:44 where i mostly act to
1:00:46 um yeah i'm also on twitter
1:00:49 uh
1:00:50 but i don't post that much so linkedin
1:00:52 is probably the best way
1:00:54 okay yeah thanks a lot thanks for
1:00:55 joining us today and thanks everyone for
1:00:57 asking questions uh
1:00:59 yeah so have a great rest of your day
1:01:02 great thanks a lot