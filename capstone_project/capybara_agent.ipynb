{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Capybara Wikipedia Agent\n",
        "\n",
        "This notebook demonstrates a Pydantic AI agent that can:\n",
        "1. Fetch and analyze Wikipedia pages\n",
        "2. Index multiple related pages\n",
        "3. Search across the indexed content to answer questions\n",
        "\n",
        "Based on week2/pydantic-ai-intro.ipynb and agents examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import requests\n",
        "from pydantic_ai import Agent\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple in-memory storage for fetched pages and summaries\n",
        "page_store = {}\n",
        "summaries_store = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Tools for the Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_web_page(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch the content of a web page.\n",
        "    \n",
        "    Args:\n",
        "        url: The URL of the web page to fetch\n",
        "        \n",
        "    Returns:\n",
        "        The HTML content of the page, or an error message if fetch fails\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add User-Agent header to avoid 403 errors from Wikipedia\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        \n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        # Store the page content\n",
        "        page_store[url] = response.text\n",
        "        \n",
        "        # Return a summary of what was fetched\n",
        "        return f\"Successfully fetched {url}. Content length: {len(response.text)} characters. Page stored.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching {url}: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_summary(title: str, summary: str) -> str:\n",
        "    \"\"\"\n",
        "    Save a summary to the summaries store.\n",
        "    \n",
        "    Args:\n",
        "        title: Title of the document or page summarized\n",
        "        summary: The summary text to save\n",
        "        \n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    entry = {\n",
        "        \"title\": title,\n",
        "        \"summary\": summary,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    summaries_store.append(entry)\n",
        "    return f\"Saved summary for: {title}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_content(query: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Search through all stored page content for relevant information.\n",
        "    \n",
        "    Args:\n",
        "        query: The search query string\n",
        "        \n",
        "    Returns:\n",
        "        List of search results with URL and relevant excerpts\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    for url, content in page_store.items():\n",
        "        content_lower = content.lower()\n",
        "        if query_lower in content_lower:\n",
        "            # Find the context around the match\n",
        "            idx = content_lower.find(query_lower)\n",
        "            start = max(0, idx - 200)\n",
        "            end = min(len(content), idx + len(query) + 200)\n",
        "            excerpt = content[start:end]\n",
        "            \n",
        "            results.append({\n",
        "                \"url\": url,\n",
        "                \"excerpt\": excerpt,\n",
        "                \"relevance\": \"high\" if query_lower in content_lower[:500] else \"medium\"\n",
        "            })\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Agent\n",
        "\n",
        "We'll use iterative prompt improvement to get the agent to use the tools correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial agent instructions - this will be refined based on behavior\n",
        "instructions = \"\"\"\n",
        "You are a helpful research assistant that can fetch web pages, analyze content, and search through information.\n",
        "\n",
        "IMPORTANT: When a user asks about a web page:\n",
        "1. ALWAYS use the fetch_web_page tool first to get the page content\n",
        "2. Read and summarize the content\n",
        "3. Use the save_summary tool to store your summary\n",
        "4. Report what you found to the user\n",
        "\n",
        "When searching for information:\n",
        "1. Use the search_content tool with relevant keywords from the question\n",
        "2. Look through the results carefully\n",
        "3. Synthesize information from multiple sources\n",
        "4. Provide a comprehensive answer citing your sources\n",
        "\n",
        "Be thorough and use the tools available to you. Don't skip tool usage.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the agent with all tools\n",
        "agent = Agent(\n",
        "    name='research_assistant',\n",
        "    instructions=instructions,\n",
        "    tools=[fetch_web_page, save_summary, search_content],\n",
        "    model='openai:gpt-4o-mini'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: Log Tool Calls\n",
        "\n",
        "First, let's add a helper to see what the agent is doing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to log tool calls - must be async\n",
        "async def log_function_calls(run_ctx, event_stream):\n",
        "    \"\"\"Log all function calls and their results\"\"\"\n",
        "    async for event in event_stream:\n",
        "        try:\n",
        "            if hasattr(event, 'is_function_call') and event.is_function_call():\n",
        "                print(f\"üîß TOOL CALL: {event.content.function_name}({event.content.arguments})\")\n",
        "            elif hasattr(event, 'is_function_result') and event.is_function_result():\n",
        "                result = event.content.result\n",
        "                if isinstance(result, str) and len(result) > 200:\n",
        "                    print(f\"‚úÖ TOOL RESULT: {result[:200]}...\")\n",
        "                else:\n",
        "                    print(f\"‚úÖ TOOL RESULT: {result}\")\n",
        "            elif hasattr(event, 'is_response') and event.is_response():\n",
        "                print(f\"üìù RESPONSE: {event.content}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error logging event: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Question 5: Fetch and Analyze a Wikipedia Page\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Provide a short summary of this page and store that summary: https://en.wikipedia.org/wiki/Capybara\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "I have summarized the Wikipedia page on Capybaras. Here's the summary:\n",
            "\n",
            "**Capybara**: The Capybara (Hydrochoerus hydrochaeris) is the largest rodent in the world, native to South America. These semi-aquatic mammals are found in groups near bodies of water and can weigh up to 66 kilograms (146 lb). Capybaras have a social structure, living in groups of 10 to 20 individuals, and are herbivorous, feeding mainly on grasses and aquatic plants. They have adaptations for swimming, including webbed feet and a streamlined body. Their conservation status is currently listed as Least Concern, although habitat loss and hunting pose threats.\n",
            "\n",
            "This summary has been stored successfully.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Clear storage for clean test\n",
        "page_store.clear()\n",
        "summaries_store.clear()\n",
        "\n",
        "# Ask the question\n",
        "question = \"Provide a short summary of this page and store that summary: https://en.wikipedia.org/wiki/Capybara\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display all saved summaries\n",
        "print(\"=\"*80)\n",
        "print(\"ALL SAVED SUMMARIES:\")\n",
        "print(\"=\"*80)\n",
        "for i, summary in enumerate(summaries_store, 1):\n",
        "    print(f\"\\n{i}. {summary['title']}\")\n",
        "    print(f\"   {summary['summary'][:200]}...\")\n",
        "    print(f\"   Timestamp: {summary['timestamp']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Provide a short summary of the following pages and stores those summaryies:\n",
            "\n",
            " Lesser capybara ‚Äî https://en.wikipedia.org/wiki/Lesser_capybara\n",
            "\n",
            "Hydrochoerus (genus) ‚Äî https://en.wikipedia.org/wiki/Hydrochoerus\n",
            "\n",
            "Neochoerus (extinct genus related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus\n",
            "\n",
            "Caviodon (extinct genus of rodents related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Caviodon\n",
            "\n",
            "Neochoerus aesopi (extinct species close to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus_aesopi\n",
            "\n",
            "\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "I have successfully fetched and summarized the requested pages. Here are the summaries:\n",
            "\n",
            "1. **Lesser Capybara**: The lesser capybara (Hydrochoerus isthmius) is a smaller species of capybara found in Colombia and Venezuela. Typically around 75 cm long, they inhabit wetlands, are social creatures living in groups, and primarily feed on grasses and aquatic plants.\n",
            "\n",
            "2. **Hydrochoerus (genus)**: Hydrochoerus is a genus of large rodents in the Caviidae family, comprising two living species: the common and lesser capybaras. These semi-aquatic animals are social, often found in groups near water bodies, and primarily eat grasses and aquatic plants.\n",
            "\n",
            "3. **Neochoerus (extinct genus related to capybaras)**: Neochoerus is an extinct genus of capybaras from the Pleistocene epoch in North America, related to modern capybaras. Fossils indicate they were similar in size and ecology, likely inhabiting wetland environments and having similar diets.\n",
            "\n",
            "4. **Caviodon (extinct genus of rodents related to capybaras)**: Caviodon is an extinct genus of rodents from the family Caviidae, related to capybaras, which lived during the Miocene epoch. Fossil evidence suggests their adaptability to varied environments and similarities to modern cavy species.\n",
            "\n",
            "5. **Neochoerus aesopi (extinct species close to capybaras)**: Neochoerus aesopi is an extinct Pleistocene species of capybara from North America, known from fossil remains. It is significant for understanding the evolutionary history of Neochoerus and its relationship to today's capybaras.\n",
            "\n",
            "Feel free to ask if you need further information!\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Call for Question 6 \n",
        "# Clear storage for clean test\n",
        "page_store.clear()\n",
        "summaries_store.clear()\n",
        "\n",
        "# Ask the question\n",
        "question = '''Provide a short summary of the following pages and stores those summaryies:\n",
        "\n",
        " Lesser capybara ‚Äî https://en.wikipedia.org/wiki/Lesser_capybara\n",
        "\n",
        "Hydrochoerus (genus) ‚Äî https://en.wikipedia.org/wiki/Hydrochoerus\n",
        "\n",
        "Neochoerus (extinct genus related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus\n",
        "\n",
        "Caviodon (extinct genus of rodents related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Caviodon\n",
        "\n",
        "Neochoerus aesopi (extinct species close to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus_aesopi\n",
        "\n",
        "'''\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: \n",
            "\n",
            "Based on the summaries you created and the following pages,\n",
            "provide a short summary of the threats to the capybara populations.\n",
            "\n",
            "Capybara ‚Äî https://en.wikipedia.org/wiki/Capybara\n",
            "\n",
            "Lesser capybara ‚Äî https://en.wikipedia.org/wiki/Lesser_capybara\n",
            "\n",
            "Hydrochoerus (genus) ‚Äî https://en.wikipedia.org/wiki/Hydrochoerus\n",
            "\n",
            "Neochoerus (extinct genus related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus\n",
            "\n",
            "Caviodon (extinct genus of rodents related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Caviodon\n",
            "\n",
            "Neochoerus aesopi (extinct species close to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus_aesopi\n",
            "\n",
            "\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "Based on the information gathered from the Wikipedia pages, here is a summary of the threats to capybara populations:\n",
            "\n",
            "1. **Habitat Loss**: Capybaras face significant threats from habitat destruction, primarily due to agricultural expansion and urban development. As their natural environments are altered or destroyed, their populations decline.\n",
            "\n",
            "2. **Hunting**: They are hunted for their meat and skin, which poses a direct threat to their survival. This hunting pressure can be especially intense in regions where they are considered a food source.\n",
            "\n",
            "3. **Competition with Livestock**: As agricultural practices grow, capybaras may experience increased competition for resources like food and water from livestock.\n",
            "\n",
            "4. **Environmental Changes**: Changes in environmental conditions, possibly influenced by climate change, can further stress capybara populations by altering their habitats and availability of essential resources.\n",
            "\n",
            "5. **Exotic Trade**: Capybaras are sometimes captured for the exotic pet trade, which can threaten local populations by removing individuals from the wild.\n",
            "\n",
            "These factors collectively contribute to a reduction in capybara populations, highlighting the need for conservation efforts to protect their habitats and manage hunting practices effectively.\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Verification:\n",
            "Pages fetched: ['https://en.wikipedia.org/wiki/Neochoerus', 'https://en.wikipedia.org/wiki/Caviodon', 'https://en.wikipedia.org/wiki/Lesser_capybara', 'https://en.wikipedia.org/wiki/Hydrochoerus', 'https://en.wikipedia.org/wiki/Neochoerus_aesopi', 'https://en.wikipedia.org/wiki/Capybara']\n",
            "Summaries saved: 6\n",
            "  - Capybara\n",
            "  - Lesser Capybara\n",
            "  - Hydrochoerus\n",
            "  - Caviodon\n",
            "  - Neochoerus aesopi\n",
            "  - Neochoerus\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Call for Question 6b \n",
        "# DON'T clear storage - we want to keep the indexed pages from Question 6a\n",
        "# This will search through all previously indexed pages\n",
        "\n",
        "# Ask the question about threats\n",
        "question = \"What are the threats to capybara populations?\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
