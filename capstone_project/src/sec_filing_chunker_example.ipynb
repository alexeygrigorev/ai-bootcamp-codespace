{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SEC Filing Download, Parsing, and Chunking\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Download SEC filings using the EDGAR client\n",
        "2. Parse XML/HTML documents from SEC filings\n",
        "3. Create intelligent chunks for RAG systems\n",
        "4. Store chunks in a vector database\n",
        "\n",
        "Based on techniques from week1/docs.py and week1/intelligent-chunking.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from sec_edgar_client import SECEdgarClient\n",
        "from sec_xml_parser import parse_sec_filing, chunk_sec_documents, SECXMLParser\n",
        "import json\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the SEC EDGAR Client\n",
        "\n",
        "The client will automatically read your `SEC_USER_AGENT` from the `.env` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize client - reads SEC_USER_AGENT from .env automatically\n",
        "client = SECEdgarClient()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Fetch Filings\n",
        "\n",
        "Get recent filings for a company\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Apple's recent 10-K filings\n",
        "apple_cik = \"320193\"\n",
        "filings = client.fetch_filings(apple_cik, years=3)\n",
        "\n",
        "# Filter for 10-K annual reports\n",
        "ten_k_filings = [f for f in filings if f['form'] == '10-K']\n",
        "\n",
        "print(f\"Found {len(ten_k_filings)} 10-K filings\")\n",
        "\n",
        "# Show the most recent filing\n",
        "if ten_k_filings:\n",
        "    latest = ten_k_filings[0]\n",
        "    print(f\"\\nMost recent 10-K:\")\n",
        "    print(f\"  Date: {latest['filing_date']}\")\n",
        "    print(f\"  Accession: {latest['accession_number']}\")\n",
        "    print(f\"  Document: {latest['primary_document']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Download and Parse a Filing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the most recent 10-K\n",
        "if ten_k_filings:\n",
        "    filing = ten_k_filings[0]\n",
        "    \n",
        "    # Download to a directory\n",
        "    output_dir = \"sec_downloads\"\n",
        "    Path(output_dir).mkdir(exist_ok=True)\n",
        "    \n",
        "    file_path = client.download_filing_document(\n",
        "        accession_number=filing['accession_number'],\n",
        "        primary_document=filing['primary_document'],\n",
        "        cik=apple_cik,\n",
        "        output_dir=output_dir\n",
        "    )\n",
        "    \n",
        "    print(f\"Downloaded to: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse the downloaded document\n",
        "if file_path:\n",
        "    parser = SECXMLParser()\n",
        "    parsed_doc = parse_sec_filing(file_path, document_name=filing['primary_document'])\n",
        "    \n",
        "    print(f\"Parsed document: {parsed_doc['document_name']}\")\n",
        "    print(f\"Filing type: {parsed_doc.get('filing_type', 'Unknown')}\")\n",
        "    print(f\"Number of sections: {len(parsed_doc.get('sections', []))}\")\n",
        "    \n",
        "    # Show first few sections\n",
        "    for i, section in enumerate(parsed_doc.get('sections', [])[:3]):\n",
        "        print(f\"\\nSection {i+1}: {section.get('title', 'Untitled')}\")\n",
        "        print(f\"  Length: {len(section.get('content', ''))} chars\")\n",
        "        print(f\"  Preview: {section.get('content', '')[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Intelligent Chunks\n",
        "\n",
        "Use the chunking functions to split the document into manageable pieces for RAG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create chunks from the parsed document\n",
        "# Adjust size and step for your use case:\n",
        "# - size: max characters per chunk\n",
        "# - step: overlap between chunks (for context preservation)\n",
        "\n",
        "chunks = chunk_sec_documents(\n",
        "    [parsed_doc],\n",
        "    size=2000,      # Max 2000 characters per chunk\n",
        "    step=1000,      # 1000 character overlap between chunks\n",
        "    chunk_by_section=True  # Preserve section boundaries\n",
        ")\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks\")\n",
        "print(f\"\\nFirst 3 chunks:\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\nChunk {i+1}:\")\n",
        "    print(f\"  Section: {chunk.get('section_title', 'N/A')}\")\n",
        "    print(f\"  Content length: {len(chunk.get('content', ''))}\")\n",
        "    print(f\"  Start position: {chunk.get('start', 0)}\")\n",
        "    print(f\"  Preview: {chunk.get('content', '')[:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare Chunks for Vector Database\n",
        "\n",
        "Add metadata and prepare for embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhance chunks with metadata for RAG\n",
        "enhanced_chunks = []\n",
        "for i, chunk in enumerate(chunks):\n",
        "    enhanced_chunk = {\n",
        "        'id': f\"{parsed_doc['document_name']}_chunk_{i}\",\n",
        "        'content': chunk.get('content', ''),\n",
        "        'metadata': {\n",
        "            'document_name': parsed_doc['document_name'],\n",
        "            'filing_type': parsed_doc.get('filing_type', 'Unknown'),\n",
        "            'section_title': chunk.get('section_title', 'Untitled'),\n",
        "            'filing_date': filing['filing_date'],\n",
        "            'cik': apple_cik,\n",
        "            'form': filing['form'],\n",
        "            'start_pos': chunk.get('start', 0),\n",
        "            'chunk_index': i\n",
        "        }\n",
        "    }\n",
        "    enhanced_chunks.append(enhanced_chunk)\n",
        "\n",
        "print(f\"Prepared {len(enhanced_chunks)} enhanced chunks\")\n",
        "\n",
        "# Show example\n",
        "example = enhanced_chunks[0]\n",
        "print(f\"\\nExample chunk metadata: {json.dumps(example['metadata'], indent=2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Save Chunks (Optional)\n",
        "\n",
        "Save for later use or batch processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save chunks to JSON file\n",
        "output_file = f\"chunks_{parsed_doc['document_name']}.json\"\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(enhanced_chunks, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Saved {len(enhanced_chunks)} chunks to {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
