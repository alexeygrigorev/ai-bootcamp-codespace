{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Capybara Wikipedia Agent\n",
        "\n",
        "This notebook demonstrates a Pydantic AI agent that can:\n",
        "1. Fetch and analyze Wikipedia pages\n",
        "2. Index multiple related pages\n",
        "3. Search across the indexed content to answer questions\n",
        "\n",
        "Based on week2/pydantic-ai-intro.ipynb and agents examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import requests\n",
        "from pydantic_ai import Agent\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple in-memory storage for fetched pages and summaries\n",
        "page_store = {}\n",
        "summaries_store = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Tools for the Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_web_page(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetch the content of a web page.\n",
        "    \n",
        "    Args:\n",
        "        url: The URL of the web page to fetch\n",
        "        \n",
        "    Returns:\n",
        "        The HTML content of the page, or an error message if fetch fails\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Add User-Agent header to avoid 403 errors from Wikipedia\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        \n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        \n",
        "        # Store the page content\n",
        "        page_store[url] = response.text\n",
        "        \n",
        "        # Return a summary of what was fetched\n",
        "        return f\"Successfully fetched {url}. Content length: {len(response.text)} characters. Page stored.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching {url}: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_summary(title: str, summary: str) -> str:\n",
        "    \"\"\"\n",
        "    Save a summary to the summaries store.\n",
        "    \n",
        "    Args:\n",
        "        title: Title of the document or page summarized\n",
        "        summary: The summary text to save\n",
        "        \n",
        "    Returns:\n",
        "        Confirmation message\n",
        "    \"\"\"\n",
        "    entry = {\n",
        "        \"title\": title,\n",
        "        \"summary\": summary,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    summaries_store.append(entry)\n",
        "    return f\"Saved summary for: {title}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_content(query: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Search through all stored page content for relevant information.\n",
        "    \n",
        "    Args:\n",
        "        query: The search query string\n",
        "        \n",
        "    Returns:\n",
        "        List of search results with URL and relevant excerpts\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    for url, content in page_store.items():\n",
        "        content_lower = content.lower()\n",
        "        if query_lower in content_lower:\n",
        "            # Find the context around the match\n",
        "            idx = content_lower.find(query_lower)\n",
        "            start = max(0, idx - 200)\n",
        "            end = min(len(content), idx + len(query) + 200)\n",
        "            excerpt = content[start:end]\n",
        "            \n",
        "            results.append({\n",
        "                \"url\": url,\n",
        "                \"excerpt\": excerpt,\n",
        "                \"relevance\": \"high\" if query_lower in content_lower[:500] else \"medium\"\n",
        "            })\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Agent\n",
        "\n",
        "We'll use iterative prompt improvement to get the agent to use the tools correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial agent instructions - this will be refined based on behavior\n",
        "instructions = \"\"\"\n",
        "You are a helpful research assistant that can fetch web pages, analyze content, and search through information.\n",
        "\n",
        "IMPORTANT: When a user asks about a web page:\n",
        "1. ALWAYS use the fetch_web_page tool first to get the page content\n",
        "2. Read and summarize the content\n",
        "3. Use the save_summary tool to store your summary\n",
        "4. Report what you found to the user\n",
        "\n",
        "When searching for information:\n",
        "1. Use the search_content tool with relevant keywords from the question\n",
        "2. Look through the results carefully\n",
        "3. Synthesize information from multiple sources\n",
        "4. Provide a comprehensive answer citing your sources\n",
        "\n",
        "Be thorough and use the tools available to you. Don't skip tool usage.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the agent with all tools\n",
        "agent = Agent(\n",
        "    name='research_assistant',\n",
        "    instructions=instructions,\n",
        "    tools=[fetch_web_page, save_summary, search_content],\n",
        "    model='openai:gpt-4o-mini'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: Log Tool Calls\n",
        "\n",
        "First, let's add a helper to see what the agent is doing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to log tool calls - must be async\n",
        "async def log_function_calls(run_ctx, event_stream):\n",
        "    \"\"\"Log all function calls and their results\"\"\"\n",
        "    async for event in event_stream:\n",
        "        try:\n",
        "            if hasattr(event, 'is_function_call') and event.is_function_call():\n",
        "                print(f\"üîß TOOL CALL: {event.content.function_name}({event.content.arguments})\")\n",
        "            elif hasattr(event, 'is_function_result') and event.is_function_result():\n",
        "                result = event.content.result\n",
        "                if isinstance(result, str) and len(result) > 200:\n",
        "                    print(f\"‚úÖ TOOL RESULT: {result[:200]}...\")\n",
        "                else:\n",
        "                    print(f\"‚úÖ TOOL RESULT: {result}\")\n",
        "            elif hasattr(event, 'is_response') and event.is_response():\n",
        "                print(f\"üìù RESPONSE: {event.content}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error logging event: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Question 5: Fetch and Analyze a Wikipedia Page\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Provide a short summary of this page and store that summary: https://en.wikipedia.org/wiki/Capybara\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "I have summarized the Wikipedia page on capybaras. \n",
            "\n",
            "**Summary:** The capybara (Hydrochoerus hydrochaeris) is the largest rodent in the world, native to South America. They are semi-aquatic mammals found near rivers, lakes, and wetlands in groups. Capybaras have webbed feet, long bodies, and a short stout head, adapted for swimming. They are herbivorous, feeding on grasses and aquatic plants, and are social animals, often living in groups of 10-20 individuals. Capybaras are known for their friendly disposition and are often kept as pets. They have few natural predators but can be hunted by jaguars, caimans, and anacondas.\n",
            "\n",
            "This summary has been stored successfully. If you need more information, feel free to ask!\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Verification:\n",
            "Pages fetched: ['https://en.wikipedia.org/wiki/Capybara']\n",
            "Summaries saved: 1\n",
            "  - Capybara\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Clear storage for clean test\n",
        "page_store.clear()\n",
        "summaries_store.clear()\n",
        "\n",
        "# Ask the question\n",
        "question = \"Provide a short summary of this page and store that summary: https://en.wikipedia.org/wiki/Capybara\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ALL SAVED SUMMARIES:\n",
            "================================================================================\n",
            "\n",
            "1. Capybara\n",
            "   The capybara (Hydrochoerus hydrochaeris) is the largest rodent in the world, native to South America. They are semi-aquatic mammals found near rivers, lakes, and wetlands in groups. Capybaras have web...\n",
            "   Timestamp: 2025-10-26T19:09:48.903977\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display all saved summaries\n",
        "print(\"=\"*80)\n",
        "print(\"ALL SAVED SUMMARIES:\")\n",
        "print(\"=\"*80)\n",
        "for i, summary in enumerate(summaries_store, 1):\n",
        "    print(f\"\\n{i}. {summary['title']}\")\n",
        "    print(f\"   {summary['summary'][:200]}...\")\n",
        "    print(f\"   Timestamp: {summary['timestamp']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Provide a short summary of the following pages and stores those summaryies:\n",
            "\n",
            " Lesser capybara ‚Äî https://en.wikipedia.org/wiki/Lesser_capybara\n",
            "\n",
            "Hydrochoerus (genus) ‚Äî https://en.wikipedia.org/wiki/Hydrochoerus\n",
            "\n",
            "Neochoerus (extinct genus related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus\n",
            "\n",
            "Caviodon (extinct genus of rodents related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Caviodon\n",
            "\n",
            "Neochoerus aesopi (extinct species close to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus_aesopi\n",
            "\n",
            "\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "I have successfully fetched and summarized the requested pages. Here are the summaries:\n",
            "\n",
            "1. **Lesser capybara**: The Lesser capybara (Hydrochoerus isthmius) is a rodent native to South America, closely related to the capybara. It inhabits wetland areas, particularly in Brazil and Colombia. This species is smaller than the common capybara and has a more limited range. The Lesser capybara plays a role in its ecosystem, particularly in the dispersal of aquatic plants.\n",
            "\n",
            "2. **Hydrochoerus (genus)**: Hydrochoerus is a genus of large rodents commonly known as capybaras, which includes the extant species Hydrochoerus hydrochaeris (the common capybara) and Hydrochoerus isthmius (the lesser capybara). They are the largest living rodents and are native to South America, inhabiting savannas and dense forests near water sources.\n",
            "\n",
            "3. **Neochoerus (extinct genus related to capybaras)**: Neochoerus is an extinct genus of caviid rodents that lived during the Late Miocene through the Pleistocene epoch in North America. They were close relatives of modern capybaras and are known primarily from fossil remains. Their morphology suggests adaptations for a semi-aquatic lifestyle similar to those of their living relatives.\n",
            "\n",
            "4. **Caviodon (extinct genus of rodents related to capybaras)**: Caviodon is an extinct genus of rodents known from fossils discovered in South America. They belonged to the family Caviidae and are thought to be closely related to modern capybaras. Caviodon lived during the Late Miocene, and its fossil remains indicate morphological traits that align with adaptations seen in contemporary capybaras.\n",
            "\n",
            "5. **Neochoerus aesopi (extinct species close to capybaras)**: Neochoerus aesopi is an extinct species of rodent that is closely related to modern capybaras. It existed during the Pleistocene epoch in North America and is known from fossil evidence. This species, like its relatives, was adapted to a semi-aquatic environment and played a role in the ecosystem during its time.\n",
            "\n",
            "These summaries have been stored successfully. Let me know if you need anything else!\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Verification:\n",
            "Pages fetched: ['https://en.wikipedia.org/wiki/Neochoerus_aesopi', 'https://en.wikipedia.org/wiki/Neochoerus', 'https://en.wikipedia.org/wiki/Lesser_capybara', 'https://en.wikipedia.org/wiki/Caviodon', 'https://en.wikipedia.org/wiki/Hydrochoerus']\n",
            "Summaries saved: 5\n",
            "  - Lesser capybara\n",
            "  - Hydrochoerus (genus)\n",
            "  - Neochoerus (extinct genus related to capybaras)\n",
            "  - Caviodon (extinct genus of rodents related to capybaras)\n",
            "  - Neochoerus aesopi (extinct species close to capybaras)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Call for Question 6 \n",
        "# Clear storage for clean test\n",
        "page_store.clear()\n",
        "summaries_store.clear()\n",
        "\n",
        "# Ask the question\n",
        "question = '''Provide a short summary of the following pages and stores those summaryies:\n",
        "\n",
        " Lesser capybara ‚Äî https://en.wikipedia.org/wiki/Lesser_capybara\n",
        "\n",
        "Hydrochoerus (genus) ‚Äî https://en.wikipedia.org/wiki/Hydrochoerus\n",
        "\n",
        "Neochoerus (extinct genus related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus\n",
        "\n",
        "Caviodon (extinct genus of rodents related to capybaras) ‚Äî https://en.wikipedia.org/wiki/Caviodon\n",
        "\n",
        "Neochoerus aesopi (extinct species close to capybaras) ‚Äî https://en.wikipedia.org/wiki/Neochoerus_aesopi\n",
        "\n",
        "'''\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are the threats to capybara populations?\n",
            "\n",
            "Agent processing...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Final Response:\n",
            "================================================================================\n",
            "Capybara populations face several threats, primarily including:\n",
            "\n",
            "1. **Habitat Destruction**: Agricultural expansion and urban development lead to significant loss of their natural habitats.\n",
            "2. **Hunting**: Capybaras are hunted for their meat and skin, which contributes to population decline.\n",
            "3. **Predation**: They are preyed upon by larger predators such as jaguars and caimans.\n",
            "4. **Diseases and Parasites**: Capybaras are susceptible to various diseases and parasites, which can be worsened by environmental changes.\n",
            "\n",
            "Conservation efforts are crucial to address these threats and ensure the survival of capybara populations.\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Verification:\n",
            "Pages fetched: ['https://en.wikipedia.org/wiki/Neochoerus_aesopi', 'https://en.wikipedia.org/wiki/Neochoerus', 'https://en.wikipedia.org/wiki/Lesser_capybara', 'https://en.wikipedia.org/wiki/Caviodon', 'https://en.wikipedia.org/wiki/Hydrochoerus', 'https://en.wikipedia.org/wiki/Capybara']\n",
            "Summaries saved: 6\n",
            "  - Lesser capybara\n",
            "  - Hydrochoerus (genus)\n",
            "  - Neochoerus (extinct genus related to capybaras)\n",
            "  - Caviodon (extinct genus of rodents related to capybaras)\n",
            "  - Neochoerus aesopi (extinct species close to capybaras)\n",
            "  - Capybara\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Call for Question 6b \n",
        "# DON'T clear storage - we want to keep the indexed pages from Question 6a\n",
        "# This will search through all previously indexed pages\n",
        "\n",
        "# Ask the question about threats\n",
        "question = \"What are the threats to capybara populations?\"\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(\"\\nAgent processing...\\n\")\n",
        "\n",
        "# Run with event logging\n",
        "result = await agent.run(user_prompt=question, event_stream_handler=log_function_calls)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Final Response:\")\n",
        "print(\"=\"*80)\n",
        "print(result.output)\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verify what tools were actually used\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Verification:\")\n",
        "print(f\"Pages fetched: {list(page_store.keys())}\")\n",
        "print(f\"Summaries saved: {len(summaries_store)}\")\n",
        "if summaries_store:\n",
        "    for summary in summaries_store:\n",
        "        print(f\"  - {summary['title']}\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
