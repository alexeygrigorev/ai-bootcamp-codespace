# Agent Response Unit Tests

This directory contains unit tests for validating the SEC Cybersecurity Agent's responses.

## Test Structure

- `agent_tests/test_response_validation.py`: Tests for validating agent responses from stress tests
- `conftest.py`: Pytest configuration and shared fixtures

## Setup

Install pytest (if not already installed):
```bash
cd /Users/ddegeest/my-code-projects/ai-bootcamp-codespace
poetry add --group dev pytest
poetry install --with dev
```

Or install directly:
```bash
pip install pytest
```

## Running Tests

### Run all tests
```bash
cd capstone_project
poetry run pytest eval/tests/ -v
```

### Run unit tests only
```bash
poetry run pytest eval/tests/agent_tests/ -v
```

### Run judge tests only
```bash
poetry run pytest eval/tests/test_judge_evaluation.py -v
```

### Run specific test file
```bash
poetry run pytest eval/tests/agent_tests/test_response_validation.py -v
```

### Run specific test class
```bash
poetry run pytest eval/tests/agent_tests/test_response_validation.py::TestResponseValidation -v
```

### Run specific test
```bash
poetry run pytest eval/tests/agent_tests/test_response_validation.py::TestResponseValidation::test_no_forbidden_phrases -v
```

## Test Coverage

### Unit Tests - Response Validation (`TestResponseValidation`)

Rule-based validation tests that check agent responses for compliance:

1. **`test_no_forbidden_phrases`**: Ensures responses don't contain phrases indicating general knowledge usage
2. **`test_cik_accuracy`**: Validates that responses use correct CIKs (no wrong company mappings)
3. **`test_subsidiary_mapping`**: Checks that subsidiaries are correctly mapped to parent companies
4. **`test_sec_citations_when_filings_found`**: Ensures responses cite SEC forms when information is provided
5. **`test_response_structure`**: Validates that responses have proper structure (not empty)
6. **`test_historical_name_mapping`**: Checks that historical names (Yahoo → Altaba) are correctly mapped

### Unit Tests - CIK Lookup (`TestCIKLookup`)

1. **`test_change_healthcare_maps_to_unitedhealth`**: Validates Change Healthcare → UnitedHealth Group mapping
2. **`test_sony_pictures_maps_to_sony_group`**: Validates Sony Pictures → Sony Group Corp mapping
3. **`test_yahoo_maps_to_altaba_cik`**: Validates Yahoo → Altaba CIK mapping
4. **`test_ticker_symbol_lookup`**: Tests ticker symbol to CIK mappings

### Judge Tests - LLM-Based Evaluation (`test_judge_evaluation.py`)

LLM-based judge tests that evaluate agent response quality:

1. **`test_judge_evaluates_all_responses`**: Verifies judge can evaluate all successful stress test responses
2. **`test_judge_evaluation_completeness`**: Checks that judge evaluation covers all successful responses
3. **`test_judge_identifies_data_source_violations`**: Tests that judge identifies when agent uses general knowledge
4. **`test_judge_evaluates_citation_quality`**: Verifies judge evaluates citation quality in responses
5. **`test_judge_evaluation_average_score`**: Validates that judge provides meaningful average scores
6. **`test_judge_evaluation_summary_statistics`**: Checks that summary statistics are complete
7. **`test_judge_evaluates_missing_document_handling`**: Tests judge evaluation of missing document handling

## Adding New Tests

To add new tests:

1. Add test methods to existing test classes in `test_response_validation.py`
2. Or create new test files following the naming convention `test_*.py`
3. Use pytest fixtures from `conftest.py` for shared setup
4. Follow the existing patterns for assertions and error messages

## Test Data

**Unit Tests**:
- Use `stress_test_results.json` from `eval/` directory
- Generated by running: `poetry run python src/run_stress_tests.py`

**Judge Tests**:
- Use `stress_test_results.json` for input
- Generate `judge_evaluation_results.json` as output
- Run judge evaluation first: `poetry run python eval/judge_evaluator.py`

## Continuous Integration

These tests can be integrated into CI/CD pipelines to ensure agent quality remains consistent across changes.

